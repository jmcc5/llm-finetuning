{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment notebook for \"Context is All You Need\"\n",
    "In this notebook we conduct experiments involving few-shot fine-tuning, in-context learning (ICL), and a novel implementation of context distillation.\n",
    "\n",
    "To install the development environment, run the following:\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate fine-tuning\n",
    "```\n",
    "\n",
    "Run ```pip install -e .``` if module importing isn't working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the check below fails, verify your pytorch installation by following the steps at https://pytorch.org/get-started/locally/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "from src.utils import cuda_check\n",
    "\n",
    "cuda_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets\n",
    "\n",
    "Import datasets using methods from `src/data/data.py`. Datasets are downloaded from huggingface and stored in `/data`. Once downloaded, datasets are loaded locally.\n",
    "\n",
    "Our in domain dataset is [MNLI](https://huggingface.co/datasets/glue). Our out of domain dataset is [HANS](https://huggingface.co/datasets/hans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In domain (MNLI):\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "    num_rows: 261802\n",
      "})\n",
      "{'hypothesis': 'A member of my team will execute your orders with immense '\n",
      "               'precision.',\n",
      " 'idx': 2,\n",
      " 'label': 0,\n",
      " 'premise': 'One of our number will carry out your instructions minutely.'}\n",
      "\n",
      "Out of domain (HANS):\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "{'binary_parse_hypothesis': '( ( The athlete ) ( ( avoided ( the president ) ) '\n",
      "                            '. ) )',\n",
      " 'binary_parse_premise': '( ( The president ) ( ( avoided ( the athlete ) ) . '\n",
      "                         ') )',\n",
      " 'heuristic': 'lexical_overlap',\n",
      " 'hypothesis': 'The athlete avoided the president .',\n",
      " 'label': 1,\n",
      " 'parse_hypothesis': '(ROOT (S (NP (DT The) (NN athlete)) (VP (VBD avoided) '\n",
      "                     '(NP (DT the) (NN president))) (. .)))',\n",
      " 'parse_premise': '(ROOT (S (NP (DT The) (NN president)) (VP (VBD avoided) (NP '\n",
      "                  '(DT the) (NN athlete))) (. .)))',\n",
      " 'premise': 'The president avoided the athlete .',\n",
      " 'subcase': 'ln_subject/object_swap',\n",
      " 'template': 'temp1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from src.data.data import get_in_domain, get_out_domain\n",
    "\n",
    "in_domain_train, in_domain_test = get_in_domain()\n",
    "out_domain = get_out_domain()\n",
    "\n",
    "print(f\"In domain (MNLI):\\n{in_domain_train}\")\n",
    "pprint.pprint(in_domain_train[1])\n",
    "\n",
    "print(f\"\\nOut of domain (HANS):\\n{out_domain}\")\n",
    "pprint.pprint(out_domain[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and evaluation datasets\n",
    "\n",
    "The `get_random_subsets` method from `src/data/data.py` creates a dictionary of training and evaluation data organized by sample size. Each sample size will contain 10 randomly generated trials of that sample size. Evaluation sets contain 50 samples and are randomly generated a single time to ensure consistant comparison across fine-tuning methods.\n",
    "\n",
    "Before generating our datasets, we set random seeds to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train datasets:\n",
      "{2: [...], 4: [...], 8: [...], 16: [...]}\n",
      "\n",
      "Eval datasets:\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "    num_rows: 50\n",
      "})\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from src.data.data import get_random_subsets\n",
    "\n",
    "# Seed random generators\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Generate training and evaluation datasets\n",
    "train_datasets, eval_dataset_in, eval_dataset_out = get_random_subsets(train_dataset=in_domain_train, \n",
    "                                                                       eval_dataset_in=in_domain_test, \n",
    "                                                                       eval_dataset_out=out_domain, \n",
    "                                                                       train_sample_sizes=[2, 4, 8, 16],\n",
    "                                                                       num_trials=10,\n",
    "                                                                       eval_sample_size=50)\n",
    "\n",
    "print(\"Train datasets:\")\n",
    "pprint.pprint(train_datasets, depth=1)\n",
    "print(\"\\nEval datasets:\")\n",
    "pprint.pprint(eval_dataset_in, depth=1)\n",
    "pprint.pprint(eval_dataset_out, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models\n",
    "\n",
    "Import models using methods from `src/models/opt.py`. Models are downloaded from huggingface and stored in `/models/pretrained`. Once downloaded, models are loaded locally. In the following experiments, model loading is handled in the scope of each fine-tuning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.model.model import get_model\n",
    "\n",
    "# # Get SequenceClassification models\n",
    "# model_opt125, tokenizer_opt125 = get_model(model_name='opt-125m', model_type='SequenceClassification', pretrained=True)\n",
    "# model_opt350, tokenizer_opt350 = get_model(model_name='opt-350m', model_type='SequenceClassification', pretrained=True)\n",
    "\n",
    "# # Get CasualLM models\n",
    "# model_opt125_causal, tokenizer_opt125_causal = get_model(model_name='opt-125m', model_type='CausalLM', pretrained=True)\n",
    "# model_opt350_causal, tokenizer_opt350_causal = get_model(model_name='opt-350m', model_type='CausalLM', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot baseline\n",
    "\n",
    "We evaluate both models on in and out of domain eval sets with no training or context using the `generate` method. These results serve as a baseline for comparison to other fine-tuning methods. Model parameters are not updated using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c5fa64b1f841c9821af21ed13ef5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb3618ad10b464686bb784b081775a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89f513b1a63440794a1da4fb5a6298f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abb0aa796884a22882c1c8256041661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "{'eval_in_accuracy': 0.56,\n",
      " 'eval_in_loss': 0.7520318841934204,\n",
      " 'eval_in_peak_memory_gb': 8.716383934020996,\n",
      " 'eval_in_runtime': 45.67260932922363,\n",
      " 'eval_in_samples_per_second': 1.0947480499654196,\n",
      " 'eval_out_accuracy': 0.52,\n",
      " 'eval_out_loss': 0.6991815215349197,\n",
      " 'eval_out_peak_memory_gb': 8.716383934020996,\n",
      " 'eval_out_runtime': 48.564321517944336,\n",
      " 'eval_out_samples_per_second': 1.0295624120173323,\n",
      " 'model_name': 'opt-350m',\n",
      " 'sample_size': '50'}\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.zeroshot import batch_evaluate\n",
    "\n",
    "metrics = batch_evaluate(model_names=['opt-125m', 'opt-350m'], \n",
    "                         eval_dataset_in=eval_dataset_in, \n",
    "                         eval_dataset_out=eval_dataset_out, \n",
    "                         exp_label='final')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot fine-tuning\n",
    "\n",
    "We fine-tune both models on 10 trials of training data and evaluate on in and out of domain eval sets. This method updates all model parameters. Fine-tuned models can be saved locally to `models/finetuned/` by setting the `save_trials` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f401568ae64985bde7dd59823a5808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a78fd266224c4eaa0b439ec76ef900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28b667422be45868eb49b0e3bfbaae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4353790ce7fc4cbe82498cded6791b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98eff2a2a1de471ea5f333b2a5b74d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cde6e66f3ce466badb42d20525a6731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce408b128bc4ae2aea6e95c95030d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76a6febeb714a889d40c892e67546ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "[{'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.6512948274612427,\n",
      "  'eval_in_peak_memory_gb': 1.9606671333312988,\n",
      "  'eval_in_runtime': 2.3888,\n",
      "  'eval_in_samples_per_second': 20.931,\n",
      "  'eval_in_steps_per_second': 2.93,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.3591598272323608,\n",
      "  'eval_out_peak_memory_gb': 1.9606671333312988,\n",
      "  'eval_out_runtime': 2.3738,\n",
      "  'eval_out_samples_per_second': 21.063,\n",
      "  'eval_out_steps_per_second': 2.949,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.09104223455869942,\n",
      "  'train_peak_memory_gb': 2.501254081726074,\n",
      "  'train_runtime': 76.6694,\n",
      "  'train_samples_per_second': 1.043,\n",
      "  'train_steps_per_second': 0.522},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.6590774059295654,\n",
      "  'eval_in_peak_memory_gb': 1.9703221321105957,\n",
      "  'eval_in_runtime': 2.5261,\n",
      "  'eval_in_samples_per_second': 19.794,\n",
      "  'eval_in_steps_per_second': 2.771,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.7978763580322266,\n",
      "  'eval_out_peak_memory_gb': 1.9703221321105957,\n",
      "  'eval_out_runtime': 2.4061,\n",
      "  'eval_out_samples_per_second': 20.78,\n",
      "  'eval_out_steps_per_second': 2.909,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.049839600150153276,\n",
      "  'train_peak_memory_gb': 2.509810447692871,\n",
      "  'train_runtime': 74.3417,\n",
      "  'train_samples_per_second': 1.076,\n",
      "  'train_steps_per_second': 0.538},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.0681917667388916,\n",
      "  'eval_in_peak_memory_gb': 1.9689679145812988,\n",
      "  'eval_in_runtime': 2.3941,\n",
      "  'eval_in_samples_per_second': 20.884,\n",
      "  'eval_in_steps_per_second': 2.924,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 2.241699457168579,\n",
      "  'eval_out_peak_memory_gb': 1.9689679145812988,\n",
      "  'eval_out_runtime': 2.4005,\n",
      "  'eval_out_samples_per_second': 20.829,\n",
      "  'eval_out_steps_per_second': 2.916,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.08353768109982411,\n",
      "  'train_peak_memory_gb': 2.509793281555176,\n",
      "  'train_runtime': 74.1056,\n",
      "  'train_samples_per_second': 1.08,\n",
      "  'train_steps_per_second': 0.54},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.0835771560668945,\n",
      "  'eval_in_peak_memory_gb': 1.9644627571105957,\n",
      "  'eval_in_runtime': 2.3644,\n",
      "  'eval_in_samples_per_second': 21.147,\n",
      "  'eval_in_steps_per_second': 2.961,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 2.3465769290924072,\n",
      "  'eval_out_peak_memory_gb': 1.9644627571105957,\n",
      "  'eval_out_runtime': 2.4877,\n",
      "  'eval_out_samples_per_second': 20.099,\n",
      "  'eval_out_steps_per_second': 2.814,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.1614820058010082,\n",
      "  'train_peak_memory_gb': 2.503951072692871,\n",
      "  'train_runtime': 74.1444,\n",
      "  'train_samples_per_second': 1.079,\n",
      "  'train_steps_per_second': 0.539},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8743894100189209,\n",
      "  'eval_in_peak_memory_gb': 1.9672589302062988,\n",
      "  'eval_in_runtime': 2.3876,\n",
      "  'eval_in_samples_per_second': 20.941,\n",
      "  'eval_in_steps_per_second': 2.932,\n",
      "  'eval_out_accuracy': 0.62,\n",
      "  'eval_out_loss': 0.6655565500259399,\n",
      "  'eval_out_peak_memory_gb': 1.9672589302062988,\n",
      "  'eval_out_runtime': 2.4028,\n",
      "  'eval_out_samples_per_second': 20.809,\n",
      "  'eval_out_steps_per_second': 2.913,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.1133302556212584,\n",
      "  'train_peak_memory_gb': 2.507845878601074,\n",
      "  'train_runtime': 74.8613,\n",
      "  'train_samples_per_second': 1.069,\n",
      "  'train_steps_per_second': 0.534},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.4284957647323608,\n",
      "  'eval_in_peak_memory_gb': 1.9651951789855957,\n",
      "  'eval_in_runtime': 2.3149,\n",
      "  'eval_in_samples_per_second': 21.599,\n",
      "  'eval_in_steps_per_second': 3.024,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.9019846320152283,\n",
      "  'eval_out_peak_memory_gb': 1.9651951789855957,\n",
      "  'eval_out_runtime': 2.3264,\n",
      "  'eval_out_samples_per_second': 21.493,\n",
      "  'eval_out_steps_per_second': 3.009,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.09114095647673821,\n",
      "  'train_peak_memory_gb': 2.5058984756469727,\n",
      "  'train_runtime': 74.4693,\n",
      "  'train_samples_per_second': 1.074,\n",
      "  'train_steps_per_second': 0.537},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.0923309326171875,\n",
      "  'eval_in_peak_memory_gb': 1.9643349647521973,\n",
      "  'eval_in_runtime': 2.3359,\n",
      "  'eval_in_samples_per_second': 21.405,\n",
      "  'eval_in_steps_per_second': 2.997,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 2.407954454421997,\n",
      "  'eval_out_peak_memory_gb': 1.9643349647521973,\n",
      "  'eval_out_runtime': 2.3252,\n",
      "  'eval_out_samples_per_second': 21.504,\n",
      "  'eval_out_steps_per_second': 3.011,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.11192005892853558,\n",
      "  'train_peak_memory_gb': 2.5049219131469727,\n",
      "  'train_runtime': 74.0566,\n",
      "  'train_samples_per_second': 1.08,\n",
      "  'train_steps_per_second': 0.54},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 1.1013184785842896,\n",
      "  'eval_in_peak_memory_gb': 1.9666543006896973,\n",
      "  'eval_in_runtime': 2.3198,\n",
      "  'eval_in_samples_per_second': 21.554,\n",
      "  'eval_in_steps_per_second': 3.018,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7585542798042297,\n",
      "  'eval_out_peak_memory_gb': 1.9666543006896973,\n",
      "  'eval_out_runtime': 2.3195,\n",
      "  'eval_out_samples_per_second': 21.557,\n",
      "  'eval_out_steps_per_second': 3.018,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.07167190347390714,\n",
      "  'train_peak_memory_gb': 2.506625175476074,\n",
      "  'train_runtime': 73.7771,\n",
      "  'train_samples_per_second': 1.084,\n",
      "  'train_steps_per_second': 0.542},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.8509795665740967,\n",
      "  'eval_in_peak_memory_gb': 1.9640908241271973,\n",
      "  'eval_in_runtime': 2.4463,\n",
      "  'eval_in_samples_per_second': 20.439,\n",
      "  'eval_in_steps_per_second': 2.861,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 2.5146594047546387,\n",
      "  'eval_out_peak_memory_gb': 1.9640908241271973,\n",
      "  'eval_out_runtime': 2.3081,\n",
      "  'eval_out_samples_per_second': 21.663,\n",
      "  'eval_out_steps_per_second': 3.033,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.08265501392070292,\n",
      "  'train_peak_memory_gb': 2.504672050476074,\n",
      "  'train_runtime': 72.8753,\n",
      "  'train_samples_per_second': 1.098,\n",
      "  'train_steps_per_second': 0.549},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.2965588569641113,\n",
      "  'eval_in_peak_memory_gb': 1.9664044380187988,\n",
      "  'eval_in_runtime': 2.2699,\n",
      "  'eval_in_samples_per_second': 22.027,\n",
      "  'eval_in_steps_per_second': 3.084,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 3.2080578804016113,\n",
      "  'eval_out_peak_memory_gb': 1.9664044380187988,\n",
      "  'eval_out_runtime': 2.322,\n",
      "  'eval_out_samples_per_second': 21.533,\n",
      "  'eval_out_steps_per_second': 3.015,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.06869642752426444,\n",
      "  'train_peak_memory_gb': 2.506863594055176,\n",
      "  'train_runtime': 72.9848,\n",
      "  'train_samples_per_second': 1.096,\n",
      "  'train_steps_per_second': 0.548},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.02266263961792,\n",
      "  'eval_in_peak_memory_gb': 1.9687294960021973,\n",
      "  'eval_in_runtime': 2.281,\n",
      "  'eval_in_samples_per_second': 21.92,\n",
      "  'eval_in_steps_per_second': 3.069,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.3133018016815186,\n",
      "  'eval_out_peak_memory_gb': 1.9687294960021973,\n",
      "  'eval_out_runtime': 2.3071,\n",
      "  'eval_out_samples_per_second': 21.672,\n",
      "  'eval_out_steps_per_second': 3.034,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.09192299126625585,\n",
      "  'train_peak_memory_gb': 3.5672483444213867,\n",
      "  'train_runtime': 76.6865,\n",
      "  'train_samples_per_second': 2.086,\n",
      "  'train_steps_per_second': 0.522},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.1557531356811523,\n",
      "  'eval_in_peak_memory_gb': 1.9656777381896973,\n",
      "  'eval_in_runtime': 2.3292,\n",
      "  'eval_in_samples_per_second': 21.467,\n",
      "  'eval_in_steps_per_second': 3.005,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.9119937419891357,\n",
      "  'eval_out_peak_memory_gb': 1.9656777381896973,\n",
      "  'eval_out_runtime': 2.3385,\n",
      "  'eval_out_samples_per_second': 21.381,\n",
      "  'eval_out_steps_per_second': 2.993,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.11490638980503717,\n",
      "  'train_peak_memory_gb': 3.5628538131713867,\n",
      "  'train_runtime': 76.5579,\n",
      "  'train_samples_per_second': 2.09,\n",
      "  'train_steps_per_second': 0.522},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.423065662384033,\n",
      "  'eval_in_peak_memory_gb': 1.9650673866271973,\n",
      "  'eval_in_runtime': 2.3354,\n",
      "  'eval_in_samples_per_second': 21.409,\n",
      "  'eval_in_steps_per_second': 2.997,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.4038910865783691,\n",
      "  'eval_out_peak_memory_gb': 1.9650673866271973,\n",
      "  'eval_out_runtime': 2.315,\n",
      "  'eval_out_samples_per_second': 21.598,\n",
      "  'eval_out_steps_per_second': 3.024,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.11094205439439975,\n",
      "  'train_peak_memory_gb': 3.5630979537963867,\n",
      "  'train_runtime': 76.8734,\n",
      "  'train_samples_per_second': 2.081,\n",
      "  'train_steps_per_second': 0.52},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7683770060539246,\n",
      "  'eval_in_peak_memory_gb': 1.9608006477355957,\n",
      "  'eval_in_runtime': 2.2974,\n",
      "  'eval_in_samples_per_second': 21.764,\n",
      "  'eval_in_steps_per_second': 3.047,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7793896198272705,\n",
      "  'eval_out_peak_memory_gb': 1.9608006477355957,\n",
      "  'eval_out_runtime': 2.3095,\n",
      "  'eval_out_samples_per_second': 21.65,\n",
      "  'eval_out_steps_per_second': 3.031,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.11501682789021288,\n",
      "  'train_peak_memory_gb': 3.557488441467285,\n",
      "  'train_runtime': 76.2049,\n",
      "  'train_samples_per_second': 2.1,\n",
      "  'train_steps_per_second': 0.525},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.1842432022094727,\n",
      "  'eval_in_peak_memory_gb': 1.9643349647521973,\n",
      "  'eval_in_runtime': 2.2935,\n",
      "  'eval_in_samples_per_second': 21.801,\n",
      "  'eval_in_steps_per_second': 3.052,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.1006698608398438,\n",
      "  'eval_out_peak_memory_gb': 1.9643349647521973,\n",
      "  'eval_out_runtime': 2.3067,\n",
      "  'eval_out_samples_per_second': 21.676,\n",
      "  'eval_out_steps_per_second': 3.035,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.09240248913811229,\n",
      "  'train_peak_memory_gb': 3.5616331100463867,\n",
      "  'train_runtime': 76.8077,\n",
      "  'train_samples_per_second': 2.083,\n",
      "  'train_steps_per_second': 0.521},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.53071928024292,\n",
      "  'eval_in_peak_memory_gb': 1.9637303352355957,\n",
      "  'eval_in_runtime': 2.3196,\n",
      "  'eval_in_samples_per_second': 21.556,\n",
      "  'eval_in_steps_per_second': 3.018,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.412126302719116,\n",
      "  'eval_out_peak_memory_gb': 1.9637303352355957,\n",
      "  'eval_out_runtime': 2.2783,\n",
      "  'eval_out_samples_per_second': 21.946,\n",
      "  'eval_out_steps_per_second': 3.072,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.07262066169278114,\n",
      "  'train_peak_memory_gb': 3.561638832092285,\n",
      "  'train_runtime': 77.0925,\n",
      "  'train_samples_per_second': 2.075,\n",
      "  'train_steps_per_second': 0.519},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.8670480251312256,\n",
      "  'eval_in_peak_memory_gb': 1.9628643989562988,\n",
      "  'eval_in_runtime': 2.3378,\n",
      "  'eval_in_samples_per_second': 21.387,\n",
      "  'eval_in_steps_per_second': 2.994,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.8240950107574463,\n",
      "  'eval_out_peak_memory_gb': 1.9628643989562988,\n",
      "  'eval_out_runtime': 2.314,\n",
      "  'eval_out_samples_per_second': 21.608,\n",
      "  'eval_out_steps_per_second': 3.025,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.13440734040559618,\n",
      "  'train_peak_memory_gb': 3.5599184036254883,\n",
      "  'train_runtime': 76.6262,\n",
      "  'train_samples_per_second': 2.088,\n",
      "  'train_steps_per_second': 0.522},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 1.0300610065460205,\n",
      "  'eval_in_peak_memory_gb': 1.9637303352355957,\n",
      "  'eval_in_runtime': 2.3632,\n",
      "  'eval_in_samples_per_second': 21.157,\n",
      "  'eval_in_steps_per_second': 2.962,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.9508508443832397,\n",
      "  'eval_out_peak_memory_gb': 1.9637303352355957,\n",
      "  'eval_out_runtime': 2.2786,\n",
      "  'eval_out_samples_per_second': 21.944,\n",
      "  'eval_out_steps_per_second': 3.072,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.085461916110944,\n",
      "  'train_peak_memory_gb': 3.561638832092285,\n",
      "  'train_runtime': 77.3953,\n",
      "  'train_samples_per_second': 2.067,\n",
      "  'train_steps_per_second': 0.517},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.734781503677368,\n",
      "  'eval_in_peak_memory_gb': 1.9621434211730957,\n",
      "  'eval_in_runtime': 2.3323,\n",
      "  'eval_in_samples_per_second': 21.438,\n",
      "  'eval_in_steps_per_second': 3.001,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.797690749168396,\n",
      "  'eval_out_peak_memory_gb': 1.9621434211730957,\n",
      "  'eval_out_runtime': 2.3288,\n",
      "  'eval_out_samples_per_second': 21.47,\n",
      "  'eval_out_steps_per_second': 3.006,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.05555127304905909,\n",
      "  'train_peak_memory_gb': 3.558465003967285,\n",
      "  'train_runtime': 76.5638,\n",
      "  'train_samples_per_second': 2.09,\n",
      "  'train_steps_per_second': 0.522},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.4825992584228516,\n",
      "  'eval_in_peak_memory_gb': 1.9644627571105957,\n",
      "  'eval_in_runtime': 2.2783,\n",
      "  'eval_in_samples_per_second': 21.946,\n",
      "  'eval_in_steps_per_second': 3.073,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.2859082221984863,\n",
      "  'eval_out_peak_memory_gb': 1.9644627571105957,\n",
      "  'eval_out_runtime': 2.3317,\n",
      "  'eval_out_samples_per_second': 21.443,\n",
      "  'eval_out_steps_per_second': 3.002,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.08746785043476848,\n",
      "  'train_peak_memory_gb': 3.561638832092285,\n",
      "  'train_runtime': 76.984,\n",
      "  'train_samples_per_second': 2.078,\n",
      "  'train_steps_per_second': 0.52},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.68,\n",
      "  'eval_in_loss': 0.6119036674499512,\n",
      "  'eval_in_peak_memory_gb': 1.9658055305480957,\n",
      "  'eval_in_runtime': 2.302,\n",
      "  'eval_in_samples_per_second': 21.721,\n",
      "  'eval_in_steps_per_second': 3.041,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.9899230003356934,\n",
      "  'eval_out_peak_memory_gb': 1.9658055305480957,\n",
      "  'eval_out_runtime': 2.3538,\n",
      "  'eval_out_samples_per_second': 21.242,\n",
      "  'eval_out_steps_per_second': 2.974,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.12744573562231382,\n",
      "  'train_peak_memory_gb': 5.667632102966309,\n",
      "  'train_runtime': 82.8868,\n",
      "  'train_samples_per_second': 3.861,\n",
      "  'train_steps_per_second': 0.483},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.1870166063308716,\n",
      "  'eval_in_peak_memory_gb': 1.9666600227355957,\n",
      "  'eval_in_runtime': 2.4376,\n",
      "  'eval_in_samples_per_second': 20.512,\n",
      "  'eval_in_steps_per_second': 2.872,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.96088045835495,\n",
      "  'eval_out_peak_memory_gb': 1.9666600227355957,\n",
      "  'eval_out_runtime': 2.3712,\n",
      "  'eval_out_samples_per_second': 21.086,\n",
      "  'eval_out_steps_per_second': 2.952,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.11443167184916092,\n",
      "  'train_peak_memory_gb': 5.667143821716309,\n",
      "  'train_runtime': 84.372,\n",
      "  'train_samples_per_second': 3.793,\n",
      "  'train_steps_per_second': 0.474},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.9172869324684143,\n",
      "  'eval_in_peak_memory_gb': 1.9672646522521973,\n",
      "  'eval_in_runtime': 2.3219,\n",
      "  'eval_in_samples_per_second': 21.534,\n",
      "  'eval_in_steps_per_second': 3.015,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7478668093681335,\n",
      "  'eval_out_peak_memory_gb': 1.9672646522521973,\n",
      "  'eval_out_runtime': 2.3014,\n",
      "  'eval_out_samples_per_second': 21.726,\n",
      "  'eval_out_steps_per_second': 3.042,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.1622966493203421,\n",
      "  'train_peak_memory_gb': 5.670062065124512,\n",
      "  'train_runtime': 83.5888,\n",
      "  'train_samples_per_second': 3.828,\n",
      "  'train_steps_per_second': 0.479},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.7278499603271484,\n",
      "  'eval_in_peak_memory_gb': 1.9686074256896973,\n",
      "  'eval_in_runtime': 2.3202,\n",
      "  'eval_in_samples_per_second': 21.55,\n",
      "  'eval_in_steps_per_second': 3.017,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.612584114074707,\n",
      "  'eval_out_peak_memory_gb': 1.9686074256896973,\n",
      "  'eval_out_runtime': 2.3439,\n",
      "  'eval_out_samples_per_second': 21.332,\n",
      "  'eval_out_steps_per_second': 2.987,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.09747911978702177,\n",
      "  'train_peak_memory_gb': 5.669085502624512,\n",
      "  'train_runtime': 85.7024,\n",
      "  'train_samples_per_second': 3.734,\n",
      "  'train_steps_per_second': 0.467},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 0.7857147455215454,\n",
      "  'eval_in_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_in_runtime': 2.3112,\n",
      "  'eval_in_samples_per_second': 21.634,\n",
      "  'eval_in_steps_per_second': 3.029,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.8609684705734253,\n",
      "  'eval_out_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_out_runtime': 2.4353,\n",
      "  'eval_out_samples_per_second': 20.532,\n",
      "  'eval_out_steps_per_second': 2.874,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.1330087346563232,\n",
      "  'train_peak_memory_gb': 5.66616153717041,\n",
      "  'train_runtime': 83.3528,\n",
      "  'train_samples_per_second': 3.839,\n",
      "  'train_steps_per_second': 0.48},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.62,\n",
      "  'eval_in_loss': 1.3838775157928467,\n",
      "  'eval_in_peak_memory_gb': 1.9666600227355957,\n",
      "  'eval_in_runtime': 2.3116,\n",
      "  'eval_in_samples_per_second': 21.63,\n",
      "  'eval_in_steps_per_second': 3.028,\n",
      "  'eval_out_accuracy': 0.44,\n",
      "  'eval_out_loss': 1.420020580291748,\n",
      "  'eval_out_peak_memory_gb': 1.9666600227355957,\n",
      "  'eval_out_runtime': 2.3063,\n",
      "  'eval_out_samples_per_second': 21.679,\n",
      "  'eval_out_steps_per_second': 3.035,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.10391211378955631,\n",
      "  'train_peak_memory_gb': 5.667387962341309,\n",
      "  'train_runtime': 83.3376,\n",
      "  'train_samples_per_second': 3.84,\n",
      "  'train_steps_per_second': 0.48},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 1.4416691064834595,\n",
      "  'eval_in_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_in_runtime': 2.4452,\n",
      "  'eval_in_samples_per_second': 20.448,\n",
      "  'eval_in_steps_per_second': 2.863,\n",
      "  'eval_out_accuracy': 0.44,\n",
      "  'eval_out_loss': 1.0013431310653687,\n",
      "  'eval_out_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_out_runtime': 2.4603,\n",
      "  'eval_out_samples_per_second': 20.323,\n",
      "  'eval_out_steps_per_second': 2.845,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.07683522509105387,\n",
      "  'train_peak_memory_gb': 5.66616153717041,\n",
      "  'train_runtime': 84.243,\n",
      "  'train_samples_per_second': 3.799,\n",
      "  'train_steps_per_second': 0.475},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.5243215560913086,\n",
      "  'eval_in_peak_memory_gb': 1.9681248664855957,\n",
      "  'eval_in_runtime': 2.338,\n",
      "  'eval_in_samples_per_second': 21.386,\n",
      "  'eval_in_steps_per_second': 2.994,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.0511786937713623,\n",
      "  'eval_out_peak_memory_gb': 1.9681248664855957,\n",
      "  'eval_out_runtime': 2.419,\n",
      "  'eval_out_samples_per_second': 20.67,\n",
      "  'eval_out_steps_per_second': 2.894,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.15225724070478464,\n",
      "  'train_peak_memory_gb': 5.66957950592041,\n",
      "  'train_runtime': 85.2623,\n",
      "  'train_samples_per_second': 3.753,\n",
      "  'train_steps_per_second': 0.469},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.8573195934295654,\n",
      "  'eval_in_peak_memory_gb': 1.9660496711730957,\n",
      "  'eval_in_runtime': 2.3872,\n",
      "  'eval_in_samples_per_second': 20.945,\n",
      "  'eval_in_steps_per_second': 2.932,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7637326121330261,\n",
      "  'eval_out_peak_memory_gb': 1.9660496711730957,\n",
      "  'eval_out_runtime': 2.3379,\n",
      "  'eval_out_samples_per_second': 21.386,\n",
      "  'eval_out_steps_per_second': 2.994,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.11652317558182404,\n",
      "  'train_peak_memory_gb': 5.66640567779541,\n",
      "  'train_runtime': 86.7795,\n",
      "  'train_samples_per_second': 3.688,\n",
      "  'train_steps_per_second': 0.461},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.6968246698379517,\n",
      "  'eval_in_peak_memory_gb': 1.9688572883605957,\n",
      "  'eval_in_runtime': 2.3947,\n",
      "  'eval_in_samples_per_second': 20.879,\n",
      "  'eval_in_steps_per_second': 2.923,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.8947157859802246,\n",
      "  'eval_out_peak_memory_gb': 1.9688572883605957,\n",
      "  'eval_out_runtime': 2.4095,\n",
      "  'eval_out_samples_per_second': 20.751,\n",
      "  'eval_out_steps_per_second': 2.905,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83614960189440.0,\n",
      "  'train_loss': 0.13686920835243654,\n",
      "  'train_peak_memory_gb': 5.670073509216309,\n",
      "  'train_runtime': 85.1593,\n",
      "  'train_samples_per_second': 3.758,\n",
      "  'train_steps_per_second': 0.47},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.880422055721283,\n",
      "  'eval_in_peak_memory_gb': 1.9645848274230957,\n",
      "  'eval_in_runtime': 2.3834,\n",
      "  'eval_in_samples_per_second': 20.978,\n",
      "  'eval_in_steps_per_second': 2.937,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.1494026184082031,\n",
      "  'eval_out_peak_memory_gb': 1.9645848274230957,\n",
      "  'eval_out_runtime': 2.3296,\n",
      "  'eval_out_samples_per_second': 21.463,\n",
      "  'eval_out_steps_per_second': 3.005,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.09256214653159986,\n",
      "  'train_peak_memory_gb': 5.66542911529541,\n",
      "  'train_runtime': 102.1258,\n",
      "  'train_samples_per_second': 6.267,\n",
      "  'train_steps_per_second': 0.783},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.64,\n",
      "  'eval_in_loss': 0.8719920516014099,\n",
      "  'eval_in_peak_memory_gb': 1.9688572883605957,\n",
      "  'eval_in_runtime': 2.4014,\n",
      "  'eval_in_samples_per_second': 20.822,\n",
      "  'eval_in_steps_per_second': 2.915,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.8737753033638,\n",
      "  'eval_out_peak_memory_gb': 1.9688572883605957,\n",
      "  'eval_out_runtime': 2.5673,\n",
      "  'eval_out_samples_per_second': 19.475,\n",
      "  'eval_out_steps_per_second': 2.727,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.11410071380469163,\n",
      "  'train_peak_memory_gb': 5.67080020904541,\n",
      "  'train_runtime': 102.5944,\n",
      "  'train_samples_per_second': 6.238,\n",
      "  'train_steps_per_second': 0.78},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 1.2339309453964233,\n",
      "  'eval_in_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_in_runtime': 2.3671,\n",
      "  'eval_in_samples_per_second': 21.123,\n",
      "  'eval_in_steps_per_second': 2.957,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 1.0251389741897583,\n",
      "  'eval_out_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_out_runtime': 2.551,\n",
      "  'eval_out_samples_per_second': 19.601,\n",
      "  'eval_out_steps_per_second': 2.744,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.10692669729396584,\n",
      "  'train_peak_memory_gb': 5.66567325592041,\n",
      "  'train_runtime': 104.368,\n",
      "  'train_samples_per_second': 6.132,\n",
      "  'train_steps_per_second': 0.767},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 2.4527273178100586,\n",
      "  'eval_in_peak_memory_gb': 1.9700722694396973,\n",
      "  'eval_in_runtime': 2.4118,\n",
      "  'eval_in_samples_per_second': 20.731,\n",
      "  'eval_in_steps_per_second': 2.902,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.780989408493042,\n",
      "  'eval_out_peak_memory_gb': 1.9700722694396973,\n",
      "  'eval_out_runtime': 2.3677,\n",
      "  'eval_out_samples_per_second': 21.117,\n",
      "  'eval_out_steps_per_second': 2.956,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.07736830241638018,\n",
      "  'train_peak_memory_gb': 5.671282768249512,\n",
      "  'train_runtime': 102.6465,\n",
      "  'train_samples_per_second': 6.235,\n",
      "  'train_steps_per_second': 0.779},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 1.0890841484069824,\n",
      "  'eval_in_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_in_runtime': 2.4123,\n",
      "  'eval_in_samples_per_second': 20.727,\n",
      "  'eval_in_steps_per_second': 2.902,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.5289098024368286,\n",
      "  'eval_out_peak_memory_gb': 1.9653172492980957,\n",
      "  'eval_out_runtime': 2.3796,\n",
      "  'eval_out_samples_per_second': 21.012,\n",
      "  'eval_out_steps_per_second': 2.942,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.09296711258975847,\n",
      "  'train_peak_memory_gb': 5.66542911529541,\n",
      "  'train_runtime': 102.1524,\n",
      "  'train_samples_per_second': 6.265,\n",
      "  'train_steps_per_second': 0.783},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.5014020204544067,\n",
      "  'eval_in_peak_memory_gb': 1.9703221321105957,\n",
      "  'eval_in_runtime': 2.3903,\n",
      "  'eval_in_samples_per_second': 20.918,\n",
      "  'eval_in_steps_per_second': 2.928,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.8621004223823547,\n",
      "  'eval_out_peak_memory_gb': 1.9703221321105957,\n",
      "  'eval_out_runtime': 2.4205,\n",
      "  'eval_out_samples_per_second': 20.657,\n",
      "  'eval_out_steps_per_second': 2.892,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.08805117928259279,\n",
      "  'train_peak_memory_gb': 5.67080020904541,\n",
      "  'train_runtime': 102.2072,\n",
      "  'train_samples_per_second': 6.262,\n",
      "  'train_steps_per_second': 0.783},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.62,\n",
      "  'eval_in_loss': 1.079645037651062,\n",
      "  'eval_in_peak_memory_gb': 1.9650673866271973,\n",
      "  'eval_in_runtime': 2.371,\n",
      "  'eval_in_samples_per_second': 21.088,\n",
      "  'eval_in_steps_per_second': 2.952,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.6370360851287842,\n",
      "  'eval_out_peak_memory_gb': 1.9650673866271973,\n",
      "  'eval_out_runtime': 2.418,\n",
      "  'eval_out_samples_per_second': 20.679,\n",
      "  'eval_out_steps_per_second': 2.895,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.09909379829259705,\n",
      "  'train_peak_memory_gb': 5.664690971374512,\n",
      "  'train_runtime': 102.8472,\n",
      "  'train_samples_per_second': 6.223,\n",
      "  'train_steps_per_second': 0.778},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.6006033420562744,\n",
      "  'eval_in_peak_memory_gb': 1.9686074256896973,\n",
      "  'eval_in_runtime': 2.4025,\n",
      "  'eval_in_samples_per_second': 20.811,\n",
      "  'eval_in_steps_per_second': 2.914,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.7788376808166504,\n",
      "  'eval_out_peak_memory_gb': 1.9686074256896973,\n",
      "  'eval_out_runtime': 2.3654,\n",
      "  'eval_out_samples_per_second': 21.138,\n",
      "  'eval_out_steps_per_second': 2.959,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.12380069977843959,\n",
      "  'train_peak_memory_gb': 5.669817924499512,\n",
      "  'train_runtime': 101.6613,\n",
      "  'train_samples_per_second': 6.295,\n",
      "  'train_steps_per_second': 0.787},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.64,\n",
      "  'eval_in_loss': 1.007778525352478,\n",
      "  'eval_in_peak_memory_gb': 1.9660496711730957,\n",
      "  'eval_in_runtime': 2.4544,\n",
      "  'eval_in_samples_per_second': 20.371,\n",
      "  'eval_in_steps_per_second': 2.852,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.211786985397339,\n",
      "  'eval_out_peak_memory_gb': 1.9660496711730957,\n",
      "  'eval_out_runtime': 2.3934,\n",
      "  'eval_out_samples_per_second': 20.891,\n",
      "  'eval_out_steps_per_second': 2.925,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.09887633431462746,\n",
      "  'train_peak_memory_gb': 5.666167259216309,\n",
      "  'train_runtime': 101.2927,\n",
      "  'train_samples_per_second': 6.318,\n",
      "  'train_steps_per_second': 0.79},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.6612656116485596,\n",
      "  'eval_in_peak_memory_gb': 1.9678750038146973,\n",
      "  'eval_in_runtime': 2.3832,\n",
      "  'eval_in_samples_per_second': 20.98,\n",
      "  'eval_in_steps_per_second': 2.937,\n",
      "  'eval_out_accuracy': 0.44,\n",
      "  'eval_out_loss': 0.8224455118179321,\n",
      "  'eval_out_peak_memory_gb': 1.9678750038146973,\n",
      "  'eval_out_runtime': 2.3556,\n",
      "  'eval_out_samples_per_second': 21.226,\n",
      "  'eval_out_steps_per_second': 2.972,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167229920378880.0,\n",
      "  'train_loss': 0.09455249685088347,\n",
      "  'train_peak_memory_gb': 5.668108940124512,\n",
      "  'train_runtime': 100.626,\n",
      "  'train_samples_per_second': 6.36,\n",
      "  'train_steps_per_second': 0.795},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 3.8622705936431885,\n",
      "  'eval_in_peak_memory_gb': 4.794731616973877,\n",
      "  'eval_in_runtime': 12.4029,\n",
      "  'eval_in_samples_per_second': 4.031,\n",
      "  'eval_in_steps_per_second': 0.564,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 1.2294542789459229,\n",
      "  'eval_out_peak_memory_gb': 4.794731616973877,\n",
      "  'eval_out_runtime': 12.5678,\n",
      "  'eval_out_samples_per_second': 3.978,\n",
      "  'eval_out_steps_per_second': 0.557,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.05370558390046822,\n",
      "  'train_peak_memory_gb': 6.504080772399902,\n",
      "  'train_runtime': 179.384,\n",
      "  'train_samples_per_second': 0.446,\n",
      "  'train_steps_per_second': 0.223},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 10.111700057983398,\n",
      "  'eval_in_peak_memory_gb': 4.795944690704346,\n",
      "  'eval_in_runtime': 16.5275,\n",
      "  'eval_in_samples_per_second': 3.025,\n",
      "  'eval_in_steps_per_second': 0.424,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 8.341504096984863,\n",
      "  'eval_out_peak_memory_gb': 4.795944690704346,\n",
      "  'eval_out_runtime': 16.2669,\n",
      "  'eval_out_samples_per_second': 3.074,\n",
      "  'eval_out_steps_per_second': 0.43,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.02108209662227791,\n",
      "  'train_peak_memory_gb': 6.505293846130371,\n",
      "  'train_runtime': 212.2038,\n",
      "  'train_samples_per_second': 0.377,\n",
      "  'train_steps_per_second': 0.188},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 8.323565483093262,\n",
      "  'eval_in_peak_memory_gb': 4.796440601348877,\n",
      "  'eval_in_runtime': 16.5919,\n",
      "  'eval_in_samples_per_second': 3.014,\n",
      "  'eval_in_steps_per_second': 0.422,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 7.603822231292725,\n",
      "  'eval_out_peak_memory_gb': 4.796440601348877,\n",
      "  'eval_out_runtime': 16.3361,\n",
      "  'eval_out_samples_per_second': 3.061,\n",
      "  'eval_out_steps_per_second': 0.428,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.07785814142715557,\n",
      "  'train_peak_memory_gb': 6.503836631774902,\n",
      "  'train_runtime': 211.4534,\n",
      "  'train_samples_per_second': 0.378,\n",
      "  'train_steps_per_second': 0.189},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 7.266726016998291,\n",
      "  'eval_in_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_in_runtime': 16.2645,\n",
      "  'eval_in_samples_per_second': 3.074,\n",
      "  'eval_in_steps_per_second': 0.43,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 5.9048333168029785,\n",
      "  'eval_out_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_out_runtime': 16.4184,\n",
      "  'eval_out_samples_per_second': 3.045,\n",
      "  'eval_out_steps_per_second': 0.426,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.023467183338922747,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 212.3075,\n",
      "  'train_samples_per_second': 0.377,\n",
      "  'train_steps_per_second': 0.188},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.903283715248108,\n",
      "  'eval_in_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_in_runtime': 14.3092,\n",
      "  'eval_in_samples_per_second': 3.494,\n",
      "  'eval_in_steps_per_second': 0.489,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.9551344513893127,\n",
      "  'eval_out_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_out_runtime': 14.2385,\n",
      "  'eval_out_samples_per_second': 3.512,\n",
      "  'eval_out_steps_per_second': 0.492,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.05485075943400695,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 195.5086,\n",
      "  'train_samples_per_second': 0.409,\n",
      "  'train_steps_per_second': 0.205},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 2.3737268447875977,\n",
      "  'eval_in_peak_memory_gb': 4.794487476348877,\n",
      "  'eval_in_runtime': 14.3783,\n",
      "  'eval_in_samples_per_second': 3.477,\n",
      "  'eval_in_steps_per_second': 0.487,\n",
      "  'eval_out_accuracy': 0.62,\n",
      "  'eval_out_loss': 0.8707536458969116,\n",
      "  'eval_out_peak_memory_gb': 4.794487476348877,\n",
      "  'eval_out_runtime': 14.3927,\n",
      "  'eval_out_samples_per_second': 3.474,\n",
      "  'eval_out_steps_per_second': 0.486,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.09348717808996518,\n",
      "  'train_peak_memory_gb': 6.503836631774902,\n",
      "  'train_runtime': 196.1019,\n",
      "  'train_samples_per_second': 0.408,\n",
      "  'train_steps_per_second': 0.204},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 8.16798210144043,\n",
      "  'eval_in_peak_memory_gb': 4.794487476348877,\n",
      "  'eval_in_runtime': 11.7798,\n",
      "  'eval_in_samples_per_second': 4.245,\n",
      "  'eval_in_steps_per_second': 0.594,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 6.7218017578125,\n",
      "  'eval_out_peak_memory_gb': 4.794487476348877,\n",
      "  'eval_out_runtime': 11.7271,\n",
      "  'eval_out_samples_per_second': 4.264,\n",
      "  'eval_out_steps_per_second': 0.597,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.04246882254922877,\n",
      "  'train_peak_memory_gb': 6.503836631774902,\n",
      "  'train_runtime': 175.919,\n",
      "  'train_samples_per_second': 0.455,\n",
      "  'train_steps_per_second': 0.227},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.7899113893508911,\n",
      "  'eval_in_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_in_runtime': 11.6464,\n",
      "  'eval_in_samples_per_second': 4.293,\n",
      "  'eval_in_steps_per_second': 0.601,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7463599443435669,\n",
      "  'eval_out_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_out_runtime': 11.779,\n",
      "  'eval_out_samples_per_second': 4.245,\n",
      "  'eval_out_steps_per_second': 0.594,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.04721237719209261,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 175.4877,\n",
      "  'train_samples_per_second': 0.456,\n",
      "  'train_steps_per_second': 0.228},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 8.00939655303955,\n",
      "  'eval_in_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_in_runtime': 11.7605,\n",
      "  'eval_in_samples_per_second': 4.252,\n",
      "  'eval_in_steps_per_second': 0.595,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 7.987216949462891,\n",
      "  'eval_out_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_out_runtime': 11.7622,\n",
      "  'eval_out_samples_per_second': 4.251,\n",
      "  'eval_out_steps_per_second': 0.595,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.036897112277464304,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 172.0319,\n",
      "  'train_samples_per_second': 0.465,\n",
      "  'train_steps_per_second': 0.233},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 9.135858535766602,\n",
      "  'eval_in_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_in_runtime': 12.4293,\n",
      "  'eval_in_samples_per_second': 4.023,\n",
      "  'eval_in_steps_per_second': 0.563,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 7.787524223327637,\n",
      "  'eval_out_peak_memory_gb': 4.795456409454346,\n",
      "  'eval_out_runtime': 12.5329,\n",
      "  'eval_out_samples_per_second': 3.989,\n",
      "  'eval_out_steps_per_second': 0.559,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.03595399767670306,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 176.7036,\n",
      "  'train_samples_per_second': 0.453,\n",
      "  'train_steps_per_second': 0.226},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 6.146905899047852,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 13.284,\n",
      "  'eval_in_samples_per_second': 3.764,\n",
      "  'eval_in_steps_per_second': 0.527,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 5.738714694976807,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 13.2139,\n",
      "  'eval_out_samples_per_second': 3.784,\n",
      "  'eval_out_steps_per_second': 0.53,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.10596712044944825,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 378.6854,\n",
      "  'train_samples_per_second': 0.423,\n",
      "  'train_steps_per_second': 0.106},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.641188383102417,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 17.018,\n",
      "  'eval_in_samples_per_second': 2.938,\n",
      "  'eval_in_steps_per_second': 0.411,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 1.5868139266967773,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 17.1499,\n",
      "  'eval_out_samples_per_second': 2.915,\n",
      "  'eval_out_steps_per_second': 0.408,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.03722372841451786,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 402.4485,\n",
      "  'train_samples_per_second': 0.398,\n",
      "  'train_steps_per_second': 0.099},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 3.8698697090148926,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 29.6859,\n",
      "  'eval_in_samples_per_second': 1.684,\n",
      "  'eval_in_steps_per_second': 0.236,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 1.5674378871917725,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 29.7177,\n",
      "  'eval_out_samples_per_second': 1.682,\n",
      "  'eval_out_steps_per_second': 0.236,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.04659962610319326,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 519.049,\n",
      "  'train_samples_per_second': 0.308,\n",
      "  'train_steps_per_second': 0.077},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.7922128438949585,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 18.8394,\n",
      "  'eval_in_samples_per_second': 2.654,\n",
      "  'eval_in_steps_per_second': 0.372,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.8684401512145996,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 18.7826,\n",
      "  'eval_out_samples_per_second': 2.662,\n",
      "  'eval_out_steps_per_second': 0.373,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.038441557649865746,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 439.2834,\n",
      "  'train_samples_per_second': 0.364,\n",
      "  'train_steps_per_second': 0.091},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 5.010772705078125,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 23.0261,\n",
      "  'eval_in_samples_per_second': 2.171,\n",
      "  'eval_in_steps_per_second': 0.304,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 4.638939380645752,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 23.0429,\n",
      "  'eval_out_samples_per_second': 2.17,\n",
      "  'eval_out_steps_per_second': 0.304,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.040055715027727604,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 419.1506,\n",
      "  'train_samples_per_second': 0.382,\n",
      "  'train_steps_per_second': 0.095},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.2830395698547363,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 21.075,\n",
      "  'eval_in_samples_per_second': 2.372,\n",
      "  'eval_in_steps_per_second': 0.332,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 3.6986048221588135,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 21.1959,\n",
      "  'eval_out_samples_per_second': 2.359,\n",
      "  'eval_out_steps_per_second': 0.33,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.059069031394025195,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 446.6063,\n",
      "  'train_samples_per_second': 0.358,\n",
      "  'train_steps_per_second': 0.09},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.6293030977249146,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 29.8847,\n",
      "  'eval_in_samples_per_second': 1.673,\n",
      "  'eval_in_steps_per_second': 0.234,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.8478844165802002,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 29.9414,\n",
      "  'eval_out_samples_per_second': 1.67,\n",
      "  'eval_out_steps_per_second': 0.234,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.1078892665624295,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 489.2048,\n",
      "  'train_samples_per_second': 0.327,\n",
      "  'train_steps_per_second': 0.082},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.5285453796386719,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 20.1419,\n",
      "  'eval_in_samples_per_second': 2.482,\n",
      "  'eval_in_steps_per_second': 0.348,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.9498306512832642,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 19.9996,\n",
      "  'eval_out_samples_per_second': 2.5,\n",
      "  'eval_out_steps_per_second': 0.35,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.07910946360097952,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 422.3879,\n",
      "  'train_samples_per_second': 0.379,\n",
      "  'train_steps_per_second': 0.095},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 7.0978217124938965,\n",
      "  'eval_in_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_in_runtime': 27.9285,\n",
      "  'eval_in_samples_per_second': 1.79,\n",
      "  'eval_in_steps_per_second': 0.251,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7820982336997986,\n",
      "  'eval_out_peak_memory_gb': 4.797409534454346,\n",
      "  'eval_out_runtime': 27.8806,\n",
      "  'eval_out_samples_per_second': 1.793,\n",
      "  'eval_out_steps_per_second': 0.251,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.05759723169011397,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 476.3324,\n",
      "  'train_samples_per_second': 0.336,\n",
      "  'train_steps_per_second': 0.084},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 5.201329231262207,\n",
      "  'eval_in_peak_memory_gb': 4.796432971954346,\n",
      "  'eval_in_runtime': 20.9622,\n",
      "  'eval_in_samples_per_second': 2.385,\n",
      "  'eval_in_steps_per_second': 0.334,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 3.0622212886810303,\n",
      "  'eval_out_peak_memory_gb': 4.796432971954346,\n",
      "  'eval_out_runtime': 20.7228,\n",
      "  'eval_out_samples_per_second': 2.413,\n",
      "  'eval_out_steps_per_second': 0.338,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.022113627838086947,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 434.8599,\n",
      "  'train_samples_per_second': 0.368,\n",
      "  'train_steps_per_second': 0.092},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 1.121846318244934,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 17.1134,\n",
      "  'eval_in_samples_per_second': 2.922,\n",
      "  'eval_in_steps_per_second': 0.76,\n",
      "  'eval_out_accuracy': 0.64,\n",
      "  'eval_out_loss': 0.8708092570304871,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 16.8902,\n",
      "  'eval_out_samples_per_second': 2.96,\n",
      "  'eval_out_steps_per_second': 0.77,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.051356260075348235,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 616.1801,\n",
      "  'train_samples_per_second': 0.519,\n",
      "  'train_steps_per_second': 0.13},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 1.3212921619415283,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 10.618,\n",
      "  'eval_in_samples_per_second': 4.709,\n",
      "  'eval_in_steps_per_second': 1.224,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.8129022121429443,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 10.7842,\n",
      "  'eval_out_samples_per_second': 4.636,\n",
      "  'eval_out_steps_per_second': 1.205,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.056002235618483456,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 589.5111,\n",
      "  'train_samples_per_second': 0.543,\n",
      "  'train_steps_per_second': 0.136},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.8969310522079468,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 12.2289,\n",
      "  'eval_in_samples_per_second': 4.089,\n",
      "  'eval_in_steps_per_second': 1.063,\n",
      "  'eval_out_accuracy': 0.44,\n",
      "  'eval_out_loss': 1.504125714302063,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 12.1819,\n",
      "  'eval_out_samples_per_second': 4.104,\n",
      "  'eval_out_steps_per_second': 1.067,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.036089679052821566,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 612.0832,\n",
      "  'train_samples_per_second': 0.523,\n",
      "  'train_steps_per_second': 0.131},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 5.723161697387695,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 17.2884,\n",
      "  'eval_in_samples_per_second': 2.892,\n",
      "  'eval_in_steps_per_second': 0.752,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 5.5443806648254395,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 17.1876,\n",
      "  'eval_out_samples_per_second': 2.909,\n",
      "  'eval_out_steps_per_second': 0.756,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.042188926207030894,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 605.3345,\n",
      "  'train_samples_per_second': 0.529,\n",
      "  'train_steps_per_second': 0.132},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.7607998847961426,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 21.7947,\n",
      "  'eval_in_samples_per_second': 2.294,\n",
      "  'eval_in_steps_per_second': 0.596,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 2.254488468170166,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 21.5779,\n",
      "  'eval_out_samples_per_second': 2.317,\n",
      "  'eval_out_steps_per_second': 0.602,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.052995371889322664,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 667.9395,\n",
      "  'train_samples_per_second': 0.479,\n",
      "  'train_steps_per_second': 0.12},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 2.6741843223571777,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 19.4419,\n",
      "  'eval_in_samples_per_second': 2.572,\n",
      "  'eval_in_steps_per_second': 0.669,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 2.1051294803619385,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 19.7026,\n",
      "  'eval_out_samples_per_second': 2.538,\n",
      "  'eval_out_steps_per_second': 0.66,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.037548837642827945,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 641.243,\n",
      "  'train_samples_per_second': 0.499,\n",
      "  'train_steps_per_second': 0.125},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 2.6565661430358887,\n",
      "  'eval_in_peak_memory_gb': 4.261246204376221,\n",
      "  'eval_in_runtime': 18.7137,\n",
      "  'eval_in_samples_per_second': 2.672,\n",
      "  'eval_in_steps_per_second': 0.695,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 2.2835946083068848,\n",
      "  'eval_out_peak_memory_gb': 4.261246204376221,\n",
      "  'eval_out_runtime': 18.6636,\n",
      "  'eval_out_samples_per_second': 2.679,\n",
      "  'eval_out_steps_per_second': 0.697,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.050192663914954846,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 575.1351,\n",
      "  'train_samples_per_second': 0.556,\n",
      "  'train_steps_per_second': 0.139},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 4.658231258392334,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 12.5494,\n",
      "  'eval_in_samples_per_second': 3.984,\n",
      "  'eval_in_steps_per_second': 1.036,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 1.2319560050964355,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 12.5952,\n",
      "  'eval_out_samples_per_second': 3.97,\n",
      "  'eval_out_steps_per_second': 1.032,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.03833681739286341,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 551.1268,\n",
      "  'train_samples_per_second': 0.581,\n",
      "  'train_steps_per_second': 0.145},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 2.439480781555176,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 15.715,\n",
      "  'eval_in_samples_per_second': 3.182,\n",
      "  'eval_in_steps_per_second': 0.827,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 2.0439600944519043,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 15.6486,\n",
      "  'eval_out_samples_per_second': 3.195,\n",
      "  'eval_out_steps_per_second': 0.831,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.05433017840106338,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 564.5107,\n",
      "  'train_samples_per_second': 0.567,\n",
      "  'train_steps_per_second': 0.142},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 6.784378528594971,\n",
      "  'eval_in_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_in_runtime': 18.0563,\n",
      "  'eval_in_samples_per_second': 2.769,\n",
      "  'eval_in_steps_per_second': 0.72,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 4.124746799468994,\n",
      "  'eval_out_peak_memory_gb': 4.263199329376221,\n",
      "  'eval_out_runtime': 17.7266,\n",
      "  'eval_out_samples_per_second': 2.821,\n",
      "  'eval_out_steps_per_second': 0.733,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298214007767040.0,\n",
      "  'train_loss': 0.024758649220779638,\n",
      "  'train_peak_memory_gb': 9.243460655212402,\n",
      "  'train_runtime': 553.4537,\n",
      "  'train_samples_per_second': 0.578,\n",
      "  'train_steps_per_second': 0.145},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 1.6758835315704346,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 12.8003,\n",
      "  'eval_in_samples_per_second': 3.906,\n",
      "  'eval_in_steps_per_second': 1.953,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 1.1500297784805298,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 12.6414,\n",
      "  'eval_out_samples_per_second': 3.955,\n",
      "  'eval_out_steps_per_second': 1.978,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.05711895451688835,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 578.5675,\n",
      "  'train_samples_per_second': 1.106,\n",
      "  'train_steps_per_second': 0.553},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.53178071975708,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 5.43,\n",
      "  'eval_in_samples_per_second': 9.208,\n",
      "  'eval_in_steps_per_second': 4.604,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.1722509860992432,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 5.3004,\n",
      "  'eval_out_samples_per_second': 9.433,\n",
      "  'eval_out_steps_per_second': 4.717,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.029122941909392352,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 437.0735,\n",
      "  'train_samples_per_second': 1.464,\n",
      "  'train_steps_per_second': 0.732},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 2.024996757507324,\n",
      "  'eval_in_peak_memory_gb': 3.9946370124816895,\n",
      "  'eval_in_runtime': 4.9888,\n",
      "  'eval_in_samples_per_second': 10.022,\n",
      "  'eval_in_steps_per_second': 5.011,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 1.2061320543289185,\n",
      "  'eval_out_peak_memory_gb': 3.9946370124816895,\n",
      "  'eval_out_runtime': 4.8736,\n",
      "  'eval_out_samples_per_second': 10.259,\n",
      "  'eval_out_steps_per_second': 5.13,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.03805808782659176,\n",
      "  'train_peak_memory_gb': 6.502860069274902,\n",
      "  'train_runtime': 428.0273,\n",
      "  'train_samples_per_second': 1.495,\n",
      "  'train_steps_per_second': 0.748},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.8043909072875977,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 6.203,\n",
      "  'eval_in_samples_per_second': 8.061,\n",
      "  'eval_in_steps_per_second': 4.03,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.6793243885040283,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 6.0629,\n",
      "  'eval_out_samples_per_second': 8.247,\n",
      "  'eval_out_steps_per_second': 4.123,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.04193374218583736,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 447.37,\n",
      "  'train_samples_per_second': 1.431,\n",
      "  'train_steps_per_second': 0.715},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 2.3133254051208496,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 5.8376,\n",
      "  'eval_in_samples_per_second': 8.565,\n",
      "  'eval_in_steps_per_second': 4.283,\n",
      "  'eval_out_accuracy': 0.42,\n",
      "  'eval_out_loss': 1.9191783666610718,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 5.7715,\n",
      "  'eval_out_samples_per_second': 8.663,\n",
      "  'eval_out_steps_per_second': 4.332,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.05322805272598317,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 433.7739,\n",
      "  'train_samples_per_second': 1.475,\n",
      "  'train_steps_per_second': 0.738},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 2.605842351913452,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 5.3129,\n",
      "  'eval_in_samples_per_second': 9.411,\n",
      "  'eval_in_steps_per_second': 4.706,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 1.204371452331543,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 5.1916,\n",
      "  'eval_out_samples_per_second': 9.631,\n",
      "  'eval_out_steps_per_second': 4.815,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.031560660667103425,\n",
      "  'train_peak_memory_gb': 6.501875877380371,\n",
      "  'train_runtime': 415.37,\n",
      "  'train_samples_per_second': 1.541,\n",
      "  'train_steps_per_second': 0.77},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 1.6216524839401245,\n",
      "  'eval_in_peak_memory_gb': 3.9946370124816895,\n",
      "  'eval_in_runtime': 6.4182,\n",
      "  'eval_in_samples_per_second': 7.79,\n",
      "  'eval_in_steps_per_second': 3.895,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 1.2212331295013428,\n",
      "  'eval_out_peak_memory_gb': 3.9946370124816895,\n",
      "  'eval_out_runtime': 6.325,\n",
      "  'eval_out_samples_per_second': 7.905,\n",
      "  'eval_out_steps_per_second': 3.953,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.03237739261052319,\n",
      "  'train_peak_memory_gb': 6.502860069274902,\n",
      "  'train_runtime': 430.3843,\n",
      "  'train_samples_per_second': 1.487,\n",
      "  'train_steps_per_second': 0.744},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 1.865696907043457,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 4.3691,\n",
      "  'eval_in_samples_per_second': 11.444,\n",
      "  'eval_in_steps_per_second': 5.722,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.5900911092758179,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 4.2804,\n",
      "  'eval_out_samples_per_second': 11.681,\n",
      "  'eval_out_steps_per_second': 5.841,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.04938900653504443,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 395.197,\n",
      "  'train_samples_per_second': 1.619,\n",
      "  'train_steps_per_second': 0.81},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.68,\n",
      "  'eval_in_loss': 1.664461374282837,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 4.4025,\n",
      "  'eval_in_samples_per_second': 11.357,\n",
      "  'eval_in_steps_per_second': 5.679,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 3.5690457820892334,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 4.2931,\n",
      "  'eval_out_samples_per_second': 11.646,\n",
      "  'eval_out_steps_per_second': 5.823,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.06047771864373351,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 401.025,\n",
      "  'train_samples_per_second': 1.596,\n",
      "  'train_steps_per_second': 0.798},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 2.348245620727539,\n",
      "  'eval_in_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_in_runtime': 4.2848,\n",
      "  'eval_in_samples_per_second': 11.669,\n",
      "  'eval_in_steps_per_second': 5.835,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 1.181236982345581,\n",
      "  'eval_out_peak_memory_gb': 3.994629383087158,\n",
      "  'eval_out_runtime': 4.2854,\n",
      "  'eval_out_samples_per_second': 11.667,\n",
      "  'eval_out_steps_per_second': 5.834,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 596428015534080.0,\n",
      "  'train_loss': 0.07230718631873448,\n",
      "  'train_peak_memory_gb': 6.502852439880371,\n",
      "  'train_runtime': 413.5587,\n",
      "  'train_samples_per_second': 1.548,\n",
      "  'train_steps_per_second': 0.774}]\n",
      "Training histories:\n",
      "[{'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7361,\n",
      "                 0.7685,\n",
      "                 0.5733,\n",
      "                 0.6349,\n",
      "                 0.274,\n",
      "                 0.1973,\n",
      "                 0.1367,\n",
      "                 0.1348,\n",
      "                 0.0613,\n",
      "                 0.0396,\n",
      "                 0.0234,\n",
      "                 0.018,\n",
      "                 0.013,\n",
      "                 0.0069,\n",
      "                 0.0049,\n",
      "                 0.0038,\n",
      "                 0.002,\n",
      "                 0.0021,\n",
      "                 0.0013,\n",
      "                 0.0011,\n",
      "                 0.001,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.8267877697944641,\n",
      "               0.8300397992134094,\n",
      "               0.8409209251403809,\n",
      "               0.8566209077835083,\n",
      "               0.8797966241836548,\n",
      "               0.9213926196098328,\n",
      "               0.9711987376213074,\n",
      "               1.0215120315551758,\n",
      "               1.0704145431518555,\n",
      "               1.1186258792877197,\n",
      "               1.1633484363555908,\n",
      "               1.2090866565704346,\n",
      "               1.2444789409637451,\n",
      "               1.2770745754241943,\n",
      "               1.3096381425857544,\n",
      "               1.342052936553955,\n",
      "               1.3728138208389282,\n",
      "               1.404064416885376,\n",
      "               1.4327256679534912,\n",
      "               1.459144949913025,\n",
      "               1.4839811325073242,\n",
      "               1.5071686506271362,\n",
      "               1.5283960103988647,\n",
      "               1.5479590892791748,\n",
      "               1.5650933980941772,\n",
      "               1.5809974670410156,\n",
      "               1.5953266620635986,\n",
      "               1.6081393957138062,\n",
      "               1.6190000772476196,\n",
      "               1.6282228231430054,\n",
      "               1.6359392404556274,\n",
      "               1.6424610614776611,\n",
      "               1.6479839086532593,\n",
      "               1.652535080909729,\n",
      "               1.6563720703125,\n",
      "               1.6595484018325806,\n",
      "               1.6619884967803955,\n",
      "               1.6636362075805664,\n",
      "               1.6646673679351807,\n",
      "               1.665175199508667]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.5675,\n",
      "                 0.4702,\n",
      "                 0.3837,\n",
      "                 0.2837,\n",
      "                 0.1412,\n",
      "                 0.0856,\n",
      "                 0.0324,\n",
      "                 0.0122,\n",
      "                 0.0075,\n",
      "                 0.0038,\n",
      "                 0.0019,\n",
      "                 0.001,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.812256932258606,\n",
      "               0.8753525614738464,\n",
      "               0.9968677759170532,\n",
      "               1.1972845792770386,\n",
      "               1.4184110164642334,\n",
      "               1.650342583656311,\n",
      "               1.894822120666504,\n",
      "               2.1402533054351807,\n",
      "               2.3813652992248535,\n",
      "               2.6035315990448,\n",
      "               2.8068554401397705,\n",
      "               2.990813732147217,\n",
      "               3.151400327682495,\n",
      "               3.2944366931915283,\n",
      "               3.419875383377075,\n",
      "               3.528818130493164,\n",
      "               3.623657703399658,\n",
      "               3.7065742015838623,\n",
      "               3.7785487174987793,\n",
      "               3.841012477874756,\n",
      "               3.8952198028564453,\n",
      "               3.942526340484619,\n",
      "               3.9832630157470703,\n",
      "               4.018349647521973,\n",
      "               4.048525333404541,\n",
      "               4.074372291564941,\n",
      "               4.096364974975586,\n",
      "               4.115030288696289,\n",
      "               4.130856990814209,\n",
      "               4.144097328186035,\n",
      "               4.155091285705566,\n",
      "               4.1640825271606445,\n",
      "               4.171342372894287,\n",
      "               4.177074909210205,\n",
      "               4.1814727783203125,\n",
      "               4.184714317321777,\n",
      "               4.1869587898254395,\n",
      "               4.188340187072754,\n",
      "               4.1889753341674805]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7908,\n",
      "                 0.7862,\n",
      "                 0.6165,\n",
      "                 0.513,\n",
      "                 0.3152,\n",
      "                 0.1652,\n",
      "                 0.0761,\n",
      "                 0.0305,\n",
      "                 0.022,\n",
      "                 0.0115,\n",
      "                 0.0062,\n",
      "                 0.0029,\n",
      "                 0.0013,\n",
      "                 0.001,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.764984130859375,\n",
      "               0.7332131266593933,\n",
      "               0.7152761220932007,\n",
      "               0.7411553263664246,\n",
      "               0.8145602941513062,\n",
      "               0.9183288812637329,\n",
      "               1.039482831954956,\n",
      "               1.1682168245315552,\n",
      "               1.3034803867340088,\n",
      "               1.4407060146331787,\n",
      "               1.570549726486206,\n",
      "               1.6881330013275146,\n",
      "               1.7931573390960693,\n",
      "               1.886530876159668,\n",
      "               1.9684518575668335,\n",
      "               2.041529417037964,\n",
      "               2.1070358753204346,\n",
      "               2.1637871265411377,\n",
      "               2.2139205932617188,\n",
      "               2.2577645778656006,\n",
      "               2.2958638668060303,\n",
      "               2.329249382019043,\n",
      "               2.3583805561065674,\n",
      "               2.383805751800537,\n",
      "               2.405661106109619,\n",
      "               2.4245314598083496,\n",
      "               2.440764904022217,\n",
      "               2.454598903656006,\n",
      "               2.466315507888794,\n",
      "               2.4762444496154785,\n",
      "               2.4845030307769775,\n",
      "               2.491312026977539,\n",
      "               2.4967892169952393,\n",
      "               2.5011909008026123,\n",
      "               2.504635810852051,\n",
      "               2.507189989089966,\n",
      "               2.508984327316284,\n",
      "               2.510096549987793,\n",
      "               2.510629653930664]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.2255,\n",
      "                 1.7024,\n",
      "                 1.4009,\n",
      "                 1.0091,\n",
      "                 0.5277,\n",
      "                 0.2622,\n",
      "                 0.1566,\n",
      "                 0.075,\n",
      "                 0.0538,\n",
      "                 0.0204,\n",
      "                 0.011,\n",
      "                 0.0059,\n",
      "                 0.0022,\n",
      "                 0.002,\n",
      "                 0.0011,\n",
      "                 0.0005,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7652134299278259,\n",
      "               0.7321997284889221,\n",
      "               0.7048900127410889,\n",
      "               0.7086255550384521,\n",
      "               0.743924617767334,\n",
      "               0.8078670501708984,\n",
      "               0.8936353921890259,\n",
      "               0.995313823223114,\n",
      "               1.1094757318496704,\n",
      "               1.2327239513397217,\n",
      "               1.3598105907440186,\n",
      "               1.4827085733413696,\n",
      "               1.5979865789413452,\n",
      "               1.702487587928772,\n",
      "               1.7991809844970703,\n",
      "               1.8870508670806885,\n",
      "               1.9655048847198486,\n",
      "               2.0343730449676514,\n",
      "               2.094463348388672,\n",
      "               2.147395372390747,\n",
      "               2.19423508644104,\n",
      "               2.234867811203003,\n",
      "               2.2700603008270264,\n",
      "               2.300506591796875,\n",
      "               2.326875686645508,\n",
      "               2.3495519161224365,\n",
      "               2.3687844276428223,\n",
      "               2.3851075172424316,\n",
      "               2.3988068103790283,\n",
      "               2.4102835655212402,\n",
      "               2.419771909713745,\n",
      "               2.4275312423706055,\n",
      "               2.4337728023529053,\n",
      "               2.4386932849884033,\n",
      "               2.4424610137939453,\n",
      "               2.445249080657959,\n",
      "               2.4471845626831055,\n",
      "               2.4483859539031982,\n",
      "               2.448946475982666]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.93,\n",
      "                 0.9718,\n",
      "                 0.8304,\n",
      "                 0.6083,\n",
      "                 0.4669,\n",
      "                 0.286,\n",
      "                 0.1673,\n",
      "                 0.0842,\n",
      "                 0.0643,\n",
      "                 0.0498,\n",
      "                 0.0239,\n",
      "                 0.0162,\n",
      "                 0.0098,\n",
      "                 0.0058,\n",
      "                 0.0052,\n",
      "                 0.0044,\n",
      "                 0.0016,\n",
      "                 0.0014,\n",
      "                 0.0007,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7816917300224304,\n",
      "               0.766732394695282,\n",
      "               0.7480637431144714,\n",
      "               0.7339785695075989,\n",
      "               0.7266258001327515,\n",
      "               0.7244263887405396,\n",
      "               0.7276387214660645,\n",
      "               0.7354528307914734,\n",
      "               0.7428425550460815,\n",
      "               0.7483415007591248,\n",
      "               0.7529385685920715,\n",
      "               0.7584267854690552,\n",
      "               0.7658635377883911,\n",
      "               0.774439811706543,\n",
      "               0.7830411195755005,\n",
      "               0.7919566631317139,\n",
      "               0.8001310229301453,\n",
      "               0.8071626424789429,\n",
      "               0.8135960698127747,\n",
      "               0.8192504644393921,\n",
      "               0.8242979049682617,\n",
      "               0.8288084864616394,\n",
      "               0.8329544067382812,\n",
      "               0.8366186022758484,\n",
      "               0.8399189114570618,\n",
      "               0.8427885174751282,\n",
      "               0.8451407551765442,\n",
      "               0.8471498489379883,\n",
      "               0.8488557934761047,\n",
      "               0.8503021001815796,\n",
      "               0.8515257835388184,\n",
      "               0.8525297045707703,\n",
      "               0.8533362150192261,\n",
      "               0.8539636731147766,\n",
      "               0.8544540405273438,\n",
      "               0.8548223376274109,\n",
      "               0.8550798296928406,\n",
      "               0.8552333116531372,\n",
      "               0.8553041219711304]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6158,\n",
      "                 0.7193,\n",
      "                 0.7567,\n",
      "                 0.5247,\n",
      "                 0.3771,\n",
      "                 0.2014,\n",
      "                 0.1681,\n",
      "                 0.1256,\n",
      "                 0.0624,\n",
      "                 0.0335,\n",
      "                 0.0197,\n",
      "                 0.0109,\n",
      "                 0.0085,\n",
      "                 0.0045,\n",
      "                 0.003,\n",
      "                 0.0029,\n",
      "                 0.0019,\n",
      "                 0.0013,\n",
      "                 0.001,\n",
      "                 0.0014,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7873801589012146,\n",
      "               0.793242335319519,\n",
      "               0.7978677749633789,\n",
      "               0.8031063079833984,\n",
      "               0.8089232444763184,\n",
      "               0.8169814944267273,\n",
      "               0.8216306567192078,\n",
      "               0.8326684832572937,\n",
      "               0.8424814343452454,\n",
      "               0.8571304082870483,\n",
      "               0.873896598815918,\n",
      "               0.8971682786941528,\n",
      "               0.9251161813735962,\n",
      "               0.9544709324836731,\n",
      "               0.9845985174179077,\n",
      "               1.0146138668060303,\n",
      "               1.0426198244094849,\n",
      "               1.0701240301132202,\n",
      "               1.0974632501602173,\n",
      "               1.122791051864624,\n",
      "               1.1449992656707764,\n",
      "               1.1642345190048218,\n",
      "               1.1811078786849976,\n",
      "               1.1957013607025146,\n",
      "               1.208409070968628,\n",
      "               1.2194730043411255,\n",
      "               1.2290478944778442,\n",
      "               1.2373219728469849,\n",
      "               1.2442471981048584,\n",
      "               1.2502105236053467,\n",
      "               1.2551870346069336,\n",
      "               1.259225606918335,\n",
      "               1.2624651193618774,\n",
      "               1.2650372982025146,\n",
      "               1.2670447826385498,\n",
      "               1.268489122390747,\n",
      "               1.2695000171661377,\n",
      "               1.2701104879379272,\n",
      "               1.2703958749771118]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.1565,\n",
      "                 1.0025,\n",
      "                 0.966,\n",
      "                 0.6273,\n",
      "                 0.3937,\n",
      "                 0.1706,\n",
      "                 0.0791,\n",
      "                 0.0425,\n",
      "                 0.0166,\n",
      "                 0.011,\n",
      "                 0.0048,\n",
      "                 0.0024,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.766907274723053,\n",
      "               0.7382780313491821,\n",
      "               0.7228072881698608,\n",
      "               0.7479311227798462,\n",
      "               0.8183452486991882,\n",
      "               0.919075608253479,\n",
      "               1.0391746759414673,\n",
      "               1.1674230098724365,\n",
      "               1.3012243509292603,\n",
      "               1.4377095699310303,\n",
      "               1.5675859451293945,\n",
      "               1.6846097707748413,\n",
      "               1.7902553081512451,\n",
      "               1.8860838413238525,\n",
      "               1.9720592498779297,\n",
      "               2.0476014614105225,\n",
      "               2.1139144897460938,\n",
      "               2.1725077629089355,\n",
      "               2.223254919052124,\n",
      "               2.267385959625244,\n",
      "               2.3062942028045654,\n",
      "               2.339883327484131,\n",
      "               2.369037389755249,\n",
      "               2.3942153453826904,\n",
      "               2.415844440460205,\n",
      "               2.4343132972717285,\n",
      "               2.4500861167907715,\n",
      "               2.4634101390838623,\n",
      "               2.4746146202087402,\n",
      "               2.4839625358581543,\n",
      "               2.4916751384735107,\n",
      "               2.4979987144470215,\n",
      "               2.5030581951141357,\n",
      "               2.507045269012451,\n",
      "               2.5101046562194824,\n",
      "               2.512352705001831,\n",
      "               2.5139052867889404,\n",
      "               2.5148613452911377,\n",
      "               2.5153069496154785]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6007,\n",
      "                 0.663,\n",
      "                 0.547,\n",
      "                 0.4156,\n",
      "                 0.2587,\n",
      "                 0.154,\n",
      "                 0.0874,\n",
      "                 0.0534,\n",
      "                 0.0353,\n",
      "                 0.0188,\n",
      "                 0.0114,\n",
      "                 0.0071,\n",
      "                 0.0033,\n",
      "                 0.0022,\n",
      "                 0.0018,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7907788157463074,\n",
      "               0.7967157363891602,\n",
      "               0.8037708401679993,\n",
      "               0.8157345056533813,\n",
      "               0.8256133198738098,\n",
      "               0.8388909101486206,\n",
      "               0.8540444374084473,\n",
      "               0.8757921457290649,\n",
      "               0.9014674425125122,\n",
      "               0.924892246723175,\n",
      "               0.9486373662948608,\n",
      "               0.9726930856704712,\n",
      "               0.9966325759887695,\n",
      "               1.019797682762146,\n",
      "               1.041774034500122,\n",
      "               1.062341332435608,\n",
      "               1.0813610553741455,\n",
      "               1.0983649492263794,\n",
      "               1.113726019859314,\n",
      "               1.1267364025115967,\n",
      "               1.1377853155136108,\n",
      "               1.1474201679229736,\n",
      "               1.1559326648712158,\n",
      "               1.1634246110916138,\n",
      "               1.1697518825531006,\n",
      "               1.1751445531845093,\n",
      "               1.1798765659332275,\n",
      "               1.184040904045105,\n",
      "               1.1875646114349365,\n",
      "               1.1905333995819092,\n",
      "               1.1929690837860107,\n",
      "               1.1949613094329834,\n",
      "               1.1965558528900146,\n",
      "               1.1978082656860352,\n",
      "               1.1987632513046265,\n",
      "               1.1994880437850952,\n",
      "               1.199994683265686,\n",
      "               1.2002966403961182,\n",
      "               1.2004337310791016]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.8625,\n",
      "                 0.7891,\n",
      "                 0.6308,\n",
      "                 0.4635,\n",
      "                 0.2684,\n",
      "                 0.1535,\n",
      "                 0.0639,\n",
      "                 0.032,\n",
      "                 0.0172,\n",
      "                 0.01,\n",
      "                 0.0051,\n",
      "                 0.0029,\n",
      "                 0.0022,\n",
      "                 0.001,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7663643956184387,\n",
      "               0.7359959483146667,\n",
      "               0.7167975306510925,\n",
      "               0.7416424751281738,\n",
      "               0.8106572031974792,\n",
      "               0.9095838665962219,\n",
      "               1.0251638889312744,\n",
      "               1.148980736732483,\n",
      "               1.2760498523712158,\n",
      "               1.4022226333618164,\n",
      "               1.5236966609954834,\n",
      "               1.6363986730575562,\n",
      "               1.7387313842773438,\n",
      "               1.8298413753509521,\n",
      "               1.91190505027771,\n",
      "               1.9855339527130127,\n",
      "               2.050469160079956,\n",
      "               2.1080029010772705,\n",
      "               2.15816068649292,\n",
      "               2.202007293701172,\n",
      "               2.240187883377075,\n",
      "               2.273401975631714,\n",
      "               2.30218505859375,\n",
      "               2.3271899223327637,\n",
      "               2.3487980365753174,\n",
      "               2.3672375679016113,\n",
      "               2.3830204010009766,\n",
      "               2.396533250808716,\n",
      "               2.407932758331299,\n",
      "               2.4174885749816895,\n",
      "               2.4254565238952637,\n",
      "               2.4320247173309326,\n",
      "               2.437328577041626,\n",
      "               2.4415342807769775,\n",
      "               2.444789171218872,\n",
      "               2.4471969604492188,\n",
      "               2.4488773345947266,\n",
      "               2.4499237537384033,\n",
      "               2.450411081314087]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7865,\n",
      "                 0.592,\n",
      "                 0.6152,\n",
      "                 0.4351,\n",
      "                 0.1785,\n",
      "                 0.0763,\n",
      "                 0.0337,\n",
      "                 0.0156,\n",
      "                 0.0063,\n",
      "                 0.0035,\n",
      "                 0.0016,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.8105214238166809,\n",
      "               0.8659403920173645,\n",
      "               0.9723847508430481,\n",
      "               1.148678183555603,\n",
      "               1.3496220111846924,\n",
      "               1.5641103982925415,\n",
      "               1.784409761428833,\n",
      "               1.9996192455291748,\n",
      "               2.2091801166534424,\n",
      "               2.4034178256988525,\n",
      "               2.5809593200683594,\n",
      "               2.741811752319336,\n",
      "               2.8869152069091797,\n",
      "               3.0172293186187744,\n",
      "               3.1315529346466064,\n",
      "               3.2328476905822754,\n",
      "               3.3219428062438965,\n",
      "               3.400158643722534,\n",
      "               3.468315601348877,\n",
      "               3.52783203125,\n",
      "               3.579646348953247,\n",
      "               3.624600648880005,\n",
      "               3.663691997528076,\n",
      "               3.697441577911377,\n",
      "               3.7265708446502686,\n",
      "               3.7514986991882324,\n",
      "               3.772749423980713,\n",
      "               3.7907700538635254,\n",
      "               3.805943727493286,\n",
      "               3.818627119064331,\n",
      "               3.8291168212890625,\n",
      "               3.8377017974853516,\n",
      "               3.844622850418091,\n",
      "               3.850085735321045,\n",
      "               3.854304552078247,\n",
      "               3.857422351837158,\n",
      "               3.859577178955078,\n",
      "               3.860902786254883,\n",
      "               3.8615176677703857]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9038,\n",
      "                 0.7601,\n",
      "                 0.6592,\n",
      "                 0.5498,\n",
      "                 0.3513,\n",
      "                 0.1746,\n",
      "                 0.1042,\n",
      "                 0.0737,\n",
      "                 0.0353,\n",
      "                 0.0221,\n",
      "                 0.0145,\n",
      "                 0.0082,\n",
      "                 0.0041,\n",
      "                 0.0032,\n",
      "                 0.0021,\n",
      "                 0.0014,\n",
      "                 0.0013,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7727473974227905,\n",
      "               0.7485942244529724,\n",
      "               0.7275824546813965,\n",
      "               0.7228306531906128,\n",
      "               0.7443281412124634,\n",
      "               0.7859660387039185,\n",
      "               0.8460680246353149,\n",
      "               0.9150875806808472,\n",
      "               0.9932276606559753,\n",
      "               1.0742905139923096,\n",
      "               1.1547702550888062,\n",
      "               1.2331125736236572,\n",
      "               1.3062984943389893,\n",
      "               1.372833013534546,\n",
      "               1.431304693222046,\n",
      "               1.4845222234725952,\n",
      "               1.5325520038604736,\n",
      "               1.5754673480987549,\n",
      "               1.613221526145935,\n",
      "               1.6461637020111084,\n",
      "               1.6749496459960938,\n",
      "               1.7000439167022705,\n",
      "               1.7218977212905884,\n",
      "               1.7408632040023804,\n",
      "               1.757312536239624,\n",
      "               1.7715450525283813,\n",
      "               1.7838770151138306,\n",
      "               1.7943804264068604,\n",
      "               1.8032974004745483,\n",
      "               1.8107945919036865,\n",
      "               1.8171117305755615,\n",
      "               1.8223241567611694,\n",
      "               1.826572060585022,\n",
      "               1.8299407958984375,\n",
      "               1.8325634002685547,\n",
      "               1.834511399269104,\n",
      "               1.8358970880508423,\n",
      "               1.8367550373077393,\n",
      "               1.8371589183807373]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.041,\n",
      "                 0.9831,\n",
      "                 0.841,\n",
      "                 0.6486,\n",
      "                 0.3982,\n",
      "                 0.2474,\n",
      "                 0.1634,\n",
      "                 0.1033,\n",
      "                 0.0662,\n",
      "                 0.0309,\n",
      "                 0.0244,\n",
      "                 0.0138,\n",
      "                 0.0096,\n",
      "                 0.0057,\n",
      "                 0.0048,\n",
      "                 0.0029,\n",
      "                 0.0023,\n",
      "                 0.0018,\n",
      "                 0.0012,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7606233358383179,\n",
      "               0.7243217825889587,\n",
      "               0.703484058380127,\n",
      "               0.7318495512008667,\n",
      "               0.7944996953010559,\n",
      "               0.867313027381897,\n",
      "               0.9377931356430054,\n",
      "               1.0051064491271973,\n",
      "               1.0668983459472656,\n",
      "               1.1296824216842651,\n",
      "               1.1921098232269287,\n",
      "               1.2545956373214722,\n",
      "               1.3152587413787842,\n",
      "               1.3721529245376587,\n",
      "               1.4234015941619873,\n",
      "               1.471478819847107,\n",
      "               1.5171751976013184,\n",
      "               1.5580648183822632,\n",
      "               1.594835877418518,\n",
      "               1.6267802715301514,\n",
      "               1.655191421508789,\n",
      "               1.6810805797576904,\n",
      "               1.703385353088379,\n",
      "               1.7228374481201172,\n",
      "               1.7398312091827393,\n",
      "               1.7549079656600952,\n",
      "               1.768311858177185,\n",
      "               1.77992844581604,\n",
      "               1.7898914813995361,\n",
      "               1.7983620166778564,\n",
      "               1.805619478225708,\n",
      "               1.8118069171905518,\n",
      "               1.8169841766357422,\n",
      "               1.8212112188339233,\n",
      "               1.8245525360107422,\n",
      "               1.827061653137207,\n",
      "               1.8288497924804688,\n",
      "               1.829965353012085,\n",
      "               1.8305011987686157]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.0821,\n",
      "                 0.9488,\n",
      "                 0.8737,\n",
      "                 0.5682,\n",
      "                 0.4059,\n",
      "                 0.2595,\n",
      "                 0.118,\n",
      "                 0.0717,\n",
      "                 0.0429,\n",
      "                 0.0218,\n",
      "                 0.0139,\n",
      "                 0.0101,\n",
      "                 0.005,\n",
      "                 0.0034,\n",
      "                 0.0021,\n",
      "                 0.0016,\n",
      "                 0.0014,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7662221193313599,\n",
      "               0.7332608103752136,\n",
      "               0.7112067341804504,\n",
      "               0.7293950319290161,\n",
      "               0.7839256525039673,\n",
      "               0.8627597689628601,\n",
      "               0.9517404437065125,\n",
      "               1.0451291799545288,\n",
      "               1.1392498016357422,\n",
      "               1.230816125869751,\n",
      "               1.3263453245162964,\n",
      "               1.4168983697891235,\n",
      "               1.5021597146987915,\n",
      "               1.581491470336914,\n",
      "               1.6541128158569336,\n",
      "               1.7193901538848877,\n",
      "               1.7774683237075806,\n",
      "               1.8280189037322998,\n",
      "               1.8726190328598022,\n",
      "               1.9113521575927734,\n",
      "               1.9456682205200195,\n",
      "               1.9758071899414062,\n",
      "               2.0023417472839355,\n",
      "               2.0252203941345215,\n",
      "               2.044915199279785,\n",
      "               2.0619215965270996,\n",
      "               2.0764882564544678,\n",
      "               2.0888800621032715,\n",
      "               2.099409580230713,\n",
      "               2.108170986175537,\n",
      "               2.115478038787842,\n",
      "               2.121507167816162,\n",
      "               2.1263890266418457,\n",
      "               2.1302437782287598,\n",
      "               2.133209228515625,\n",
      "               2.1353955268859863,\n",
      "               2.13692307472229,\n",
      "               2.137880802154541,\n",
      "               2.138333559036255]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9071,\n",
      "                 0.8778,\n",
      "                 0.799,\n",
      "                 0.6443,\n",
      "                 0.4996,\n",
      "                 0.2994,\n",
      "                 0.1936,\n",
      "                 0.1244,\n",
      "                 0.0916,\n",
      "                 0.0568,\n",
      "                 0.035,\n",
      "                 0.0206,\n",
      "                 0.0145,\n",
      "                 0.0084,\n",
      "                 0.0057,\n",
      "                 0.0049,\n",
      "                 0.0032,\n",
      "                 0.0023,\n",
      "                 0.0015,\n",
      "                 0.0015,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0008,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7758800387382507,\n",
      "               0.7586281895637512,\n",
      "               0.7480438947677612,\n",
      "               0.7587819695472717,\n",
      "               0.7871350049972534,\n",
      "               0.8200355768203735,\n",
      "               0.8503829836845398,\n",
      "               0.8751989603042603,\n",
      "               0.8952320218086243,\n",
      "               0.9112316966056824,\n",
      "               0.9237531423568726,\n",
      "               0.9366044998168945,\n",
      "               0.9503926038742065,\n",
      "               0.9654864072799683,\n",
      "               0.9782926440238953,\n",
      "               0.9899822473526001,\n",
      "               1.000906229019165,\n",
      "               1.0106337070465088,\n",
      "               1.0198951959609985,\n",
      "               1.028196096420288,\n",
      "               1.0360605716705322,\n",
      "               1.0440399646759033,\n",
      "               1.0511564016342163,\n",
      "               1.057360291481018,\n",
      "               1.0630147457122803,\n",
      "               1.0677392482757568,\n",
      "               1.071775197982788,\n",
      "               1.0753583908081055,\n",
      "               1.0794299840927124,\n",
      "               1.0829598903656006,\n",
      "               1.085911750793457,\n",
      "               1.0883378982543945,\n",
      "               1.090375304222107,\n",
      "               1.0919811725616455,\n",
      "               1.0932353734970093,\n",
      "               1.0941985845565796,\n",
      "               1.0948904752731323,\n",
      "               1.0953283309936523,\n",
      "               1.09554123878479]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.6575,\n",
      "                 0.7386,\n",
      "                 0.5771,\n",
      "                 0.5169,\n",
      "                 0.4056,\n",
      "                 0.262,\n",
      "                 0.1775,\n",
      "                 0.1111,\n",
      "                 0.0859,\n",
      "                 0.0484,\n",
      "                 0.0491,\n",
      "                 0.0203,\n",
      "                 0.0137,\n",
      "                 0.0088,\n",
      "                 0.0056,\n",
      "                 0.004,\n",
      "                 0.0026,\n",
      "                 0.002,\n",
      "                 0.0017,\n",
      "                 0.001,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7980443239212036,\n",
      "               0.8225522041320801,\n",
      "               0.8633192181587219,\n",
      "               0.9212757349014282,\n",
      "               0.9736142158508301,\n",
      "               1.0316030979156494,\n",
      "               1.098488211631775,\n",
      "               1.170811414718628,\n",
      "               1.2480741739273071,\n",
      "               1.3239387273788452,\n",
      "               1.4050034284591675,\n",
      "               1.4916683435440063,\n",
      "               1.5772278308868408,\n",
      "               1.6645408868789673,\n",
      "               1.750788927078247,\n",
      "               1.833112359046936,\n",
      "               1.9092366695404053,\n",
      "               1.979278564453125,\n",
      "               2.0426547527313232,\n",
      "               2.0992932319641113,\n",
      "               2.1498641967773438,\n",
      "               2.195343255996704,\n",
      "               2.235421657562256,\n",
      "               2.2706973552703857,\n",
      "               2.301243305206299,\n",
      "               2.327816963195801,\n",
      "               2.351048707962036,\n",
      "               2.3711647987365723,\n",
      "               2.388399600982666,\n",
      "               2.4029834270477295,\n",
      "               2.415374279022217,\n",
      "               2.4256300926208496,\n",
      "               2.433994770050049,\n",
      "               2.44071888923645,\n",
      "               2.4460084438323975,\n",
      "               2.4500362873077393,\n",
      "               2.4528748989105225,\n",
      "               2.4546568393707275,\n",
      "               2.455498218536377]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.5525,\n",
      "                 0.5574,\n",
      "                 0.553,\n",
      "                 0.3805,\n",
      "                 0.3162,\n",
      "                 0.2094,\n",
      "                 0.1045,\n",
      "                 0.0815,\n",
      "                 0.0558,\n",
      "                 0.0299,\n",
      "                 0.0204,\n",
      "                 0.014,\n",
      "                 0.0083,\n",
      "                 0.0047,\n",
      "                 0.003,\n",
      "                 0.0025,\n",
      "                 0.0015,\n",
      "                 0.0013,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.8005598783493042,\n",
      "               0.832013726234436,\n",
      "               0.8845236897468567,\n",
      "               0.937303364276886,\n",
      "               0.9722644686698914,\n",
      "               1.0032497644424438,\n",
      "               1.0276745557785034,\n",
      "               1.058732509613037,\n",
      "               1.0935126543045044,\n",
      "               1.1374988555908203,\n",
      "               1.1802223920822144,\n",
      "               1.2252073287963867,\n",
      "               1.2679016590118408,\n",
      "               1.3107054233551025,\n",
      "               1.3536375761032104,\n",
      "               1.395592451095581,\n",
      "               1.435143232345581,\n",
      "               1.472335934638977,\n",
      "               1.507110834121704,\n",
      "               1.5391590595245361,\n",
      "               1.568901538848877,\n",
      "               1.5958168506622314,\n",
      "               1.6199829578399658,\n",
      "               1.6413524150848389,\n",
      "               1.6601508855819702,\n",
      "               1.6763519048690796,\n",
      "               1.6905027627944946,\n",
      "               1.702998161315918,\n",
      "               1.713884711265564,\n",
      "               1.7231166362762451,\n",
      "               1.7308237552642822,\n",
      "               1.7372446060180664,\n",
      "               1.7424676418304443,\n",
      "               1.7466623783111572,\n",
      "               1.7499029636383057,\n",
      "               1.7523161172866821,\n",
      "               1.7540156841278076,\n",
      "               1.7550907135009766,\n",
      "               1.755599021911621]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9974,\n",
      "                 0.9491,\n",
      "                 0.9088,\n",
      "                 0.6839,\n",
      "                 0.5659,\n",
      "                 0.3561,\n",
      "                 0.286,\n",
      "                 0.1851,\n",
      "                 0.1145,\n",
      "                 0.0986,\n",
      "                 0.0732,\n",
      "                 0.0406,\n",
      "                 0.0376,\n",
      "                 0.0167,\n",
      "                 0.0159,\n",
      "                 0.0102,\n",
      "                 0.007,\n",
      "                 0.0069,\n",
      "                 0.0038,\n",
      "                 0.0034,\n",
      "                 0.0019,\n",
      "                 0.0015,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0009,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.773567795753479,\n",
      "               0.7494081258773804,\n",
      "               0.7215946316719055,\n",
      "               0.703210175037384,\n",
      "               0.6921218633651733,\n",
      "               0.6869825720787048,\n",
      "               0.6823717355728149,\n",
      "               0.675677478313446,\n",
      "               0.6683819890022278,\n",
      "               0.660008430480957,\n",
      "               0.6485714912414551,\n",
      "               0.6373728513717651,\n",
      "               0.6254833340644836,\n",
      "               0.6120642423629761,\n",
      "               0.6002603769302368,\n",
      "               0.589642345905304,\n",
      "               0.5799037218093872,\n",
      "               0.5711508989334106,\n",
      "               0.563583254814148,\n",
      "               0.5568991899490356,\n",
      "               0.5512627363204956,\n",
      "               0.5464193820953369,\n",
      "               0.5421536564826965,\n",
      "               0.5384378433227539,\n",
      "               0.5353361368179321,\n",
      "               0.532798171043396,\n",
      "               0.53069007396698,\n",
      "               0.528954029083252,\n",
      "               0.5274501442909241,\n",
      "               0.5261953473091125,\n",
      "               0.5251741409301758,\n",
      "               0.5243421196937561,\n",
      "               0.5236794948577881,\n",
      "               0.5231789946556091,\n",
      "               0.5227957963943481,\n",
      "               0.5225151777267456,\n",
      "               0.5223178863525391,\n",
      "               0.5221981406211853,\n",
      "               0.5221457481384277]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7516,\n",
      "                 0.6811,\n",
      "                 0.6116,\n",
      "                 0.4744,\n",
      "                 0.3658,\n",
      "                 0.2078,\n",
      "                 0.1249,\n",
      "                 0.0648,\n",
      "                 0.0446,\n",
      "                 0.029,\n",
      "                 0.02,\n",
      "                 0.0113,\n",
      "                 0.0082,\n",
      "                 0.0047,\n",
      "                 0.0033,\n",
      "                 0.003,\n",
      "                 0.002,\n",
      "                 0.0013,\n",
      "                 0.001,\n",
      "                 0.0007,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7805076837539673,\n",
      "               0.7708190083503723,\n",
      "               0.7594525814056396,\n",
      "               0.7477666139602661,\n",
      "               0.736445963382721,\n",
      "               0.7272969484329224,\n",
      "               0.7239195704460144,\n",
      "               0.7236801981925964,\n",
      "               0.7300699949264526,\n",
      "               0.7402889132499695,\n",
      "               0.7521141171455383,\n",
      "               0.7653913497924805,\n",
      "               0.7775982022285461,\n",
      "               0.790365993976593,\n",
      "               0.8032042384147644,\n",
      "               0.8158859014511108,\n",
      "               0.8273859024047852,\n",
      "               0.8377259969711304,\n",
      "               0.8474170565605164,\n",
      "               0.8567956686019897,\n",
      "               0.8650766611099243,\n",
      "               0.8723092079162598,\n",
      "               0.8783683776855469,\n",
      "               0.8835185766220093,\n",
      "               0.8879737854003906,\n",
      "               0.8919588923454285,\n",
      "               0.8954533338546753,\n",
      "               0.8984926342964172,\n",
      "               0.9011541604995728,\n",
      "               0.9034072160720825,\n",
      "               0.9053136110305786,\n",
      "               0.9068493843078613,\n",
      "               0.9080791473388672,\n",
      "               0.9090935587882996,\n",
      "               0.9098914861679077,\n",
      "               0.9104810953140259,\n",
      "               0.9108996391296387,\n",
      "               0.9111482501029968,\n",
      "               0.9112647175788879]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.4022,\n",
      "                 0.4478,\n",
      "                 0.4214,\n",
      "                 0.2955,\n",
      "                 0.2409,\n",
      "                 0.1405,\n",
      "                 0.0996,\n",
      "                 0.0676,\n",
      "                 0.0403,\n",
      "                 0.0235,\n",
      "                 0.0125,\n",
      "                 0.0089,\n",
      "                 0.0052,\n",
      "                 0.0033,\n",
      "                 0.0027,\n",
      "                 0.0015,\n",
      "                 0.0012,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.8045479655265808,\n",
      "               0.8452679514884949,\n",
      "               0.9196737408638,\n",
      "               1.0305185317993164,\n",
      "               1.149034023284912,\n",
      "               1.2655903100967407,\n",
      "               1.3730027675628662,\n",
      "               1.4791550636291504,\n",
      "               1.5885307788848877,\n",
      "               1.6986987590789795,\n",
      "               1.8151094913482666,\n",
      "               1.9309221506118774,\n",
      "               2.0405213832855225,\n",
      "               2.144251823425293,\n",
      "               2.2383594512939453,\n",
      "               2.3221595287323,\n",
      "               2.397839307785034,\n",
      "               2.4681663513183594,\n",
      "               2.532011032104492,\n",
      "               2.588320016860962,\n",
      "               2.638507127761841,\n",
      "               2.683157205581665,\n",
      "               2.7226738929748535,\n",
      "               2.7575905323028564,\n",
      "               2.7875022888183594,\n",
      "               2.8134121894836426,\n",
      "               2.835883617401123,\n",
      "               2.8552300930023193,\n",
      "               2.8717081546783447,\n",
      "               2.8858437538146973,\n",
      "               2.8977065086364746,\n",
      "               2.9073665142059326,\n",
      "               2.915282726287842,\n",
      "               2.9216794967651367,\n",
      "               2.9266204833984375,\n",
      "               2.9302921295166016,\n",
      "               2.9329466819763184,\n",
      "               2.934581756591797,\n",
      "               2.935330867767334]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7542,\n",
      "                 0.637,\n",
      "                 0.6403,\n",
      "                 0.4909,\n",
      "                 0.3598,\n",
      "                 0.1996,\n",
      "                 0.1547,\n",
      "                 0.0901,\n",
      "                 0.056,\n",
      "                 0.0368,\n",
      "                 0.0222,\n",
      "                 0.0141,\n",
      "                 0.0096,\n",
      "                 0.0064,\n",
      "                 0.0103,\n",
      "                 0.0036,\n",
      "                 0.002,\n",
      "                 0.0016,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7952207326889038,\n",
      "               0.8163726925849915,\n",
      "               0.8488979339599609,\n",
      "               0.8893755078315735,\n",
      "               0.9372594952583313,\n",
      "               0.9835230112075806,\n",
      "               1.0412683486938477,\n",
      "               1.1088528633117676,\n",
      "               1.1889456510543823,\n",
      "               1.283172845840454,\n",
      "               1.3909300565719604,\n",
      "               1.503437876701355,\n",
      "               1.6190379858016968,\n",
      "               1.7228370904922485,\n",
      "               1.8245664834976196,\n",
      "               1.9195373058319092,\n",
      "               2.0062570571899414,\n",
      "               2.0861196517944336,\n",
      "               2.1582283973693848,\n",
      "               2.2235958576202393,\n",
      "               2.2820675373077393,\n",
      "               2.3337721824645996,\n",
      "               2.3796496391296387,\n",
      "               2.419922113418579,\n",
      "               2.4550700187683105,\n",
      "               2.485724687576294,\n",
      "               2.512183666229248,\n",
      "               2.5349018573760986,\n",
      "               2.554166078567505,\n",
      "               2.570406436920166,\n",
      "               2.5839593410491943,\n",
      "               2.5951645374298096,\n",
      "               2.604159116744995,\n",
      "               2.6113028526306152,\n",
      "               2.616816759109497,\n",
      "               2.6209280490875244,\n",
      "               2.623782157897949,\n",
      "               2.6255440711975098,\n",
      "               2.626375913619995]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7535,\n",
      "                 0.8206,\n",
      "                 0.7266,\n",
      "                 0.6104,\n",
      "                 0.5521,\n",
      "                 0.4128,\n",
      "                 0.3306,\n",
      "                 0.252,\n",
      "                 0.1495,\n",
      "                 0.1194,\n",
      "                 0.0953,\n",
      "                 0.0738,\n",
      "                 0.0472,\n",
      "                 0.0353,\n",
      "                 0.0268,\n",
      "                 0.0205,\n",
      "                 0.0136,\n",
      "                 0.011,\n",
      "                 0.0079,\n",
      "                 0.0055,\n",
      "                 0.0044,\n",
      "                 0.0043,\n",
      "                 0.0031,\n",
      "                 0.0024,\n",
      "                 0.0023,\n",
      "                 0.0021,\n",
      "                 0.0016,\n",
      "                 0.0015,\n",
      "                 0.0012,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.001,\n",
      "                 0.0009,\n",
      "                 0.001,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0009],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7777426838874817,\n",
      "               0.757010817527771,\n",
      "               0.7275800704956055,\n",
      "               0.6861135959625244,\n",
      "               0.6466372609138489,\n",
      "               0.611291766166687,\n",
      "               0.5772732496261597,\n",
      "               0.549885630607605,\n",
      "               0.5265189409255981,\n",
      "               0.507043719291687,\n",
      "               0.4958074688911438,\n",
      "               0.48725661635398865,\n",
      "               0.47649335861206055,\n",
      "               0.46601468324661255,\n",
      "               0.4526510238647461,\n",
      "               0.4385736882686615,\n",
      "               0.4241262972354889,\n",
      "               0.41134053468704224,\n",
      "               0.39963167905807495,\n",
      "               0.3896966278553009,\n",
      "               0.38084059953689575,\n",
      "               0.3729630410671234,\n",
      "               0.36602064967155457,\n",
      "               0.3597792983055115,\n",
      "               0.3547195792198181,\n",
      "               0.35037311911582947,\n",
      "               0.34664636850357056,\n",
      "               0.3435536324977875,\n",
      "               0.34083160758018494,\n",
      "               0.3385472595691681,\n",
      "               0.33665335178375244,\n",
      "               0.33518439531326294,\n",
      "               0.3340303301811218,\n",
      "               0.33313900232315063,\n",
      "               0.3325008153915405,\n",
      "               0.3320331275463104,\n",
      "               0.33171212673187256,\n",
      "               0.3315126299858093,\n",
      "               0.331423282623291]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.6736,\n",
      "                 0.7461,\n",
      "                 0.6659,\n",
      "                 0.5332,\n",
      "                 0.4889,\n",
      "                 0.3454,\n",
      "                 0.2841,\n",
      "                 0.2314,\n",
      "                 0.1518,\n",
      "                 0.1132,\n",
      "                 0.0903,\n",
      "                 0.0657,\n",
      "                 0.0468,\n",
      "                 0.0341,\n",
      "                 0.0248,\n",
      "                 0.0171,\n",
      "                 0.0137,\n",
      "                 0.0094,\n",
      "                 0.0064,\n",
      "                 0.0054,\n",
      "                 0.0043,\n",
      "                 0.0039,\n",
      "                 0.0028,\n",
      "                 0.0022,\n",
      "                 0.0019,\n",
      "                 0.0017,\n",
      "                 0.0015,\n",
      "                 0.0013,\n",
      "                 0.001,\n",
      "                 0.0012,\n",
      "                 0.0011,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0008],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7864565849304199,\n",
      "               0.7848227620124817,\n",
      "               0.7834473848342896,\n",
      "               0.782342791557312,\n",
      "               0.7835723161697388,\n",
      "               0.7940219640731812,\n",
      "               0.8086081743240356,\n",
      "               0.8230473399162292,\n",
      "               0.8424307703971863,\n",
      "               0.8645159006118774,\n",
      "               0.8868018984794617,\n",
      "               0.9130414128303528,\n",
      "               0.9428132772445679,\n",
      "               0.9759462475776672,\n",
      "               1.0134321451187134,\n",
      "               1.0506395101547241,\n",
      "               1.086885690689087,\n",
      "               1.1216188669204712,\n",
      "               1.1526319980621338,\n",
      "               1.1826441287994385,\n",
      "               1.2113326787948608,\n",
      "               1.237130880355835,\n",
      "               1.2602267265319824,\n",
      "               1.2812875509262085,\n",
      "               1.3005250692367554,\n",
      "               1.3177073001861572,\n",
      "               1.332983374595642,\n",
      "               1.3458073139190674,\n",
      "               1.356971025466919,\n",
      "               1.366528868675232,\n",
      "               1.3746296167373657,\n",
      "               1.3814033269882202,\n",
      "               1.3869975805282593,\n",
      "               1.3914207220077515,\n",
      "               1.3948986530303955,\n",
      "               1.3975118398666382,\n",
      "               1.3993653059005737,\n",
      "               1.4005190134048462,\n",
      "               1.4010618925094604]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0358,\n",
      "                 1.0382,\n",
      "                 0.9357,\n",
      "                 0.8024,\n",
      "                 0.6313,\n",
      "                 0.46,\n",
      "                 0.3915,\n",
      "                 0.2944,\n",
      "                 0.2241,\n",
      "                 0.1808,\n",
      "                 0.1364,\n",
      "                 0.0898,\n",
      "                 0.0732,\n",
      "                 0.0465,\n",
      "                 0.0373,\n",
      "                 0.0282,\n",
      "                 0.0192,\n",
      "                 0.0124,\n",
      "                 0.0098,\n",
      "                 0.008,\n",
      "                 0.0059,\n",
      "                 0.0041,\n",
      "                 0.0034,\n",
      "                 0.0029,\n",
      "                 0.0027,\n",
      "                 0.0018,\n",
      "                 0.002,\n",
      "                 0.0013,\n",
      "                 0.0016,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0011,\n",
      "                 0.0009,\n",
      "                 0.0011,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0007],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7693356871604919,\n",
      "               0.741045355796814,\n",
      "               0.7165242433547974,\n",
      "               0.7040718793869019,\n",
      "               0.7063831090927124,\n",
      "               0.7125743627548218,\n",
      "               0.7177304029464722,\n",
      "               0.7175842523574829,\n",
      "               0.7150894999504089,\n",
      "               0.7161896824836731,\n",
      "               0.7231751680374146,\n",
      "               0.7361297011375427,\n",
      "               0.7505366206169128,\n",
      "               0.7661949992179871,\n",
      "               0.7808265686035156,\n",
      "               0.7956859469413757,\n",
      "               0.8112775087356567,\n",
      "               0.8256327509880066,\n",
      "               0.8372756242752075,\n",
      "               0.8473628759384155,\n",
      "               0.8555396795272827,\n",
      "               0.8618015050888062,\n",
      "               0.8660293817520142,\n",
      "               0.869310736656189,\n",
      "               0.8721491694450378,\n",
      "               0.8746101260185242,\n",
      "               0.8765257000923157,\n",
      "               0.878097414970398,\n",
      "               0.8796326518058777,\n",
      "               0.8809393644332886,\n",
      "               0.8820937275886536,\n",
      "               0.8830068707466125,\n",
      "               0.8837435841560364,\n",
      "               0.8842331171035767,\n",
      "               0.8846566081047058,\n",
      "               0.8849725723266602,\n",
      "               0.8852121233940125,\n",
      "               0.8853408098220825,\n",
      "               0.8854103088378906]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7443,\n",
      "                 0.8129,\n",
      "                 0.7269,\n",
      "                 0.5851,\n",
      "                 0.3685,\n",
      "                 0.2421,\n",
      "                 0.1458,\n",
      "                 0.0853,\n",
      "                 0.0644,\n",
      "                 0.0425,\n",
      "                 0.0205,\n",
      "                 0.015,\n",
      "                 0.0122,\n",
      "                 0.0071,\n",
      "                 0.0048,\n",
      "                 0.0045,\n",
      "                 0.0029,\n",
      "                 0.0019,\n",
      "                 0.0018,\n",
      "                 0.0014,\n",
      "                 0.0012,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.8091121912002563,\n",
      "               0.8587282299995422,\n",
      "               0.9551025629043579,\n",
      "               1.1066367626190186,\n",
      "               1.2594616413116455,\n",
      "               1.399039387702942,\n",
      "               1.5327030420303345,\n",
      "               1.6476163864135742,\n",
      "               1.7502126693725586,\n",
      "               1.8537609577178955,\n",
      "               1.9542564153671265,\n",
      "               2.0517361164093018,\n",
      "               2.1554365158081055,\n",
      "               2.258012294769287,\n",
      "               2.360107898712158,\n",
      "               2.4576449394226074,\n",
      "               2.548189878463745,\n",
      "               2.6325955390930176,\n",
      "               2.7113494873046875,\n",
      "               2.7832882404327393,\n",
      "               2.84816837310791,\n",
      "               2.9060943126678467,\n",
      "               2.958592176437378,\n",
      "               3.0057218074798584,\n",
      "               3.047548294067383,\n",
      "               3.0840415954589844,\n",
      "               3.1159310340881348,\n",
      "               3.143474817276001,\n",
      "               3.16719651222229,\n",
      "               3.1875126361846924,\n",
      "               3.2047767639160156,\n",
      "               3.219259738922119,\n",
      "               3.231170177459717,\n",
      "               3.2408173084259033,\n",
      "               3.248445987701416,\n",
      "               3.2542643547058105,\n",
      "               3.2584176063537598,\n",
      "               3.261035203933716,\n",
      "               3.262279987335205]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.8484,\n",
      "                 0.8351,\n",
      "                 0.7921,\n",
      "                 0.6555,\n",
      "                 0.5657,\n",
      "                 0.4204,\n",
      "                 0.3121,\n",
      "                 0.2613,\n",
      "                 0.1854,\n",
      "                 0.1295,\n",
      "                 0.0894,\n",
      "                 0.0631,\n",
      "                 0.0427,\n",
      "                 0.0338,\n",
      "                 0.0189,\n",
      "                 0.0163,\n",
      "                 0.0112,\n",
      "                 0.0074,\n",
      "                 0.005,\n",
      "                 0.0046,\n",
      "                 0.003,\n",
      "                 0.0023,\n",
      "                 0.002,\n",
      "                 0.0017,\n",
      "                 0.0014,\n",
      "                 0.0011,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.001,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0007],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7760627269744873,\n",
      "               0.7603041529655457,\n",
      "               0.7415899038314819,\n",
      "               0.7227197289466858,\n",
      "               0.7050514221191406,\n",
      "               0.6902068853378296,\n",
      "               0.6782151460647583,\n",
      "               0.6721826791763306,\n",
      "               0.6708049178123474,\n",
      "               0.6728813648223877,\n",
      "               0.6779149770736694,\n",
      "               0.6814984679222107,\n",
      "               0.6858029961585999,\n",
      "               0.6924749612808228,\n",
      "               0.70110023021698,\n",
      "               0.7106103301048279,\n",
      "               0.7186193466186523,\n",
      "               0.7267876863479614,\n",
      "               0.7342863082885742,\n",
      "               0.7408276200294495,\n",
      "               0.746597409248352,\n",
      "               0.7515732645988464,\n",
      "               0.7560359239578247,\n",
      "               0.7596901655197144,\n",
      "               0.762627899646759,\n",
      "               0.765128493309021,\n",
      "               0.7671462297439575,\n",
      "               0.7688635587692261,\n",
      "               0.7703685760498047,\n",
      "               0.7716528177261353,\n",
      "               0.7728012800216675,\n",
      "               0.7738249897956848,\n",
      "               0.7747045755386353,\n",
      "               0.7754490375518799,\n",
      "               0.7760364413261414,\n",
      "               0.7764789462089539,\n",
      "               0.7767903208732605,\n",
      "               0.7769935727119446,\n",
      "               0.7770941853523254]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7155,\n",
      "                 0.6753,\n",
      "                 0.6984,\n",
      "                 0.5331,\n",
      "                 0.4545,\n",
      "                 0.2911,\n",
      "                 0.2202,\n",
      "                 0.1545,\n",
      "                 0.1302,\n",
      "                 0.0868,\n",
      "                 0.0553,\n",
      "                 0.0375,\n",
      "                 0.0293,\n",
      "                 0.0198,\n",
      "                 0.0124,\n",
      "                 0.0103,\n",
      "                 0.0073,\n",
      "                 0.0036,\n",
      "                 0.0033,\n",
      "                 0.0023,\n",
      "                 0.0024,\n",
      "                 0.0019,\n",
      "                 0.0016,\n",
      "                 0.001,\n",
      "                 0.001,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7784148454666138,\n",
      "               0.7663446068763733,\n",
      "               0.7572826147079468,\n",
      "               0.7553766369819641,\n",
      "               0.7552965879440308,\n",
      "               0.761727511882782,\n",
      "               0.7775748372077942,\n",
      "               0.7987271547317505,\n",
      "               0.8233944773674011,\n",
      "               0.8502920269966125,\n",
      "               0.8784977793693542,\n",
      "               0.9062973856925964,\n",
      "               0.9344522356987,\n",
      "               0.9617144465446472,\n",
      "               0.988980770111084,\n",
      "               1.013812780380249,\n",
      "               1.0378150939941406,\n",
      "               1.0612170696258545,\n",
      "               1.0839436054229736,\n",
      "               1.1057451963424683,\n",
      "               1.1260730028152466,\n",
      "               1.1449710130691528,\n",
      "               1.1617650985717773,\n",
      "               1.176763892173767,\n",
      "               1.1903736591339111,\n",
      "               1.2023789882659912,\n",
      "               1.212904453277588,\n",
      "               1.2221348285675049,\n",
      "               1.2300423383712769,\n",
      "               1.2367570400238037,\n",
      "               1.2425018548965454,\n",
      "               1.2473266124725342,\n",
      "               1.2513333559036255,\n",
      "               1.254607915878296,\n",
      "               1.257195234298706,\n",
      "               1.2591657638549805,\n",
      "               1.2605841159820557,\n",
      "               1.261487364768982,\n",
      "               1.2619202136993408]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.5248,\n",
      "                 0.5205,\n",
      "                 0.5706,\n",
      "                 0.4359,\n",
      "                 0.3267,\n",
      "                 0.2128,\n",
      "                 0.1372,\n",
      "                 0.1019,\n",
      "                 0.0608,\n",
      "                 0.0551,\n",
      "                 0.0313,\n",
      "                 0.0253,\n",
      "                 0.0175,\n",
      "                 0.0128,\n",
      "                 0.0082,\n",
      "                 0.006,\n",
      "                 0.0045,\n",
      "                 0.0029,\n",
      "                 0.0021,\n",
      "                 0.0023,\n",
      "                 0.002,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.0009,\n",
      "                 0.001,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0005],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7841663360595703,\n",
      "               0.7788532972335815,\n",
      "               0.7768620252609253,\n",
      "               0.7836757898330688,\n",
      "               0.8038814663887024,\n",
      "               0.8290539979934692,\n",
      "               0.8633257150650024,\n",
      "               0.9044873118400574,\n",
      "               0.9495746493339539,\n",
      "               1.0010950565338135,\n",
      "               1.0509010553359985,\n",
      "               1.0998849868774414,\n",
      "               1.144939661026001,\n",
      "               1.192524790763855,\n",
      "               1.2399893999099731,\n",
      "               1.2866637706756592,\n",
      "               1.330962896347046,\n",
      "               1.3725998401641846,\n",
      "               1.4067883491516113,\n",
      "               1.4398497343063354,\n",
      "               1.468711256980896,\n",
      "               1.4933375120162964,\n",
      "               1.5152842998504639,\n",
      "               1.534048080444336,\n",
      "               1.5499759912490845,\n",
      "               1.5634180307388306,\n",
      "               1.5749439001083374,\n",
      "               1.584627389907837,\n",
      "               1.5925965309143066,\n",
      "               1.599352240562439,\n",
      "               1.6048500537872314,\n",
      "               1.6093566417694092,\n",
      "               1.6129382848739624,\n",
      "               1.6157281398773193,\n",
      "               1.6179053783416748,\n",
      "               1.6195600032806396,\n",
      "               1.6206789016723633,\n",
      "               1.6213308572769165,\n",
      "               1.6216808557510376]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0142,\n",
      "                 1.0073,\n",
      "                 0.9212,\n",
      "                 0.7058,\n",
      "                 0.5662,\n",
      "                 0.451,\n",
      "                 0.3355,\n",
      "                 0.2688,\n",
      "                 0.2006,\n",
      "                 0.1445,\n",
      "                 0.1284,\n",
      "                 0.085,\n",
      "                 0.0627,\n",
      "                 0.0402,\n",
      "                 0.0367,\n",
      "                 0.0282,\n",
      "                 0.0181,\n",
      "                 0.0148,\n",
      "                 0.0113,\n",
      "                 0.0069,\n",
      "                 0.0063,\n",
      "                 0.0057,\n",
      "                 0.0041,\n",
      "                 0.0032,\n",
      "                 0.0031,\n",
      "                 0.0023,\n",
      "                 0.0018,\n",
      "                 0.0017,\n",
      "                 0.0017,\n",
      "                 0.0019,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0014,\n",
      "                 0.001,\n",
      "                 0.0012,\n",
      "                 0.001,\n",
      "                 0.001,\n",
      "                 0.0011,\n",
      "                 0.0011],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.767282247543335,\n",
      "               0.7376351356506348,\n",
      "               0.7155903577804565,\n",
      "               0.7179859280586243,\n",
      "               0.7303250432014465,\n",
      "               0.7506423592567444,\n",
      "               0.770966649055481,\n",
      "               0.7912666201591492,\n",
      "               0.8137384653091431,\n",
      "               0.8403850793838501,\n",
      "               0.8690120577812195,\n",
      "               0.8985446691513062,\n",
      "               0.9297548532485962,\n",
      "               0.9610082507133484,\n",
      "               0.9900158643722534,\n",
      "               1.0219340324401855,\n",
      "               1.0584889650344849,\n",
      "               1.0942827463150024,\n",
      "               1.1291831731796265,\n",
      "               1.1633946895599365,\n",
      "               1.194471836090088,\n",
      "               1.2233346700668335,\n",
      "               1.2497767210006714,\n",
      "               1.2735642194747925,\n",
      "               1.2946913242340088,\n",
      "               1.3130078315734863,\n",
      "               1.3293157815933228,\n",
      "               1.343885898590088,\n",
      "               1.3562040328979492,\n",
      "               1.3667157888412476,\n",
      "               1.3754984140396118,\n",
      "               1.3828771114349365,\n",
      "               1.3887932300567627,\n",
      "               1.3935116529464722,\n",
      "               1.397128701210022,\n",
      "               1.3998925685882568,\n",
      "               1.4018497467041016,\n",
      "               1.4030662775039673,\n",
      "               1.4036332368850708]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7861,\n",
      "                 0.7349,\n",
      "                 0.6718,\n",
      "                 0.5745,\n",
      "                 0.4858,\n",
      "                 0.4123,\n",
      "                 0.2694,\n",
      "                 0.2014,\n",
      "                 0.146,\n",
      "                 0.1006,\n",
      "                 0.0688,\n",
      "                 0.0572,\n",
      "                 0.0365,\n",
      "                 0.0292,\n",
      "                 0.0202,\n",
      "                 0.0156,\n",
      "                 0.0112,\n",
      "                 0.007,\n",
      "                 0.006,\n",
      "                 0.0037,\n",
      "                 0.003,\n",
      "                 0.0027,\n",
      "                 0.0019,\n",
      "                 0.0016,\n",
      "                 0.0016,\n",
      "                 0.0011,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0009,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0006],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.7861676812171936,\n",
      "               0.7829995155334473,\n",
      "               0.7787129878997803,\n",
      "               0.7805482745170593,\n",
      "               0.7862282991409302,\n",
      "               0.7902031540870667,\n",
      "               0.7959095239639282,\n",
      "               0.8004258275032043,\n",
      "               0.8097432255744934,\n",
      "               0.8255125880241394,\n",
      "               0.8436542749404907,\n",
      "               0.8626905679702759,\n",
      "               0.8812724947929382,\n",
      "               0.9005694389343262,\n",
      "               0.9223361015319824,\n",
      "               0.9417303800582886,\n",
      "               0.9604180455207825,\n",
      "               0.979178786277771,\n",
      "               0.9975826144218445,\n",
      "               1.0160119533538818,\n",
      "               1.0331346988677979,\n",
      "               1.0494757890701294,\n",
      "               1.0640838146209717,\n",
      "               1.0774879455566406,\n",
      "               1.089139699935913,\n",
      "               1.0997793674468994,\n",
      "               1.109437346458435,\n",
      "               1.1179096698760986,\n",
      "               1.125178337097168,\n",
      "               1.1315937042236328,\n",
      "               1.1370656490325928,\n",
      "               1.1416950225830078,\n",
      "               1.1456115245819092,\n",
      "               1.1488770246505737,\n",
      "               1.1514251232147217,\n",
      "               1.1534172296524048,\n",
      "               1.1548404693603516,\n",
      "               1.1557157039642334,\n",
      "               1.1561110019683838]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0607,\n",
      "                 0.9596,\n",
      "                 0.9342,\n",
      "                 0.6939,\n",
      "                 0.5694,\n",
      "                 0.3927,\n",
      "                 0.2714,\n",
      "                 0.1948,\n",
      "                 0.1394,\n",
      "                 0.086,\n",
      "                 0.0573,\n",
      "                 0.034,\n",
      "                 0.0266,\n",
      "                 0.0171,\n",
      "                 0.0081,\n",
      "                 0.0062,\n",
      "                 0.0042,\n",
      "                 0.0031,\n",
      "                 0.0023,\n",
      "                 0.002,\n",
      "                 0.0015,\n",
      "                 0.0011,\n",
      "                 0.001,\n",
      "                 0.0009,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7872334718704224,\n",
      "               0.772242546081543,\n",
      "               0.7494512796401978,\n",
      "               0.727059006690979,\n",
      "               0.7227644324302673,\n",
      "               0.7331787943840027,\n",
      "               0.7466652393341064,\n",
      "               0.7629597187042236,\n",
      "               0.7801553606987,\n",
      "               0.7979834675788879,\n",
      "               0.8222801089286804,\n",
      "               0.8524911999702454,\n",
      "               0.8849116563796997,\n",
      "               0.9200214147567749,\n",
      "               0.9561057090759277,\n",
      "               0.9942137598991394,\n",
      "               1.0352667570114136,\n",
      "               1.0761756896972656,\n",
      "               1.1142940521240234,\n",
      "               1.1496940851211548,\n",
      "               1.181929111480713,\n",
      "               1.211043119430542,\n",
      "               1.236667275428772,\n",
      "               1.2596051692962646,\n",
      "               1.279778242111206,\n",
      "               1.2972609996795654,\n",
      "               1.3123767375946045,\n",
      "               1.3253719806671143,\n",
      "               1.336553931236267,\n",
      "               1.3460568189620972,\n",
      "               1.3541582822799683,\n",
      "               1.3610165119171143,\n",
      "               1.3666883707046509,\n",
      "               1.3713371753692627,\n",
      "               1.3749282360076904,\n",
      "               1.3777028322219849,\n",
      "               1.3797991275787354,\n",
      "               1.3812730312347412,\n",
      "               1.3822014331817627,\n",
      "               1.3826375007629395]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.7229,\n",
      "                 0.796,\n",
      "                 0.6417,\n",
      "                 0.6761,\n",
      "                 0.6785,\n",
      "                 0.5368,\n",
      "                 0.4941,\n",
      "                 0.4874,\n",
      "                 0.4054,\n",
      "                 0.3614,\n",
      "                 0.3252,\n",
      "                 0.2198,\n",
      "                 0.1879,\n",
      "                 0.2207,\n",
      "                 0.1529,\n",
      "                 0.0947,\n",
      "                 0.0703,\n",
      "                 0.0801,\n",
      "                 0.0491,\n",
      "                 0.0438,\n",
      "                 0.0334,\n",
      "                 0.0225,\n",
      "                 0.0178,\n",
      "                 0.0174,\n",
      "                 0.0103,\n",
      "                 0.0097,\n",
      "                 0.0075,\n",
      "                 0.0055,\n",
      "                 0.0038,\n",
      "                 0.0035,\n",
      "                 0.0028,\n",
      "                 0.002,\n",
      "                 0.0014,\n",
      "                 0.0018,\n",
      "                 0.0015,\n",
      "                 0.0012,\n",
      "                 0.0011,\n",
      "                 0.001,\n",
      "                 0.0006,\n",
      "                 0.0008,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0008,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7797219157218933,\n",
      "               0.750977635383606,\n",
      "               0.733235239982605,\n",
      "               0.7360875010490417,\n",
      "               0.7535872459411621,\n",
      "               0.7750064134597778,\n",
      "               0.7987926602363586,\n",
      "               0.8114866018295288,\n",
      "               0.8227278590202332,\n",
      "               0.833905816078186,\n",
      "               0.8418188095092773,\n",
      "               0.8605548143386841,\n",
      "               0.8819311857223511,\n",
      "               0.9020951390266418,\n",
      "               0.9234123229980469,\n",
      "               0.9453985095024109,\n",
      "               0.9649964570999146,\n",
      "               0.9827740788459778,\n",
      "               1.0002632141113281,\n",
      "               1.0153415203094482,\n",
      "               1.0281379222869873,\n",
      "               1.0395108461380005,\n",
      "               1.0491241216659546,\n",
      "               1.0571050643920898,\n",
      "               1.0639615058898926,\n",
      "               1.0698723793029785,\n",
      "               1.0751606225967407,\n",
      "               1.079660415649414,\n",
      "               1.0833641290664673,\n",
      "               1.0865392684936523,\n",
      "               1.089192271232605,\n",
      "               1.0913907289505005,\n",
      "               1.0931600332260132,\n",
      "               1.0945488214492798,\n",
      "               1.09565007686615,\n",
      "               1.096514344215393,\n",
      "               1.0971534252166748,\n",
      "               1.0976438522338867,\n",
      "               1.0979459285736084,\n",
      "               1.0980772972106934]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.9008,\n",
      "                 0.8237,\n",
      "                 0.8191,\n",
      "                 0.7992,\n",
      "                 0.7236,\n",
      "                 0.7131,\n",
      "                 0.6685,\n",
      "                 0.5195,\n",
      "                 0.4916,\n",
      "                 0.3412,\n",
      "                 0.3002,\n",
      "                 0.3558,\n",
      "                 0.3633,\n",
      "                 0.1749,\n",
      "                 0.2154,\n",
      "                 0.1723,\n",
      "                 0.1306,\n",
      "                 0.1267,\n",
      "                 0.0619,\n",
      "                 0.1052,\n",
      "                 0.0652,\n",
      "                 0.052,\n",
      "                 0.0306,\n",
      "                 0.0377,\n",
      "                 0.0279,\n",
      "                 0.018,\n",
      "                 0.0143,\n",
      "                 0.0114,\n",
      "                 0.0079,\n",
      "                 0.0099,\n",
      "                 0.0055,\n",
      "                 0.0056,\n",
      "                 0.0037,\n",
      "                 0.0029,\n",
      "                 0.0025,\n",
      "                 0.0023,\n",
      "                 0.0023,\n",
      "                 0.0014,\n",
      "                 0.0013,\n",
      "                 0.0015,\n",
      "                 0.0015,\n",
      "                 0.0008,\n",
      "                 0.0011,\n",
      "                 0.0007,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7777407765388489,\n",
      "               0.7536638975143433,\n",
      "               0.7156620025634766,\n",
      "               0.709955096244812,\n",
      "               0.7176322340965271,\n",
      "               0.7176896333694458,\n",
      "               0.7082965970039368,\n",
      "               0.6988306641578674,\n",
      "               0.6880372762680054,\n",
      "               0.6765760779380798,\n",
      "               0.6701480746269226,\n",
      "               0.6635907888412476,\n",
      "               0.6562754511833191,\n",
      "               0.6473327279090881,\n",
      "               0.6384083032608032,\n",
      "               0.6377384066581726,\n",
      "               0.6442187428474426,\n",
      "               0.6547385454177856,\n",
      "               0.667669951915741,\n",
      "               0.6841311454772949,\n",
      "               0.7012699246406555,\n",
      "               0.7165769338607788,\n",
      "               0.7293835878372192,\n",
      "               0.7392443418502808,\n",
      "               0.7476764917373657,\n",
      "               0.7537345886230469,\n",
      "               0.7587549090385437,\n",
      "               0.7629588842391968,\n",
      "               0.766668438911438,\n",
      "               0.7698665857315063,\n",
      "               0.7724032402038574,\n",
      "               0.7742622494697571,\n",
      "               0.7756959199905396,\n",
      "               0.7768017649650574,\n",
      "               0.7776358723640442,\n",
      "               0.7781696915626526,\n",
      "               0.7785511612892151,\n",
      "               0.7788516879081726,\n",
      "               0.7790528535842896,\n",
      "               0.7791199684143066]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6692,\n",
      "                 0.8775,\n",
      "                 0.7383,\n",
      "                 0.7884,\n",
      "                 0.8737,\n",
      "                 0.5501,\n",
      "                 0.5639,\n",
      "                 0.5256,\n",
      "                 0.4885,\n",
      "                 0.3736,\n",
      "                 0.3649,\n",
      "                 0.2712,\n",
      "                 0.1525,\n",
      "                 0.3214,\n",
      "                 0.2043,\n",
      "                 0.137,\n",
      "                 0.183,\n",
      "                 0.0621,\n",
      "                 0.0783,\n",
      "                 0.0633,\n",
      "                 0.0407,\n",
      "                 0.0517,\n",
      "                 0.0372,\n",
      "                 0.0258,\n",
      "                 0.027,\n",
      "                 0.0123,\n",
      "                 0.0119,\n",
      "                 0.0102,\n",
      "                 0.0069,\n",
      "                 0.0054,\n",
      "                 0.0044,\n",
      "                 0.0032,\n",
      "                 0.0033,\n",
      "                 0.0026,\n",
      "                 0.0018,\n",
      "                 0.0017,\n",
      "                 0.0016,\n",
      "                 0.001,\n",
      "                 0.001,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0008,\n",
      "                 0.0004,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7833974957466125,\n",
      "               0.7606874108314514,\n",
      "               0.7294307947158813,\n",
      "               0.7175030708312988,\n",
      "               0.7331652641296387,\n",
      "               0.7570810317993164,\n",
      "               0.7855225801467896,\n",
      "               0.7853366136550903,\n",
      "               0.7703887224197388,\n",
      "               0.7706809043884277,\n",
      "               0.7640288472175598,\n",
      "               0.7717102766036987,\n",
      "               0.7920901775360107,\n",
      "               0.822802722454071,\n",
      "               0.8596780896186829,\n",
      "               0.8844960927963257,\n",
      "               0.9077867269515991,\n",
      "               0.9302986264228821,\n",
      "               0.9482637643814087,\n",
      "               0.9640323519706726,\n",
      "               0.9769449234008789,\n",
      "               0.9874420166015625,\n",
      "               0.9969077110290527,\n",
      "               1.0050384998321533,\n",
      "               1.01168954372406,\n",
      "               1.0177175998687744,\n",
      "               1.0236737728118896,\n",
      "               1.0288937091827393,\n",
      "               1.033826231956482,\n",
      "               1.0375614166259766,\n",
      "               1.0405428409576416,\n",
      "               1.043049693107605,\n",
      "               1.0448695421218872,\n",
      "               1.046417236328125,\n",
      "               1.048095941543579,\n",
      "               1.0494661331176758,\n",
      "               1.0505702495574951,\n",
      "               1.051415205001831,\n",
      "               1.051971673965454,\n",
      "               1.052201271057129]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6987,\n",
      "                 0.5438,\n",
      "                 0.7234,\n",
      "                 0.4896,\n",
      "                 0.5633,\n",
      "                 0.4785,\n",
      "                 0.3311,\n",
      "                 0.6131,\n",
      "                 0.3265,\n",
      "                 0.3105,\n",
      "                 0.2537,\n",
      "                 0.1816,\n",
      "                 0.1997,\n",
      "                 0.079,\n",
      "                 0.0724,\n",
      "                 0.0869,\n",
      "                 0.0409,\n",
      "                 0.0461,\n",
      "                 0.037,\n",
      "                 0.025,\n",
      "                 0.0226,\n",
      "                 0.0118,\n",
      "                 0.0074,\n",
      "                 0.0106,\n",
      "                 0.0054,\n",
      "                 0.0044,\n",
      "                 0.0049,\n",
      "                 0.0015,\n",
      "                 0.0027,\n",
      "                 0.0013,\n",
      "                 0.001,\n",
      "                 0.0013,\n",
      "                 0.0009,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7930464148521423,\n",
      "               0.8242575526237488,\n",
      "               0.8882440328598022,\n",
      "               0.9832589030265808,\n",
      "               1.0064553022384644,\n",
      "               0.9553382992744446,\n",
      "               0.9047161340713501,\n",
      "               0.9304200410842896,\n",
      "               0.9896489381790161,\n",
      "               1.094201683998108,\n",
      "               1.2195934057235718,\n",
      "               1.3780466318130493,\n",
      "               1.5149176120758057,\n",
      "               1.630102515220642,\n",
      "               1.7302186489105225,\n",
      "               1.817728042602539,\n",
      "               1.8874523639678955,\n",
      "               1.943450927734375,\n",
      "               1.9894838333129883,\n",
      "               2.0291318893432617,\n",
      "               2.061347246170044,\n",
      "               2.088132381439209,\n",
      "               2.109876871109009,\n",
      "               2.1287710666656494,\n",
      "               2.144516706466675,\n",
      "               2.1572768688201904,\n",
      "               2.167757034301758,\n",
      "               2.176724910736084,\n",
      "               2.184112310409546,\n",
      "               2.1904444694519043,\n",
      "               2.1959052085876465,\n",
      "               2.199944257736206,\n",
      "               2.2031960487365723,\n",
      "               2.20572829246521,\n",
      "               2.207803964614868,\n",
      "               2.2094922065734863,\n",
      "               2.2108185291290283,\n",
      "               2.2116665840148926,\n",
      "               2.212214708328247,\n",
      "               2.212465763092041]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.7843,\n",
      "                 0.6954,\n",
      "                 0.7939,\n",
      "                 0.5171,\n",
      "                 0.6367,\n",
      "                 0.5426,\n",
      "                 0.575,\n",
      "                 0.4473,\n",
      "                 0.3783,\n",
      "                 0.4019,\n",
      "                 0.3057,\n",
      "                 0.2421,\n",
      "                 0.2469,\n",
      "                 0.1503,\n",
      "                 0.1087,\n",
      "                 0.1535,\n",
      "                 0.1246,\n",
      "                 0.0545,\n",
      "                 0.074,\n",
      "                 0.0324,\n",
      "                 0.0382,\n",
      "                 0.0307,\n",
      "                 0.0163,\n",
      "                 0.0167,\n",
      "                 0.013,\n",
      "                 0.0083,\n",
      "                 0.0058,\n",
      "                 0.0072,\n",
      "                 0.0046,\n",
      "                 0.0031,\n",
      "                 0.0029,\n",
      "                 0.002,\n",
      "                 0.0017,\n",
      "                 0.0016,\n",
      "                 0.0011,\n",
      "                 0.0014,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7802468538284302,\n",
      "               0.7507157325744629,\n",
      "               0.7234445810317993,\n",
      "               0.7167838215827942,\n",
      "               0.7173200845718384,\n",
      "               0.7244876623153687,\n",
      "               0.7511237263679504,\n",
      "               0.7704825401306152,\n",
      "               0.7906149625778198,\n",
      "               0.8042091131210327,\n",
      "               0.8110139966011047,\n",
      "               0.8041073679924011,\n",
      "               0.7992112040519714,\n",
      "               0.8035622835159302,\n",
      "               0.8084017038345337,\n",
      "               0.8173608779907227,\n",
      "               0.8266465067863464,\n",
      "               0.8364008665084839,\n",
      "               0.845051109790802,\n",
      "               0.8525267839431763,\n",
      "               0.860360324382782,\n",
      "               0.8671904802322388,\n",
      "               0.8730996251106262,\n",
      "               0.8784278631210327,\n",
      "               0.8825379610061646,\n",
      "               0.885945200920105,\n",
      "               0.8888775706291199,\n",
      "               0.8913040161132812,\n",
      "               0.8932145833969116,\n",
      "               0.8946955800056458,\n",
      "               0.8960198163986206,\n",
      "               0.8971942663192749,\n",
      "               0.898186206817627,\n",
      "               0.8990055322647095,\n",
      "               0.8996902704238892,\n",
      "               0.9002825021743774,\n",
      "               0.9007679224014282,\n",
      "               0.9011370539665222,\n",
      "               0.9013477563858032,\n",
      "               0.9014276266098022]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.5601,\n",
      "                 0.8498,\n",
      "                 0.5374,\n",
      "                 0.7941,\n",
      "                 0.5661,\n",
      "                 0.6558,\n",
      "                 0.5715,\n",
      "                 0.3704,\n",
      "                 0.3305,\n",
      "                 0.3839,\n",
      "                 0.276,\n",
      "                 0.1862,\n",
      "                 0.1913,\n",
      "                 0.1428,\n",
      "                 0.111,\n",
      "                 0.1177,\n",
      "                 0.0718,\n",
      "                 0.0791,\n",
      "                 0.046,\n",
      "                 0.0418,\n",
      "                 0.0282,\n",
      "                 0.0253,\n",
      "                 0.0196,\n",
      "                 0.0194,\n",
      "                 0.0142,\n",
      "                 0.0076,\n",
      "                 0.0064,\n",
      "                 0.0059,\n",
      "                 0.0047,\n",
      "                 0.0029,\n",
      "                 0.0032,\n",
      "                 0.002,\n",
      "                 0.0015,\n",
      "                 0.0014,\n",
      "                 0.001,\n",
      "                 0.0014,\n",
      "                 0.0013,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0009,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7845709919929504,\n",
      "               0.7744049429893494,\n",
      "               0.7525099515914917,\n",
      "               0.7408304214477539,\n",
      "               0.7415859699249268,\n",
      "               0.7445392608642578,\n",
      "               0.741962730884552,\n",
      "               0.7550318241119385,\n",
      "               0.7813356518745422,\n",
      "               0.7986634373664856,\n",
      "               0.8046895861625671,\n",
      "               0.8342833518981934,\n",
      "               0.8435264825820923,\n",
      "               0.8615716695785522,\n",
      "               0.8834033012390137,\n",
      "               0.9092341661453247,\n",
      "               0.9360483884811401,\n",
      "               0.9617104530334473,\n",
      "               0.9840399622917175,\n",
      "               1.0047781467437744,\n",
      "               1.022425889968872,\n",
      "               1.0382381677627563,\n",
      "               1.0518314838409424,\n",
      "               1.0635731220245361,\n",
      "               1.0737740993499756,\n",
      "               1.0824992656707764,\n",
      "               1.090006709098816,\n",
      "               1.0963306427001953,\n",
      "               1.1018412113189697,\n",
      "               1.1065194606781006,\n",
      "               1.1104419231414795,\n",
      "               1.1138232946395874,\n",
      "               1.1166784763336182,\n",
      "               1.1190283298492432,\n",
      "               1.120918869972229,\n",
      "               1.122390866279602,\n",
      "               1.123521089553833,\n",
      "               1.1243493556976318,\n",
      "               1.1248400211334229,\n",
      "               1.1250461339950562]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6806,\n",
      "                 0.7662,\n",
      "                 0.6463,\n",
      "                 0.6794,\n",
      "                 0.6729,\n",
      "                 0.6207,\n",
      "                 0.5745,\n",
      "                 0.5105,\n",
      "                 0.4579,\n",
      "                 0.3696,\n",
      "                 0.2934,\n",
      "                 0.2784,\n",
      "                 0.1967,\n",
      "                 0.2619,\n",
      "                 0.1768,\n",
      "                 0.1736,\n",
      "                 0.1003,\n",
      "                 0.0951,\n",
      "                 0.0907,\n",
      "                 0.0517,\n",
      "                 0.0487,\n",
      "                 0.0345,\n",
      "                 0.0267,\n",
      "                 0.0284,\n",
      "                 0.0119,\n",
      "                 0.0163,\n",
      "                 0.0097,\n",
      "                 0.0086,\n",
      "                 0.0064,\n",
      "                 0.0044,\n",
      "                 0.0044,\n",
      "                 0.0021,\n",
      "                 0.0028,\n",
      "                 0.0024,\n",
      "                 0.0025,\n",
      "                 0.0016,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7855103611946106,\n",
      "               0.7782781720161438,\n",
      "               0.7522619366645813,\n",
      "               0.7246097326278687,\n",
      "               0.6965566277503967,\n",
      "               0.6811152100563049,\n",
      "               0.6727563142776489,\n",
      "               0.6480364203453064,\n",
      "               0.6128395199775696,\n",
      "               0.5871656537055969,\n",
      "               0.5781686902046204,\n",
      "               0.558387041091919,\n",
      "               0.5595656633377075,\n",
      "               0.5747612714767456,\n",
      "               0.5874631404876709,\n",
      "               0.600503146648407,\n",
      "               0.6121051907539368,\n",
      "               0.6092137694358826,\n",
      "               0.606167197227478,\n",
      "               0.6026560068130493,\n",
      "               0.6026506423950195,\n",
      "               0.6009248495101929,\n",
      "               0.6006887555122375,\n",
      "               0.6012558937072754,\n",
      "               0.6024107336997986,\n",
      "               0.6038764119148254,\n",
      "               0.604860246181488,\n",
      "               0.6057864427566528,\n",
      "               0.6066082715988159,\n",
      "               0.6075124144554138,\n",
      "               0.6084290742874146,\n",
      "               0.6090638041496277,\n",
      "               0.6096295118331909,\n",
      "               0.6100984811782837,\n",
      "               0.6107222437858582,\n",
      "               0.6110534071922302,\n",
      "               0.611413836479187,\n",
      "               0.6116034388542175,\n",
      "               0.6117459535598755,\n",
      "               0.611784815788269]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.0018,\n",
      "                 0.8269,\n",
      "                 0.9187,\n",
      "                 0.7068,\n",
      "                 0.6894,\n",
      "                 0.6715,\n",
      "                 0.5131,\n",
      "                 0.7369,\n",
      "                 0.4414,\n",
      "                 0.5413,\n",
      "                 0.5219,\n",
      "                 0.317,\n",
      "                 0.4467,\n",
      "                 0.2139,\n",
      "                 0.2228,\n",
      "                 0.1892,\n",
      "                 0.1363,\n",
      "                 0.2077,\n",
      "                 0.1057,\n",
      "                 0.1014,\n",
      "                 0.0988,\n",
      "                 0.0489,\n",
      "                 0.0571,\n",
      "                 0.0336,\n",
      "                 0.0248,\n",
      "                 0.0278,\n",
      "                 0.0201,\n",
      "                 0.0125,\n",
      "                 0.0106,\n",
      "                 0.0092,\n",
      "                 0.0061,\n",
      "                 0.0065,\n",
      "                 0.0053,\n",
      "                 0.0032,\n",
      "                 0.0025,\n",
      "                 0.0027,\n",
      "                 0.0018,\n",
      "                 0.0016,\n",
      "                 0.0011,\n",
      "                 0.0011,\n",
      "                 0.0014,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0008,\n",
      "                 0.0007,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0007,\n",
      "                 0.0004,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003],\n",
      "  'val_loss': [0.7770346999168396,\n",
      "               0.7361248135566711,\n",
      "               0.7133632898330688,\n",
      "               0.7548125982284546,\n",
      "               0.8000224828720093,\n",
      "               0.8080394864082336,\n",
      "               0.7970809936523438,\n",
      "               0.7819623947143555,\n",
      "               0.7887424230575562,\n",
      "               0.8126239776611328,\n",
      "               0.8479307889938354,\n",
      "               0.900304913520813,\n",
      "               0.9665989875793457,\n",
      "               1.019483208656311,\n",
      "               1.074445128440857,\n",
      "               1.1321649551391602,\n",
      "               1.174870491027832,\n",
      "               1.2198219299316406,\n",
      "               1.2585068941116333,\n",
      "               1.290502667427063,\n",
      "               1.3164863586425781,\n",
      "               1.3393758535385132,\n",
      "               1.3584054708480835,\n",
      "               1.3745393753051758,\n",
      "               1.3880670070648193,\n",
      "               1.3992891311645508,\n",
      "               1.4100372791290283,\n",
      "               1.4190983772277832,\n",
      "               1.4268348217010498,\n",
      "               1.4328839778900146,\n",
      "               1.4383496046066284,\n",
      "               1.442730188369751,\n",
      "               1.4460418224334717,\n",
      "               1.448472261428833,\n",
      "               1.450551152229309,\n",
      "               1.4524972438812256,\n",
      "               1.4537999629974365,\n",
      "               1.4546074867248535,\n",
      "               1.4551219940185547,\n",
      "               1.4553344249725342]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8016,\n",
      "                 0.6408,\n",
      "                 0.6871,\n",
      "                 0.7264,\n",
      "                 0.5414,\n",
      "                 0.6659,\n",
      "                 0.5343,\n",
      "                 0.5534,\n",
      "                 0.4451,\n",
      "                 0.3897,\n",
      "                 0.3143,\n",
      "                 0.3062,\n",
      "                 0.2472,\n",
      "                 0.2389,\n",
      "                 0.1553,\n",
      "                 0.1362,\n",
      "                 0.0887,\n",
      "                 0.1122,\n",
      "                 0.063,\n",
      "                 0.0584,\n",
      "                 0.0446,\n",
      "                 0.0337,\n",
      "                 0.0238,\n",
      "                 0.0182,\n",
      "                 0.0161,\n",
      "                 0.013,\n",
      "                 0.008,\n",
      "                 0.0068,\n",
      "                 0.0054,\n",
      "                 0.0038,\n",
      "                 0.0035,\n",
      "                 0.0023,\n",
      "                 0.0019,\n",
      "                 0.0016,\n",
      "                 0.0025,\n",
      "                 0.0012,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0009,\n",
      "                 0.0008,\n",
      "                 0.0006,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7828696370124817,\n",
      "               0.7610737681388855,\n",
      "               0.7505680918693542,\n",
      "               0.7407324910163879,\n",
      "               0.7380180954933167,\n",
      "               0.7397593259811401,\n",
      "               0.7396975755691528,\n",
      "               0.7514329552650452,\n",
      "               0.7895208597183228,\n",
      "               0.8543996810913086,\n",
      "               0.9227958917617798,\n",
      "               1.0098199844360352,\n",
      "               1.0722177028656006,\n",
      "               1.1194781064987183,\n",
      "               1.1747466325759888,\n",
      "               1.2208610773086548,\n",
      "               1.2625627517700195,\n",
      "               1.2850744724273682,\n",
      "               1.3015621900558472,\n",
      "               1.3183501958847046,\n",
      "               1.3339042663574219,\n",
      "               1.3481016159057617,\n",
      "               1.36161470413208,\n",
      "               1.3735694885253906,\n",
      "               1.3846352100372314,\n",
      "               1.3948488235473633,\n",
      "               1.4037147760391235,\n",
      "               1.4112237691879272,\n",
      "               1.4178311824798584,\n",
      "               1.423380970954895,\n",
      "               1.4285646677017212,\n",
      "               1.4330514669418335,\n",
      "               1.4367692470550537,\n",
      "               1.440279483795166,\n",
      "               1.443580150604248,\n",
      "               1.4463512897491455,\n",
      "               1.4484174251556396,\n",
      "               1.4498240947723389,\n",
      "               1.4506919384002686,\n",
      "               1.4510550498962402]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8138,\n",
      "                 0.8036,\n",
      "                 0.6635,\n",
      "                 0.8389,\n",
      "                 0.6836,\n",
      "                 0.595,\n",
      "                 0.4522,\n",
      "                 0.5342,\n",
      "                 0.3645,\n",
      "                 0.3944,\n",
      "                 0.3063,\n",
      "                 0.2292,\n",
      "                 0.2769,\n",
      "                 0.1047,\n",
      "                 0.112,\n",
      "                 0.0915,\n",
      "                 0.0667,\n",
      "                 0.0492,\n",
      "                 0.0417,\n",
      "                 0.0335,\n",
      "                 0.0332,\n",
      "                 0.0127,\n",
      "                 0.0117,\n",
      "                 0.009,\n",
      "                 0.0078,\n",
      "                 0.0073,\n",
      "                 0.0031,\n",
      "                 0.0028,\n",
      "                 0.0018,\n",
      "                 0.002,\n",
      "                 0.0012,\n",
      "                 0.0016,\n",
      "                 0.0009,\n",
      "                 0.0011,\n",
      "                 0.001,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0005,\n",
      "                 0.0006,\n",
      "                 0.0003,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002],\n",
      "  'val_loss': [0.7785273194313049,\n",
      "               0.7472510933876038,\n",
      "               0.727835476398468,\n",
      "               0.7583330869674683,\n",
      "               0.8054412007331848,\n",
      "               0.8413987159729004,\n",
      "               0.8687807321548462,\n",
      "               0.9091838002204895,\n",
      "               0.9506619572639465,\n",
      "               1.0110554695129395,\n",
      "               1.0909006595611572,\n",
      "               1.1909868717193604,\n",
      "               1.3140594959259033,\n",
      "               1.4420945644378662,\n",
      "               1.5616378784179688,\n",
      "               1.6651191711425781,\n",
      "               1.750011682510376,\n",
      "               1.8163301944732666,\n",
      "               1.8696174621582031,\n",
      "               1.9107978343963623,\n",
      "               1.9431358575820923,\n",
      "               1.9692249298095703,\n",
      "               1.9896056652069092,\n",
      "               2.005608320236206,\n",
      "               2.018094301223755,\n",
      "               2.0278167724609375,\n",
      "               2.035296678543091,\n",
      "               2.041417121887207,\n",
      "               2.0458195209503174,\n",
      "               2.0496082305908203,\n",
      "               2.0525341033935547,\n",
      "               2.0549895763397217,\n",
      "               2.056994915008545,\n",
      "               2.0585241317749023,\n",
      "               2.059480667114258,\n",
      "               2.06017804145813,\n",
      "               2.0606942176818848,\n",
      "               2.0610599517822266,\n",
      "               2.0612521171569824,\n",
      "               2.061347484588623]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.8243,\n",
      "                 0.7101,\n",
      "                 0.4364,\n",
      "                 0.1131,\n",
      "                 0.0593,\n",
      "                 0.0046,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8876555562019348,\n",
      "               0.8355786204338074,\n",
      "               0.7897123098373413,\n",
      "               0.8323702812194824,\n",
      "               1.0122517347335815,\n",
      "               1.2208540439605713,\n",
      "               1.4261611700057983,\n",
      "               1.6211445331573486,\n",
      "               1.7998851537704468,\n",
      "               1.969394326210022,\n",
      "               2.1343140602111816,\n",
      "               2.295073986053467,\n",
      "               2.4396286010742188,\n",
      "               2.572930335998535,\n",
      "               2.6946959495544434,\n",
      "               2.80362868309021,\n",
      "               2.8984897136688232,\n",
      "               2.9810028076171875,\n",
      "               3.052515745162964,\n",
      "               3.1146302223205566,\n",
      "               3.1680541038513184,\n",
      "               3.214224338531494,\n",
      "               3.254006862640381,\n",
      "               3.288217067718506,\n",
      "               3.317345142364502,\n",
      "               3.342078447341919,\n",
      "               3.3630337715148926,\n",
      "               3.3808035850524902,\n",
      "               3.3955750465393066,\n",
      "               3.4076881408691406,\n",
      "               3.417585849761963,\n",
      "               3.425602436065674,\n",
      "               3.4319629669189453,\n",
      "               3.436903715133667,\n",
      "               3.4406380653381348,\n",
      "               3.443345546722412,\n",
      "               3.4451873302459717,\n",
      "               3.4463000297546387,\n",
      "               3.4468016624450684]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.4045,\n",
      "                 0.2252,\n",
      "                 0.202,\n",
      "                 0.0111,\n",
      "                 0.0005,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               1.0216693878173828,\n",
      "               1.5152028799057007,\n",
      "               2.6625916957855225,\n",
      "               4.209092617034912,\n",
      "               5.539681434631348,\n",
      "               6.611271858215332,\n",
      "               7.475677490234375,\n",
      "               8.173131942749023,\n",
      "               8.75542163848877,\n",
      "               9.244786262512207,\n",
      "               9.657330513000488,\n",
      "               10.00217056274414,\n",
      "               10.293052673339844,\n",
      "               10.538252830505371,\n",
      "               10.743634223937988,\n",
      "               10.91978645324707,\n",
      "               11.07036018371582,\n",
      "               11.199272155761719,\n",
      "               11.310070991516113,\n",
      "               11.405245780944824,\n",
      "               11.486434936523438,\n",
      "               11.555623054504395,\n",
      "               11.614173889160156,\n",
      "               11.663818359375,\n",
      "               11.706219673156738,\n",
      "               11.74207592010498,\n",
      "               11.772287368774414,\n",
      "               11.797532081604004,\n",
      "               11.818634033203125,\n",
      "               11.836057662963867,\n",
      "               11.850354194641113,\n",
      "               11.86195182800293,\n",
      "               11.87116527557373,\n",
      "               11.87834644317627,\n",
      "               11.883782386779785,\n",
      "               11.887738227844238,\n",
      "               11.890433311462402,\n",
      "               11.892062187194824,\n",
      "               11.892820358276367]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.1402,\n",
      "                 1.1056,\n",
      "                 0.7851,\n",
      "                 0.077,\n",
      "                 0.0062,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8640425801277161,\n",
      "               0.9685189127922058,\n",
      "               1.468746304512024,\n",
      "               2.319664716720581,\n",
      "               3.053621768951416,\n",
      "               3.659395933151245,\n",
      "               4.1655988693237305,\n",
      "               4.595328330993652,\n",
      "               4.944454669952393,\n",
      "               5.2414679527282715,\n",
      "               5.4971442222595215,\n",
      "               5.71566915512085,\n",
      "               5.901966094970703,\n",
      "               6.061899662017822,\n",
      "               6.199924468994141,\n",
      "               6.318212985992432,\n",
      "               6.4203596115112305,\n",
      "               6.507554531097412,\n",
      "               6.582027435302734,\n",
      "               6.6456098556518555,\n",
      "               6.699967861175537,\n",
      "               6.7464189529418945,\n",
      "               6.786154270172119,\n",
      "               6.820068359375,\n",
      "               6.848750114440918,\n",
      "               6.87291955947876,\n",
      "               6.893225193023682,\n",
      "               6.910192966461182,\n",
      "               6.924275875091553,\n",
      "               6.935910224914551,\n",
      "               6.945433139801025,\n",
      "               6.953132629394531,\n",
      "               6.959261894226074,\n",
      "               6.9640398025512695,\n",
      "               6.967658996582031,\n",
      "               6.9702959060668945,\n",
      "               6.972092628479004,\n",
      "               6.973184108734131,\n",
      "               6.9736738204956055]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.324,\n",
      "                 0.482,\n",
      "                 0.1235,\n",
      "                 0.0089,\n",
      "                 0.0004,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9040425419807434,\n",
      "               1.0328360795974731,\n",
      "               1.4123109579086304,\n",
      "               1.9401088953018188,\n",
      "               2.411146640777588,\n",
      "               2.8188061714172363,\n",
      "               3.1701419353485107,\n",
      "               3.479304790496826,\n",
      "               3.748997211456299,\n",
      "               3.9810664653778076,\n",
      "               4.180279731750488,\n",
      "               4.353743553161621,\n",
      "               4.504103660583496,\n",
      "               4.633660793304443,\n",
      "               4.74594783782959,\n",
      "               4.843105316162109,\n",
      "               4.927275657653809,\n",
      "               5.000601291656494,\n",
      "               5.064033508300781,\n",
      "               5.118979454040527,\n",
      "               5.16663122177124,\n",
      "               5.207828521728516,\n",
      "               5.243218421936035,\n",
      "               5.273518085479736,\n",
      "               5.299409866333008,\n",
      "               5.321480751037598,\n",
      "               5.3401384353637695,\n",
      "               5.355809211730957,\n",
      "               5.368895530700684,\n",
      "               5.3797502517700195,\n",
      "               5.388648986816406,\n",
      "               5.395844459533691,\n",
      "               5.401573181152344,\n",
      "               5.406041622161865,\n",
      "               5.409430027008057,\n",
      "               5.411896228790283,\n",
      "               5.413578987121582,\n",
      "               5.414595603942871,\n",
      "               5.415070533752441]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.8025,\n",
      "                 0.8299,\n",
      "                 0.3441,\n",
      "                 0.187,\n",
      "                 0.0275,\n",
      "                 0.0023,\n",
      "                 0.0006,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8951126933097839,\n",
      "               0.8868516683578491,\n",
      "               0.9012214541435242,\n",
      "               0.9248604774475098,\n",
      "               0.9122358560562134,\n",
      "               0.9014010429382324,\n",
      "               0.9042326211929321,\n",
      "               0.9198945164680481,\n",
      "               0.941704273223877,\n",
      "               0.965814471244812,\n",
      "               0.9911335706710815,\n",
      "               1.0209579467773438,\n",
      "               1.053091287612915,\n",
      "               1.0841548442840576,\n",
      "               1.1153355836868286,\n",
      "               1.1470481157302856,\n",
      "               1.1758763790130615,\n",
      "               1.1997215747833252,\n",
      "               1.2199711799621582,\n",
      "               1.2381428480148315,\n",
      "               1.2538484334945679,\n",
      "               1.2680063247680664,\n",
      "               1.2803587913513184,\n",
      "               1.2909929752349854,\n",
      "               1.3000264167785645,\n",
      "               1.3077627420425415,\n",
      "               1.3143808841705322,\n",
      "               1.3199971914291382,\n",
      "               1.3247292041778564,\n",
      "               1.3286874294281006,\n",
      "               1.3319599628448486,\n",
      "               1.3346068859100342,\n",
      "               1.3367103338241577,\n",
      "               1.3383451700210571,\n",
      "               1.3395750522613525,\n",
      "               1.340471625328064,\n",
      "               1.3410851955413818,\n",
      "               1.3414578437805176,\n",
      "               1.3416258096694946]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.3317,\n",
      "                 1.3196,\n",
      "                 0.8555,\n",
      "                 0.1835,\n",
      "                 0.0441,\n",
      "                 0.0046,\n",
      "                 0.0005,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8772948384284973,\n",
      "               0.8363935351371765,\n",
      "               0.8186279535293579,\n",
      "               0.7802502512931824,\n",
      "               0.7588178515434265,\n",
      "               0.7593393325805664,\n",
      "               0.7800447344779968,\n",
      "               0.8101370930671692,\n",
      "               0.8442087173461914,\n",
      "               0.8802846670150757,\n",
      "               0.920162558555603,\n",
      "               0.9647728204727173,\n",
      "               1.0093791484832764,\n",
      "               1.0521718263626099,\n",
      "               1.0926483869552612,\n",
      "               1.1303633451461792,\n",
      "               1.165274977684021,\n",
      "               1.1964646577835083,\n",
      "               1.224711537361145,\n",
      "               1.2495315074920654,\n",
      "               1.2713176012039185,\n",
      "               1.2903505563735962,\n",
      "               1.307193636894226,\n",
      "               1.321846604347229,\n",
      "               1.3345359563827515,\n",
      "               1.3455030918121338,\n",
      "               1.3547829389572144,\n",
      "               1.3626314401626587,\n",
      "               1.3691734075546265,\n",
      "               1.3746273517608643,\n",
      "               1.3790996074676514,\n",
      "               1.3827431201934814,\n",
      "               1.3856210708618164,\n",
      "               1.3878605365753174,\n",
      "               1.3895505666732788,\n",
      "               1.3907736539840698,\n",
      "               1.3916041851043701,\n",
      "               1.3921054601669312,\n",
      "               1.3923306465148926]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6843,\n",
      "                 0.855,\n",
      "                 0.1386,\n",
      "                 0.0199,\n",
      "                 0.0009,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9057356119155884,\n",
      "               1.050472378730774,\n",
      "               1.488041639328003,\n",
      "               2.1792807579040527,\n",
      "               2.809643507003784,\n",
      "               3.340064525604248,\n",
      "               3.786707639694214,\n",
      "               4.174718379974365,\n",
      "               4.505645751953125,\n",
      "               4.78751277923584,\n",
      "               5.028111457824707,\n",
      "               5.2337517738342285,\n",
      "               5.409117221832275,\n",
      "               5.559828758239746,\n",
      "               5.688633918762207,\n",
      "               5.799242973327637,\n",
      "               5.894206523895264,\n",
      "               5.976379871368408,\n",
      "               6.047270774841309,\n",
      "               6.1080732345581055,\n",
      "               6.160476207733154,\n",
      "               6.20542049407959,\n",
      "               6.243879795074463,\n",
      "               6.276663780212402,\n",
      "               6.304574489593506,\n",
      "               6.328306674957275,\n",
      "               6.3482818603515625,\n",
      "               6.365023612976074,\n",
      "               6.379021644592285,\n",
      "               6.390620231628418,\n",
      "               6.400099754333496,\n",
      "               6.40777063369751,\n",
      "               6.41388463973999,\n",
      "               6.418660640716553,\n",
      "               6.422269344329834,\n",
      "               6.4248948097229,\n",
      "               6.4266862869262695,\n",
      "               6.427767753601074,\n",
      "               6.4282660484313965]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7461,\n",
      "                 0.6606,\n",
      "                 0.3534,\n",
      "                 0.1086,\n",
      "                 0.0182,\n",
      "                 0.0013,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.899477481842041,\n",
      "               0.8828481435775757,\n",
      "               0.8965135812759399,\n",
      "               0.9308512806892395,\n",
      "               0.9776133298873901,\n",
      "               1.0321524143218994,\n",
      "               1.0858008861541748,\n",
      "               1.1374032497406006,\n",
      "               1.1855854988098145,\n",
      "               1.228006362915039,\n",
      "               1.265933632850647,\n",
      "               1.2971527576446533,\n",
      "               1.3250032663345337,\n",
      "               1.349975347518921,\n",
      "               1.3725645542144775,\n",
      "               1.3920962810516357,\n",
      "               1.4093071222305298,\n",
      "               1.424681305885315,\n",
      "               1.4385396242141724,\n",
      "               1.4505150318145752,\n",
      "               1.4606783390045166,\n",
      "               1.4695154428482056,\n",
      "               1.4770468473434448,\n",
      "               1.4835879802703857,\n",
      "               1.4891897439956665,\n",
      "               1.4939608573913574,\n",
      "               1.4980378150939941,\n",
      "               1.5014702081680298,\n",
      "               1.5043463706970215,\n",
      "               1.506730556488037,\n",
      "               1.5087264776229858,\n",
      "               1.5103251934051514,\n",
      "               1.511587142944336,\n",
      "               1.5125725269317627,\n",
      "               1.51331627368927,\n",
      "               1.5138509273529053,\n",
      "               1.5142157077789307,\n",
      "               1.5144380331039429,\n",
      "               1.5145381689071655]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6435,\n",
      "                 0.4606,\n",
      "                 0.3207,\n",
      "                 0.0487,\n",
      "                 0.0022,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8798366785049438,\n",
      "               0.9614065289497375,\n",
      "               1.343403697013855,\n",
      "               2.063999652862549,\n",
      "               2.6774637699127197,\n",
      "               3.2218832969665527,\n",
      "               3.6961331367492676,\n",
      "               4.100053310394287,\n",
      "               4.444140434265137,\n",
      "               4.736294746398926,\n",
      "               4.986389636993408,\n",
      "               5.200514793395996,\n",
      "               5.387385368347168,\n",
      "               5.547224998474121,\n",
      "               5.6843390464782715,\n",
      "               5.803737163543701,\n",
      "               5.905888557434082,\n",
      "               5.992819786071777,\n",
      "               6.067187309265137,\n",
      "               6.131353855133057,\n",
      "               6.186764717102051,\n",
      "               6.234076499938965,\n",
      "               6.274371147155762,\n",
      "               6.308609962463379,\n",
      "               6.337645530700684,\n",
      "               6.362160682678223,\n",
      "               6.382826805114746,\n",
      "               6.4001665115356445,\n",
      "               6.414602756500244,\n",
      "               6.426548004150391,\n",
      "               6.436330318450928,\n",
      "               6.4442458152771,\n",
      "               6.450563907623291,\n",
      "               6.455491065979004,\n",
      "               6.459219455718994,\n",
      "               6.461939811706543,\n",
      "               6.4637956619262695,\n",
      "               6.464913845062256,\n",
      "               6.465420722961426]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6875,\n",
      "                 0.5276,\n",
      "                 0.2057,\n",
      "                 0.0163,\n",
      "                 0.0011,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               1.0032833814620972,\n",
      "               1.3505885601043701,\n",
      "               2.183011293411255,\n",
      "               3.4255003929138184,\n",
      "               4.501982688903809,\n",
      "               5.403934478759766,\n",
      "               6.170688629150391,\n",
      "               6.82024621963501,\n",
      "               7.374894142150879,\n",
      "               7.848458766937256,\n",
      "               8.25322151184082,\n",
      "               8.596248626708984,\n",
      "               8.889266014099121,\n",
      "               9.142142295837402,\n",
      "               9.359539985656738,\n",
      "               9.54708194732666,\n",
      "               9.707046508789062,\n",
      "               9.844766616821289,\n",
      "               9.963287353515625,\n",
      "               10.06549072265625,\n",
      "               10.153231620788574,\n",
      "               10.228593826293945,\n",
      "               10.293194770812988,\n",
      "               10.3482666015625,\n",
      "               10.395153999328613,\n",
      "               10.434901237487793,\n",
      "               10.468358993530273,\n",
      "               10.496362686157227,\n",
      "               10.519681930541992,\n",
      "               10.538972854614258,\n",
      "               10.554777145385742,\n",
      "               10.567558288574219,\n",
      "               10.577737808227539,\n",
      "               10.58568286895752,\n",
      "               10.591703414916992,\n",
      "               10.596091270446777,\n",
      "               10.599090576171875,\n",
      "               10.600900650024414,\n",
      "               10.601733207702637]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.5652,\n",
      "                 1.3511,\n",
      "                 1.022,\n",
      "                 0.2697,\n",
      "                 0.0281,\n",
      "                 0.0023,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8762772679328918,\n",
      "               0.8663128614425659,\n",
      "               1.0356004238128662,\n",
      "               1.486440896987915,\n",
      "               1.9529211521148682,\n",
      "               2.3707499504089355,\n",
      "               2.769193172454834,\n",
      "               3.1317148208618164,\n",
      "               3.434901475906372,\n",
      "               3.6979918479919434,\n",
      "               3.9239776134490967,\n",
      "               4.116343975067139,\n",
      "               4.279483795166016,\n",
      "               4.41988468170166,\n",
      "               4.540856838226318,\n",
      "               4.644684791564941,\n",
      "               4.734076976776123,\n",
      "               4.8108086585998535,\n",
      "               4.876885414123535,\n",
      "               4.933984756469727,\n",
      "               4.982641696929932,\n",
      "               5.024511337280273,\n",
      "               5.0603742599487305,\n",
      "               5.091039180755615,\n",
      "               5.117064476013184,\n",
      "               5.139191627502441,\n",
      "               5.158049583435059,\n",
      "               5.173876762390137,\n",
      "               5.187103271484375,\n",
      "               5.19802188873291,\n",
      "               5.206938743591309,\n",
      "               5.214169502258301,\n",
      "               5.219943046569824,\n",
      "               5.224451541900635,\n",
      "               5.227874279022217,\n",
      "               5.23036527633667,\n",
      "               5.232066631317139,\n",
      "               5.2331013679504395,\n",
      "               5.233567714691162]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.5508,\n",
      "                 0.5392,\n",
      "                 0.2157,\n",
      "                 0.1238,\n",
      "                 0.0526,\n",
      "                 0.0057,\n",
      "                 0.0007,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.90619957447052,\n",
      "               1.038554310798645,\n",
      "               1.189267635345459,\n",
      "               1.2574665546417236,\n",
      "               1.246849775314331,\n",
      "               1.2499496936798096,\n",
      "               1.2622969150543213,\n",
      "               1.2754751443862915,\n",
      "               1.2882447242736816,\n",
      "               1.3015097379684448,\n",
      "               1.3147181272506714,\n",
      "               1.3251609802246094,\n",
      "               1.3352712392807007,\n",
      "               1.3448718786239624,\n",
      "               1.3533128499984741,\n",
      "               1.3609508275985718,\n",
      "               1.3675320148468018,\n",
      "               1.3727977275848389,\n",
      "               1.3764187097549438,\n",
      "               1.3802684545516968,\n",
      "               1.3833250999450684,\n",
      "               1.3856397867202759,\n",
      "               1.387251377105713,\n",
      "               1.3877942562103271,\n",
      "               1.3880574703216553,\n",
      "               1.3894267082214355,\n",
      "               1.391139030456543,\n",
      "               1.3931020498275757,\n",
      "               1.3949377536773682,\n",
      "               1.3966107368469238,\n",
      "               1.3979030847549438,\n",
      "               1.3990603685379028,\n",
      "               1.3999336957931519,\n",
      "               1.4006078243255615,\n",
      "               1.4011119604110718,\n",
      "               1.401484489440918,\n",
      "               1.4017407894134521,\n",
      "               1.4019010066986084,\n",
      "               1.4019755125045776]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.6823,\n",
      "                 0.7179,\n",
      "                 0.3373,\n",
      "                 0.1176,\n",
      "                 0.0078,\n",
      "                 0.001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8724346160888672,\n",
      "               0.8570191264152527,\n",
      "               0.9238578081130981,\n",
      "               1.1981556415557861,\n",
      "               1.4960057735443115,\n",
      "               1.749363660812378,\n",
      "               1.9602845907211304,\n",
      "               2.144737958908081,\n",
      "               2.3052544593811035,\n",
      "               2.4368197917938232,\n",
      "               2.536832809448242,\n",
      "               2.648881435394287,\n",
      "               2.7453346252441406,\n",
      "               2.8269476890563965,\n",
      "               2.897712230682373,\n",
      "               2.9596619606018066,\n",
      "               3.014129638671875,\n",
      "               3.061610698699951,\n",
      "               3.1022629737854004,\n",
      "               3.1373047828674316,\n",
      "               3.1675314903259277,\n",
      "               3.193424940109253,\n",
      "               3.2156410217285156,\n",
      "               3.2345969676971436,\n",
      "               3.2508552074432373,\n",
      "               3.264831066131592,\n",
      "               3.2767035961151123,\n",
      "               3.2866179943084717,\n",
      "               3.2948455810546875,\n",
      "               3.301654100418091,\n",
      "               3.307232618331909,\n",
      "               3.3117518424987793,\n",
      "               3.315347194671631,\n",
      "               3.318159818649292,\n",
      "               3.3202991485595703,\n",
      "               3.321861743927002,\n",
      "               3.3229281902313232,\n",
      "               3.323577880859375,\n",
      "               3.323871612548828]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.539,\n",
      "                 0.6351,\n",
      "                 0.2397,\n",
      "                 0.095,\n",
      "                 0.0264,\n",
      "                 0.0018,\n",
      "                 0.0005,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9208587408065796,\n",
      "               0.989219069480896,\n",
      "               1.1107882261276245,\n",
      "               1.200494408607483,\n",
      "               1.2716339826583862,\n",
      "               1.3521466255187988,\n",
      "               1.4358800649642944,\n",
      "               1.515190839767456,\n",
      "               1.59038507938385,\n",
      "               1.6563198566436768,\n",
      "               1.714007019996643,\n",
      "               1.7651153802871704,\n",
      "               1.81235671043396,\n",
      "               1.8533658981323242,\n",
      "               1.890323281288147,\n",
      "               1.9227869510650635,\n",
      "               1.9512370824813843,\n",
      "               1.9763505458831787,\n",
      "               1.9979135990142822,\n",
      "               2.0170741081237793,\n",
      "               2.033708095550537,\n",
      "               2.0480856895446777,\n",
      "               2.060529947280884,\n",
      "               2.071132183074951,\n",
      "               2.0802292823791504,\n",
      "               2.087958812713623,\n",
      "               2.094571352005005,\n",
      "               2.100142478942871,\n",
      "               2.104851245880127,\n",
      "               2.108767509460449,\n",
      "               2.1120076179504395,\n",
      "               2.114633321762085,\n",
      "               2.116734266281128,\n",
      "               2.1183829307556152,\n",
      "               2.119652032852173,\n",
      "               2.120582103729248,\n",
      "               2.1212172508239746,\n",
      "               2.121609687805176,\n",
      "               2.121783971786499]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.5955,\n",
      "                 0.5744,\n",
      "                 0.2519,\n",
      "                 0.1433,\n",
      "                 0.0315,\n",
      "                 0.005,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9431110620498657,\n",
      "               1.0340406894683838,\n",
      "               1.2972091436386108,\n",
      "               1.662835717201233,\n",
      "               2.175403118133545,\n",
      "               2.670989751815796,\n",
      "               3.123981475830078,\n",
      "               3.527355194091797,\n",
      "               3.8831050395965576,\n",
      "               4.198282718658447,\n",
      "               4.476532459259033,\n",
      "               4.720009803771973,\n",
      "               4.931928634643555,\n",
      "               5.114773750305176,\n",
      "               5.2751874923706055,\n",
      "               5.414597511291504,\n",
      "               5.535654544830322,\n",
      "               5.639773368835449,\n",
      "               5.730340003967285,\n",
      "               5.809410572052002,\n",
      "               5.8776044845581055,\n",
      "               5.936397552490234,\n",
      "               5.986678600311279,\n",
      "               6.029568672180176,\n",
      "               6.066018104553223,\n",
      "               6.096957206726074,\n",
      "               6.123220443725586,\n",
      "               6.145397663116455,\n",
      "               6.163724422454834,\n",
      "               6.1787872314453125,\n",
      "               6.191059589385986,\n",
      "               6.200988292694092,\n",
      "               6.208870887756348,\n",
      "               6.215006351470947,\n",
      "               6.219625473022461,\n",
      "               6.222973823547363,\n",
      "               6.225258827209473,\n",
      "               6.226635932922363,\n",
      "               6.22725772857666]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9587,\n",
      "                 0.6801,\n",
      "                 0.509,\n",
      "                 0.1669,\n",
      "                 0.0407,\n",
      "                 0.0066,\n",
      "                 0.0005,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9932071566581726,\n",
      "               1.2942757606506348,\n",
      "               1.6323162317276,\n",
      "               1.9299373626708984,\n",
      "               2.007239580154419,\n",
      "               2.081573009490967,\n",
      "               2.164893627166748,\n",
      "               2.2408080101013184,\n",
      "               2.3087594509124756,\n",
      "               2.3696398735046387,\n",
      "               2.4229531288146973,\n",
      "               2.4700841903686523,\n",
      "               2.5101261138916016,\n",
      "               2.5438826084136963,\n",
      "               2.573230028152466,\n",
      "               2.599081039428711,\n",
      "               2.621858596801758,\n",
      "               2.6417224407196045,\n",
      "               2.659022092819214,\n",
      "               2.6732327938079834,\n",
      "               2.68522047996521,\n",
      "               2.6955504417419434,\n",
      "               2.7044010162353516,\n",
      "               2.7121143341064453,\n",
      "               2.7186548709869385,\n",
      "               2.724400520324707,\n",
      "               2.7294740676879883,\n",
      "               2.7337846755981445,\n",
      "               2.7373931407928467,\n",
      "               2.7403724193573,\n",
      "               2.742802381515503,\n",
      "               2.744739055633545,\n",
      "               2.7462871074676514,\n",
      "               2.7474827766418457,\n",
      "               2.748387575149536,\n",
      "               2.749049425125122,\n",
      "               2.7495033740997314,\n",
      "               2.7497799396514893,\n",
      "               2.749905586242676]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.4125,\n",
      "                 1.4767,\n",
      "                 0.8057,\n",
      "                 0.4178,\n",
      "                 0.1412,\n",
      "                 0.0414,\n",
      "                 0.0153,\n",
      "                 0.003,\n",
      "                 0.0011,\n",
      "                 0.0004,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9022563099861145,\n",
      "               0.8695976138114929,\n",
      "               0.847976565361023,\n",
      "               0.8982780575752258,\n",
      "               0.8551149368286133,\n",
      "               0.7623961567878723,\n",
      "               0.6887131929397583,\n",
      "               0.6379467844963074,\n",
      "               0.6070095896720886,\n",
      "               0.5927203297615051,\n",
      "               0.5869659781455994,\n",
      "               0.5867882966995239,\n",
      "               0.5910661816596985,\n",
      "               0.5981022119522095,\n",
      "               0.6063907146453857,\n",
      "               0.6153331995010376,\n",
      "               0.6242251396179199,\n",
      "               0.6328312754631042,\n",
      "               0.6412855386734009,\n",
      "               0.6491311192512512,\n",
      "               0.6562579870223999,\n",
      "               0.6626197695732117,\n",
      "               0.6681987047195435,\n",
      "               0.6730783581733704,\n",
      "               0.6774094700813293,\n",
      "               0.6811244487762451,\n",
      "               0.6842960119247437,\n",
      "               0.6870023608207703,\n",
      "               0.6892914772033691,\n",
      "               0.6912091374397278,\n",
      "               0.6927981376647949,\n",
      "               0.6940909624099731,\n",
      "               0.6951195597648621,\n",
      "               0.6959272027015686,\n",
      "               0.6965500712394714,\n",
      "               0.6970116496086121,\n",
      "               0.697331964969635,\n",
      "               0.6975277662277222,\n",
      "               0.6976195573806763]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.0121,\n",
      "                 0.9606,\n",
      "                 0.7218,\n",
      "                 0.3761,\n",
      "                 0.0648,\n",
      "                 0.0245,\n",
      "                 0.0036,\n",
      "                 0.0006,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.8990240097045898,\n",
      "               0.8894222378730774,\n",
      "               0.8901926279067993,\n",
      "               0.9057973623275757,\n",
      "               0.8974281549453735,\n",
      "               0.9141491055488586,\n",
      "               0.9564491510391235,\n",
      "               0.9797012209892273,\n",
      "               1.0160436630249023,\n",
      "               1.0695008039474487,\n",
      "               1.127197027206421,\n",
      "               1.1779520511627197,\n",
      "               1.217982292175293,\n",
      "               1.2536919116973877,\n",
      "               1.2865339517593384,\n",
      "               1.3163601160049438,\n",
      "               1.3437025547027588,\n",
      "               1.3677109479904175,\n",
      "               1.386907696723938,\n",
      "               1.4029557704925537,\n",
      "               1.4178295135498047,\n",
      "               1.4307901859283447,\n",
      "               1.4416625499725342,\n",
      "               1.4508707523345947,\n",
      "               1.4586018323898315,\n",
      "               1.4649903774261475,\n",
      "               1.4705722332000732,\n",
      "               1.4753477573394775,\n",
      "               1.4793119430541992,\n",
      "               1.4825718402862549,\n",
      "               1.485174298286438,\n",
      "               1.4872745275497437,\n",
      "               1.4889237880706787,\n",
      "               1.4902112483978271,\n",
      "               1.491180181503296,\n",
      "               1.4918745756149292,\n",
      "               1.4923465251922607,\n",
      "               1.4926317930221558,\n",
      "               1.4927594661712646]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.847,\n",
      "                 0.9077,\n",
      "                 0.4116,\n",
      "                 0.0925,\n",
      "                 0.0422,\n",
      "                 0.0026,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               0.9983617067337036,\n",
      "               1.4365310668945312,\n",
      "               2.2798523902893066,\n",
      "               3.180401563644409,\n",
      "               3.913569688796997,\n",
      "               4.563401222229004,\n",
      "               5.118494987487793,\n",
      "               5.60410737991333,\n",
      "               5.994487762451172,\n",
      "               6.320742130279541,\n",
      "               6.592967987060547,\n",
      "               6.824951171875,\n",
      "               7.018597602844238,\n",
      "               7.181664943695068,\n",
      "               7.318441867828369,\n",
      "               7.434622764587402,\n",
      "               7.533326625823975,\n",
      "               7.61846923828125,\n",
      "               7.691688537597656,\n",
      "               7.754571437835693,\n",
      "               7.808312892913818,\n",
      "               7.854438781738281,\n",
      "               7.893718719482422,\n",
      "               7.9272260665893555,\n",
      "               7.955784797668457,\n",
      "               7.979874610900879,\n",
      "               8.000232696533203,\n",
      "               8.017383575439453,\n",
      "               8.031759262084961,\n",
      "               8.043747901916504,\n",
      "               8.053624153137207,\n",
      "               8.061699867248535,\n",
      "               8.068123817443848,\n",
      "               8.073125839233398,\n",
      "               8.076906204223633,\n",
      "               8.07967758178711,\n",
      "               8.081598281860352,\n",
      "               8.082759857177734,\n",
      "               8.083300590515137]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.4139,\n",
      "                 0.3237,\n",
      "                 0.1034,\n",
      "                 0.037,\n",
      "                 0.0057,\n",
      "                 0.0006,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9134084582328796,\n",
      "               1.009691596031189,\n",
      "               1.4062917232513428,\n",
      "               1.909832239151001,\n",
      "               2.323000907897949,\n",
      "               2.663391590118408,\n",
      "               2.9333741664886475,\n",
      "               3.149416446685791,\n",
      "               3.3204963207244873,\n",
      "               3.4592385292053223,\n",
      "               3.5859005451202393,\n",
      "               3.699673891067505,\n",
      "               3.802902936935425,\n",
      "               3.8894760608673096,\n",
      "               3.963146209716797,\n",
      "               4.027250289916992,\n",
      "               4.081948757171631,\n",
      "               4.129088878631592,\n",
      "               4.169329643249512,\n",
      "               4.204380035400391,\n",
      "               4.235095024108887,\n",
      "               4.261129379272461,\n",
      "               4.283307075500488,\n",
      "               4.302762985229492,\n",
      "               4.319625377655029,\n",
      "               4.333990573883057,\n",
      "               4.346235275268555,\n",
      "               4.356517791748047,\n",
      "               4.365201473236084,\n",
      "               4.3724565505981445,\n",
      "               4.378560543060303,\n",
      "               4.3835883140563965,\n",
      "               4.387653350830078,\n",
      "               4.390906810760498,\n",
      "               4.393462181091309,\n",
      "               4.395410537719727,\n",
      "               4.396830081939697,\n",
      "               4.397788047790527,\n",
      "               4.39837121963501,\n",
      "               4.3986358642578125]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.9781,\n",
      "                 0.6521,\n",
      "                 0.8704,\n",
      "                 0.5476,\n",
      "                 0.4688,\n",
      "                 0.2493,\n",
      "                 0.2126,\n",
      "                 0.0697,\n",
      "                 0.0427,\n",
      "                 0.0078,\n",
      "                 0.007,\n",
      "                 0.0013,\n",
      "                 0.0003,\n",
      "                 0.0005,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8983932733535767,\n",
      "               0.8300657272338867,\n",
      "               0.7690248489379883,\n",
      "               0.6958473920822144,\n",
      "               0.6119055151939392,\n",
      "               0.5733315348625183,\n",
      "               0.5385193824768066,\n",
      "               0.5101251602172852,\n",
      "               0.49516838788986206,\n",
      "               0.4859873354434967,\n",
      "               0.48417964577674866,\n",
      "               0.48605474829673767,\n",
      "               0.4892845153808594,\n",
      "               0.4918098449707031,\n",
      "               0.49282121658325195,\n",
      "               0.49312925338745117,\n",
      "               0.49305152893066406,\n",
      "               0.49314895272254944,\n",
      "               0.4931280016899109,\n",
      "               0.49269428849220276,\n",
      "               0.4922749400138855,\n",
      "               0.49187159538269043,\n",
      "               0.4914949834346771,\n",
      "               0.49106138944625854,\n",
      "               0.4906577169895172,\n",
      "               0.49027085304260254,\n",
      "               0.4898884892463684,\n",
      "               0.4894859194755554,\n",
      "               0.48912715911865234,\n",
      "               0.48878973722457886,\n",
      "               0.48849257826805115,\n",
      "               0.48821982741355896,\n",
      "               0.4879278540611267,\n",
      "               0.48769792914390564,\n",
      "               0.4875088632106781,\n",
      "               0.48735880851745605,\n",
      "               0.4872516989707947,\n",
      "               0.487179696559906,\n",
      "               0.4871358275413513,\n",
      "               0.4871174693107605]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.6273,\n",
      "                 0.1569,\n",
      "                 1.0306,\n",
      "                 0.5808,\n",
      "                 0.4237,\n",
      "                 0.278,\n",
      "                 0.0905,\n",
      "                 0.18,\n",
      "                 0.0342,\n",
      "                 0.0509,\n",
      "                 0.0246,\n",
      "                 0.0014,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9153211712837219,\n",
      "               0.8792917132377625,\n",
      "               0.8261871337890625,\n",
      "               0.8460984230041504,\n",
      "               1.0619096755981445,\n",
      "               1.0770785808563232,\n",
      "               1.1320613622665405,\n",
      "               1.1978594064712524,\n",
      "               1.2588413953781128,\n",
      "               1.3096287250518799,\n",
      "               1.3533484935760498,\n",
      "               1.3894965648651123,\n",
      "               1.4189194440841675,\n",
      "               1.442551851272583,\n",
      "               1.4624207019805908,\n",
      "               1.4789186716079712,\n",
      "               1.4927669763565063,\n",
      "               1.504163146018982,\n",
      "               1.513439416885376,\n",
      "               1.5208406448364258,\n",
      "               1.526827096939087,\n",
      "               1.5316531658172607,\n",
      "               1.5356824398040771,\n",
      "               1.538902997970581,\n",
      "               1.5414988994598389,\n",
      "               1.543573260307312,\n",
      "               1.5452301502227783,\n",
      "               1.5465431213378906,\n",
      "               1.5475881099700928,\n",
      "               1.5484273433685303,\n",
      "               1.549108862876892,\n",
      "               1.5496408939361572,\n",
      "               1.5500690937042236,\n",
      "               1.5504150390625,\n",
      "               1.5506889820098877,\n",
      "               1.550891637802124,\n",
      "               1.5510351657867432,\n",
      "               1.5511281490325928,\n",
      "               1.5511796474456787,\n",
      "               1.5511993169784546]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.1949,\n",
      "                 0.9392,\n",
      "                 0.5965,\n",
      "                 0.3625,\n",
      "                 0.2903,\n",
      "                 0.2584,\n",
      "                 0.1771,\n",
      "                 0.0432,\n",
      "                 0.0118,\n",
      "                 0.0105,\n",
      "                 0.0015,\n",
      "                 0.0007,\n",
      "                 0.0005,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9124123454093933,\n",
      "               0.9207112193107605,\n",
      "               0.9635499715805054,\n",
      "               0.9673455357551575,\n",
      "               0.9755115509033203,\n",
      "               0.9970033764839172,\n",
      "               1.0385841131210327,\n",
      "               1.0805962085723877,\n",
      "               1.1224210262298584,\n",
      "               1.160507321357727,\n",
      "               1.1919970512390137,\n",
      "               1.218437910079956,\n",
      "               1.2401140928268433,\n",
      "               1.2573521137237549,\n",
      "               1.2711031436920166,\n",
      "               1.2814997434616089,\n",
      "               1.28920578956604,\n",
      "               1.2956230640411377,\n",
      "               1.3006775379180908,\n",
      "               1.3044426441192627,\n",
      "               1.3072404861450195,\n",
      "               1.3093656301498413,\n",
      "               1.3109726905822754,\n",
      "               1.3121693134307861,\n",
      "               1.3130455017089844,\n",
      "               1.313677430152893,\n",
      "               1.3141359090805054,\n",
      "               1.3144502639770508,\n",
      "               1.3146626949310303,\n",
      "               1.3147810697555542,\n",
      "               1.3148410320281982,\n",
      "               1.3148576021194458,\n",
      "               1.3148504495620728,\n",
      "               1.3147876262664795,\n",
      "               1.3147268295288086,\n",
      "               1.3146650791168213,\n",
      "               1.314610481262207,\n",
      "               1.3145663738250732,\n",
      "               1.314537763595581,\n",
      "               1.3145283460617065]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0994,\n",
      "                 0.7162,\n",
      "                 0.6473,\n",
      "                 0.4511,\n",
      "                 0.358,\n",
      "                 0.024,\n",
      "                 0.0083,\n",
      "                 0.0568,\n",
      "                 0.0004,\n",
      "                 0.0126,\n",
      "                 0.0009,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9454461932182312,\n",
      "               1.2548340559005737,\n",
      "               2.0159661769866943,\n",
      "               3.424645185470581,\n",
      "               4.44680118560791,\n",
      "               4.920659065246582,\n",
      "               5.2460737228393555,\n",
      "               5.482044219970703,\n",
      "               5.65631103515625,\n",
      "               5.788677215576172,\n",
      "               5.885854721069336,\n",
      "               5.960512161254883,\n",
      "               6.019158363342285,\n",
      "               6.0640387535095215,\n",
      "               6.0981903076171875,\n",
      "               6.1243157386779785,\n",
      "               6.1454386711120605,\n",
      "               6.162587642669678,\n",
      "               6.176035404205322,\n",
      "               6.186635494232178,\n",
      "               6.194985866546631,\n",
      "               6.201452732086182,\n",
      "               6.206489086151123,\n",
      "               6.210352897644043,\n",
      "               6.213263511657715,\n",
      "               6.215512275695801,\n",
      "               6.217255592346191,\n",
      "               6.218605041503906,\n",
      "               6.21962308883667,\n",
      "               6.220395088195801,\n",
      "               6.220961570739746,\n",
      "               6.22140645980835,\n",
      "               6.2217607498168945,\n",
      "               6.222011089324951,\n",
      "               6.222184181213379,\n",
      "               6.222303867340088,\n",
      "               6.222378730773926,\n",
      "               6.22241735458374,\n",
      "               6.2224321365356445,\n",
      "               6.222434997558594]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.2439,\n",
      "                 0.7586,\n",
      "                 0.5929,\n",
      "                 0.7496,\n",
      "                 0.326,\n",
      "                 0.2995,\n",
      "                 0.1404,\n",
      "                 0.1024,\n",
      "                 0.0173,\n",
      "                 0.0066,\n",
      "                 0.0011,\n",
      "                 0.0008,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9214400053024292,\n",
      "               0.937674343585968,\n",
      "               0.9499601125717163,\n",
      "               0.9627464413642883,\n",
      "               0.9220024347305298,\n",
      "               0.9829843640327454,\n",
      "               0.9998788833618164,\n",
      "               0.998744785785675,\n",
      "               0.9980704188346863,\n",
      "               0.9827090501785278,\n",
      "               0.9668592214584351,\n",
      "               0.948552131652832,\n",
      "               0.933857262134552,\n",
      "               0.9254934191703796,\n",
      "               0.9162090420722961,\n",
      "               0.9079648852348328,\n",
      "               0.9016240835189819,\n",
      "               0.8968775868415833,\n",
      "               0.8928488492965698,\n",
      "               0.8894429206848145,\n",
      "               0.8866698145866394,\n",
      "               0.8843849301338196,\n",
      "               0.8825154304504395,\n",
      "               0.8808385133743286,\n",
      "               0.8794324994087219,\n",
      "               0.8783063888549805,\n",
      "               0.8773671388626099,\n",
      "               0.8762496113777161,\n",
      "               0.8753673434257507,\n",
      "               0.87464839220047,\n",
      "               0.8740957379341125,\n",
      "               0.8736580610275269,\n",
      "               0.8732963800430298,\n",
      "               0.8730038404464722,\n",
      "               0.8727858662605286,\n",
      "               0.8726259469985962,\n",
      "               0.8725029230117798,\n",
      "               0.8724200129508972,\n",
      "               0.8723772168159485,\n",
      "               0.8723635673522949]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.5189,\n",
      "                 0.9399,\n",
      "                 0.5621,\n",
      "                 0.4277,\n",
      "                 0.1619,\n",
      "                 0.2584,\n",
      "                 0.0646,\n",
      "                 0.0577,\n",
      "                 0.0039,\n",
      "                 0.0071,\n",
      "                 0.001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8873432278633118,\n",
      "               0.8600203394889832,\n",
      "               0.8970314264297485,\n",
      "               0.8159605860710144,\n",
      "               0.8567188382148743,\n",
      "               0.9693486094474792,\n",
      "               1.0635912418365479,\n",
      "               1.1435167789459229,\n",
      "               1.2167333364486694,\n",
      "               1.2734423875808716,\n",
      "               1.3159831762313843,\n",
      "               1.3493902683258057,\n",
      "               1.377119779586792,\n",
      "               1.397566795349121,\n",
      "               1.4130762815475464,\n",
      "               1.4248225688934326,\n",
      "               1.4336786270141602,\n",
      "               1.4400230646133423,\n",
      "               1.444440245628357,\n",
      "               1.4476134777069092,\n",
      "               1.4497480392456055,\n",
      "               1.451233148574829,\n",
      "               1.452122449874878,\n",
      "               1.4526112079620361,\n",
      "               1.4527451992034912,\n",
      "               1.4527252912521362,\n",
      "               1.4525020122528076,\n",
      "               1.4521726369857788,\n",
      "               1.451734185218811,\n",
      "               1.4512869119644165,\n",
      "               1.4508568048477173,\n",
      "               1.4503952264785767,\n",
      "               1.450008749961853,\n",
      "               1.449612021446228,\n",
      "               1.4492448568344116,\n",
      "               1.4489418268203735,\n",
      "               1.448690414428711,\n",
      "               1.4484937191009521,\n",
      "               1.448366403579712,\n",
      "               1.4483143091201782]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0559,\n",
      "                 0.7204,\n",
      "                 0.9201,\n",
      "                 0.5537,\n",
      "                 0.2995,\n",
      "                 0.29,\n",
      "                 0.0987,\n",
      "                 0.0468,\n",
      "                 0.0182,\n",
      "                 0.0099,\n",
      "                 0.0014,\n",
      "                 0.0004,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9044263958930969,\n",
      "               0.8630855679512024,\n",
      "               0.889308750629425,\n",
      "               1.0448015928268433,\n",
      "               1.2355364561080933,\n",
      "               1.4455156326293945,\n",
      "               1.6004507541656494,\n",
      "               1.7229715585708618,\n",
      "               1.8241112232208252,\n",
      "               1.90475594997406,\n",
      "               1.9695478677749634,\n",
      "               2.0199713706970215,\n",
      "               2.0598747730255127,\n",
      "               2.0907483100891113,\n",
      "               2.114356517791748,\n",
      "               2.133269786834717,\n",
      "               2.1485209465026855,\n",
      "               2.1603026390075684,\n",
      "               2.1695189476013184,\n",
      "               2.176687717437744,\n",
      "               2.1822361946105957,\n",
      "               2.1874804496765137,\n",
      "               2.191617727279663,\n",
      "               2.194958448410034,\n",
      "               2.1976661682128906,\n",
      "               2.1998157501220703,\n",
      "               2.201472759246826,\n",
      "               2.2028675079345703,\n",
      "               2.204206943511963,\n",
      "               2.205324649810791,\n",
      "               2.2062597274780273,\n",
      "               2.207045555114746,\n",
      "               2.207714319229126,\n",
      "               2.208204984664917,\n",
      "               2.208595037460327,\n",
      "               2.208859920501709,\n",
      "               2.20906138420105,\n",
      "               2.209171772003174,\n",
      "               2.2092461585998535,\n",
      "               2.2092628479003906]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7572,\n",
      "                 0.5845,\n",
      "                 1.0427,\n",
      "                 0.1842,\n",
      "                 0.3133,\n",
      "                 0.0954,\n",
      "                 0.0402,\n",
      "                 0.0388,\n",
      "                 0.0063,\n",
      "                 0.0032,\n",
      "                 0.0006,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9057896733283997,\n",
      "               0.993625283241272,\n",
      "               1.3089627027511597,\n",
      "               1.6552460193634033,\n",
      "               2.149381637573242,\n",
      "               2.6546971797943115,\n",
      "               3.119081497192383,\n",
      "               3.4836506843566895,\n",
      "               3.7739322185516357,\n",
      "               4.008151054382324,\n",
      "               4.1947455406188965,\n",
      "               4.34343957901001,\n",
      "               4.463801383972168,\n",
      "               4.560418128967285,\n",
      "               4.638071537017822,\n",
      "               4.69933557510376,\n",
      "               4.74852991104126,\n",
      "               4.787994861602783,\n",
      "               4.819046974182129,\n",
      "               4.843595027923584,\n",
      "               4.862889289855957,\n",
      "               4.87802791595459,\n",
      "               4.889925003051758,\n",
      "               4.8993048667907715,\n",
      "               4.906674861907959,\n",
      "               4.912413120269775,\n",
      "               4.916888236999512,\n",
      "               4.920359134674072,\n",
      "               4.923029899597168,\n",
      "               4.925101280212402,\n",
      "               4.926697731018066,\n",
      "               4.9279069900512695,\n",
      "               4.928810119628906,\n",
      "               4.929501056671143,\n",
      "               4.9300127029418945,\n",
      "               4.93037748336792,\n",
      "               4.930617809295654,\n",
      "               4.930761814117432,\n",
      "               4.930826663970947,\n",
      "               4.930845737457275]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.8737,\n",
      "                 0.7545,\n",
      "                 0.7641,\n",
      "                 0.6643,\n",
      "                 0.3796,\n",
      "                 0.4811,\n",
      "                 0.2948,\n",
      "                 0.0846,\n",
      "                 0.0206,\n",
      "                 0.0226,\n",
      "                 0.004,\n",
      "                 0.0013,\n",
      "                 0.0006,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9182870984077454,\n",
      "               0.9203489422798157,\n",
      "               1.0241903066635132,\n",
      "               1.0523189306259155,\n",
      "               1.3060163259506226,\n",
      "               1.6839710474014282,\n",
      "               1.977688193321228,\n",
      "               2.207155704498291,\n",
      "               2.400871753692627,\n",
      "               2.5599918365478516,\n",
      "               2.6850080490112305,\n",
      "               2.783521890640259,\n",
      "               2.8625407218933105,\n",
      "               2.925889253616333,\n",
      "               2.975067377090454,\n",
      "               3.0137863159179688,\n",
      "               3.0444183349609375,\n",
      "               3.069002866744995,\n",
      "               3.0882277488708496,\n",
      "               3.10321044921875,\n",
      "               3.1151068210601807,\n",
      "               3.1244382858276367,\n",
      "               3.1317849159240723,\n",
      "               3.1373939514160156,\n",
      "               3.141880512237549,\n",
      "               3.1453633308410645,\n",
      "               3.1479861736297607,\n",
      "               3.149996280670166,\n",
      "               3.1514782905578613,\n",
      "               3.152575731277466,\n",
      "               3.153351068496704,\n",
      "               3.153883695602417,\n",
      "               3.15425443649292,\n",
      "               3.154508113861084,\n",
      "               3.1546874046325684,\n",
      "               3.1547627449035645,\n",
      "               3.1548047065734863,\n",
      "               3.154829502105713,\n",
      "               3.1548385620117188,\n",
      "               3.1548404693603516]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.3696,\n",
      "                 0.6927,\n",
      "                 0.3993,\n",
      "                 0.1896,\n",
      "                 0.1409,\n",
      "                 0.1155,\n",
      "                 0.0653,\n",
      "                 0.0053,\n",
      "                 0.002,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9077681303024292,\n",
      "               1.0022069215774536,\n",
      "               1.265740156173706,\n",
      "               1.6098690032958984,\n",
      "               2.3378453254699707,\n",
      "               3.053328275680542,\n",
      "               3.671860456466675,\n",
      "               4.159350395202637,\n",
      "               4.553829193115234,\n",
      "               4.867434024810791,\n",
      "               5.115394115447998,\n",
      "               5.31374979019165,\n",
      "               5.469098091125488,\n",
      "               5.5908355712890625,\n",
      "               5.684199810028076,\n",
      "               5.757258415222168,\n",
      "               5.814682960510254,\n",
      "               5.859850883483887,\n",
      "               5.895142555236816,\n",
      "               5.9228081703186035,\n",
      "               5.944665431976318,\n",
      "               5.9619832038879395,\n",
      "               5.975852966308594,\n",
      "               5.986845970153809,\n",
      "               5.995429039001465,\n",
      "               6.002164840698242,\n",
      "               6.007509708404541,\n",
      "               6.011660099029541,\n",
      "               6.0149431228637695,\n",
      "               6.0175018310546875,\n",
      "               6.019527912139893,\n",
      "               6.02108907699585,\n",
      "               6.0222578048706055,\n",
      "               6.023159027099609,\n",
      "               6.023830890655518,\n",
      "               6.0243072509765625,\n",
      "               6.02461576461792,\n",
      "               6.024801254272461,\n",
      "               6.024890899658203,\n",
      "               6.0249223709106445]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.6446,\n",
      "                 0.4833,\n",
      "                 1.5207,\n",
      "                 0.4686,\n",
      "                 1.2058,\n",
      "                 0.8099,\n",
      "                 0.6774,\n",
      "                 2.0573,\n",
      "                 0.5706,\n",
      "                 1.189,\n",
      "                 0.6659,\n",
      "                 0.4888,\n",
      "                 1.9828,\n",
      "                 0.2103,\n",
      "                 0.7912,\n",
      "                 0.4701,\n",
      "                 0.7343,\n",
      "                 0.5019,\n",
      "                 0.0888,\n",
      "                 0.1159,\n",
      "                 0.0687,\n",
      "                 0.783,\n",
      "                 0.2668,\n",
      "                 0.3214,\n",
      "                 0.0549,\n",
      "                 0.0029,\n",
      "                 0.037,\n",
      "                 0.0325,\n",
      "                 0.0153,\n",
      "                 0.0071,\n",
      "                 0.0058,\n",
      "                 0.0028,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0004,\n",
      "                 0.0001,\n",
      "                 0.0008,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9123034477233887,\n",
      "               0.9933615922927856,\n",
      "               1.3898522853851318,\n",
      "               1.384514331817627,\n",
      "               1.5989856719970703,\n",
      "               1.7302898168563843,\n",
      "               1.8240604400634766,\n",
      "               1.8724143505096436,\n",
      "               1.8929344415664673,\n",
      "               1.898404836654663,\n",
      "               1.904057264328003,\n",
      "               1.9092098474502563,\n",
      "               1.9088932275772095,\n",
      "               1.9123411178588867,\n",
      "               1.919504165649414,\n",
      "               1.922306776046753,\n",
      "               1.9257705211639404,\n",
      "               1.9269746541976929,\n",
      "               1.9294601678848267,\n",
      "               1.9318149089813232,\n",
      "               1.933638334274292,\n",
      "               1.9349571466445923,\n",
      "               1.9375298023223877,\n",
      "               1.9414056539535522,\n",
      "               1.944575548171997,\n",
      "               1.9472911357879639,\n",
      "               1.9501278400421143,\n",
      "               1.9517780542373657,\n",
      "               1.9525725841522217,\n",
      "               1.952736258506775,\n",
      "               1.9526937007904053,\n",
      "               1.9533121585845947,\n",
      "               1.953667402267456,\n",
      "               1.9541137218475342,\n",
      "               1.954355239868164,\n",
      "               1.9544779062271118,\n",
      "               1.954874038696289,\n",
      "               1.9551780223846436,\n",
      "               1.9552713632583618,\n",
      "               1.9553312063217163]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6555,\n",
      "                 0.4653,\n",
      "                 1.2595,\n",
      "                 0.5888,\n",
      "                 1.0648,\n",
      "                 0.3911,\n",
      "                 0.4195,\n",
      "                 0.3092,\n",
      "                 0.3332,\n",
      "                 0.4564,\n",
      "                 0.5413,\n",
      "                 0.2638,\n",
      "                 0.2449,\n",
      "                 0.2997,\n",
      "                 0.2442,\n",
      "                 0.5445,\n",
      "                 0.0997,\n",
      "                 0.4037,\n",
      "                 0.147,\n",
      "                 0.1323,\n",
      "                 0.124,\n",
      "                 0.054,\n",
      "                 0.0834,\n",
      "                 0.1043,\n",
      "                 0.0238,\n",
      "                 0.0103,\n",
      "                 0.0076,\n",
      "                 0.0026,\n",
      "                 0.0124,\n",
      "                 0.0279,\n",
      "                 0.0023,\n",
      "                 0.0002,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8812467455863953,\n",
      "               0.8618006706237793,\n",
      "               0.8010621070861816,\n",
      "               1.034484624862671,\n",
      "               1.4510871171951294,\n",
      "               1.694393515586853,\n",
      "               1.717678427696228,\n",
      "               1.667933464050293,\n",
      "               1.6252845525741577,\n",
      "               1.59799063205719,\n",
      "               1.57157301902771,\n",
      "               1.5561374425888062,\n",
      "               1.5440174341201782,\n",
      "               1.5342556238174438,\n",
      "               1.528246521949768,\n",
      "               1.5234519243240356,\n",
      "               1.5197972059249878,\n",
      "               1.5146220922470093,\n",
      "               1.5098613500595093,\n",
      "               1.5064644813537598,\n",
      "               1.503808617591858,\n",
      "               1.5016542673110962,\n",
      "               1.4994897842407227,\n",
      "               1.4983174800872803,\n",
      "               1.4967319965362549,\n",
      "               1.4954177141189575,\n",
      "               1.4939402341842651,\n",
      "               1.4943673610687256,\n",
      "               1.4935271739959717,\n",
      "               1.4925569295883179,\n",
      "               1.492008924484253,\n",
      "               1.4916586875915527,\n",
      "               1.4912118911743164,\n",
      "               1.490888237953186,\n",
      "               1.4904217720031738,\n",
      "               1.4901800155639648,\n",
      "               1.4900137186050415,\n",
      "               1.489805817604065,\n",
      "               1.4896509647369385,\n",
      "               1.4896091222763062]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.433,\n",
      "                 0.445,\n",
      "                 1.0237,\n",
      "                 0.2379,\n",
      "                 0.8753,\n",
      "                 1.4571,\n",
      "                 0.592,\n",
      "                 1.2122,\n",
      "                 0.6221,\n",
      "                 0.5575,\n",
      "                 0.3551,\n",
      "                 0.1984,\n",
      "                 0.533,\n",
      "                 0.7544,\n",
      "                 0.7361,\n",
      "                 0.0581,\n",
      "                 0.3702,\n",
      "                 0.0351,\n",
      "                 0.3536,\n",
      "                 0.0183,\n",
      "                 0.6261,\n",
      "                 0.5036,\n",
      "                 0.0046,\n",
      "                 0.1031,\n",
      "                 0.0192,\n",
      "                 0.007,\n",
      "                 0.0024,\n",
      "                 0.0194,\n",
      "                 0.0006,\n",
      "                 0.0046,\n",
      "                 0.0147,\n",
      "                 0.0036,\n",
      "                 0.0001,\n",
      "                 0.0003,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8916769027709961,\n",
      "               1.1164515018463135,\n",
      "               1.2464544773101807,\n",
      "               1.012570858001709,\n",
      "               1.350158929824829,\n",
      "               1.5629198551177979,\n",
      "               1.6827129125595093,\n",
      "               1.7553869485855103,\n",
      "               1.8015257120132446,\n",
      "               1.8264377117156982,\n",
      "               1.831565499305725,\n",
      "               1.8368873596191406,\n",
      "               1.8420155048370361,\n",
      "               1.8458229303359985,\n",
      "               1.8487484455108643,\n",
      "               1.8487796783447266,\n",
      "               1.8506065607070923,\n",
      "               1.8536659479141235,\n",
      "               1.8560765981674194,\n",
      "               1.8590847253799438,\n",
      "               1.8628000020980835,\n",
      "               1.8699127435684204,\n",
      "               1.8721351623535156,\n",
      "               1.8737032413482666,\n",
      "               1.875694990158081,\n",
      "               1.8776781558990479,\n",
      "               1.878868818283081,\n",
      "               1.880025863647461,\n",
      "               1.88271963596344,\n",
      "               1.8848350048065186,\n",
      "               1.8870480060577393,\n",
      "               1.888810396194458,\n",
      "               1.8896706104278564,\n",
      "               1.8897072076797485,\n",
      "               1.8904564380645752,\n",
      "               1.8913017511367798,\n",
      "               1.8919250965118408,\n",
      "               1.8925071954727173,\n",
      "               1.8928896188735962,\n",
      "               1.8929884433746338]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.4026,\n",
      "                 0.7255,\n",
      "                 1.3889,\n",
      "                 0.6662,\n",
      "                 1.148,\n",
      "                 0.6791,\n",
      "                 0.2391,\n",
      "                 0.7203,\n",
      "                 0.0959,\n",
      "                 0.3237,\n",
      "                 0.0908,\n",
      "                 1.6928,\n",
      "                 0.3992,\n",
      "                 0.4006,\n",
      "                 1.13,\n",
      "                 1.1383,\n",
      "                 0.0134,\n",
      "                 0.9258,\n",
      "                 0.1407,\n",
      "                 0.071,\n",
      "                 0.0023,\n",
      "                 0.7953,\n",
      "                 0.001,\n",
      "                 0.1521,\n",
      "                 0.0024,\n",
      "                 0.0057,\n",
      "                 0.0003,\n",
      "                 0.0037,\n",
      "                 0.0091,\n",
      "                 0.006,\n",
      "                 0.0243,\n",
      "                 0.0221,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0018,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [1.0044547319412231,\n",
      "               1.937803030014038,\n",
      "               1.85592782497406,\n",
      "               2.367948055267334,\n",
      "               1.575319766998291,\n",
      "               2.1045846939086914,\n",
      "               2.5326132774353027,\n",
      "               2.7619831562042236,\n",
      "               2.8818624019622803,\n",
      "               2.944009780883789,\n",
      "               2.9753408432006836,\n",
      "               3.0026156902313232,\n",
      "               3.019364833831787,\n",
      "               3.0377261638641357,\n",
      "               3.0481390953063965,\n",
      "               3.059936046600342,\n",
      "               3.0680148601531982,\n",
      "               3.0759143829345703,\n",
      "               3.0852246284484863,\n",
      "               3.095223903656006,\n",
      "               3.103891134262085,\n",
      "               3.1097114086151123,\n",
      "               3.1144142150878906,\n",
      "               3.123953104019165,\n",
      "               3.1286072731018066,\n",
      "               3.130695343017578,\n",
      "               3.1349377632141113,\n",
      "               3.1400146484375,\n",
      "               3.1443352699279785,\n",
      "               3.148036479949951,\n",
      "               3.15024995803833,\n",
      "               3.1531968116760254,\n",
      "               3.1559600830078125,\n",
      "               3.1571426391601562,\n",
      "               3.1581408977508545,\n",
      "               3.159412384033203,\n",
      "               3.1603751182556152,\n",
      "               3.1608452796936035,\n",
      "               3.161038637161255,\n",
      "               3.1611227989196777]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.5168,\n",
      "                 0.3649,\n",
      "                 1.8356,\n",
      "                 0.9429,\n",
      "                 0.9956,\n",
      "                 1.7593,\n",
      "                 0.8942,\n",
      "                 1.5984,\n",
      "                 0.9085,\n",
      "                 0.6127,\n",
      "                 0.2611,\n",
      "                 0.7729,\n",
      "                 1.5671,\n",
      "                 0.1988,\n",
      "                 0.7059,\n",
      "                 0.787,\n",
      "                 0.7324,\n",
      "                 0.585,\n",
      "                 0.0405,\n",
      "                 0.3769,\n",
      "                 0.049,\n",
      "                 0.0905,\n",
      "                 0.1134,\n",
      "                 0.1802,\n",
      "                 0.0177,\n",
      "                 0.0364,\n",
      "                 0.0191,\n",
      "                 0.0024,\n",
      "                 0.0092,\n",
      "                 0.0019,\n",
      "                 0.0036,\n",
      "                 0.0472,\n",
      "                 0.0005,\n",
      "                 0.0014,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0019,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8614534139633179,\n",
      "               0.8441155552864075,\n",
      "               0.8068974614143372,\n",
      "               1.190863013267517,\n",
      "               2.0862345695495605,\n",
      "               2.127715587615967,\n",
      "               2.1297764778137207,\n",
      "               2.0700652599334717,\n",
      "               2.03486967086792,\n",
      "               2.0149593353271484,\n",
      "               2.003171920776367,\n",
      "               1.9927070140838623,\n",
      "               1.9838387966156006,\n",
      "               1.9754400253295898,\n",
      "               1.9700062274932861,\n",
      "               1.9669339656829834,\n",
      "               1.9631192684173584,\n",
      "               1.9590648412704468,\n",
      "               1.955909013748169,\n",
      "               1.9515266418457031,\n",
      "               1.9473886489868164,\n",
      "               1.9449265003204346,\n",
      "               1.943077802658081,\n",
      "               1.9415664672851562,\n",
      "               1.9392673969268799,\n",
      "               1.9375078678131104,\n",
      "               1.9360376596450806,\n",
      "               1.934657096862793,\n",
      "               1.9335308074951172,\n",
      "               1.9322078227996826,\n",
      "               1.9313266277313232,\n",
      "               1.9305884838104248,\n",
      "               1.9299732446670532,\n",
      "               1.9294414520263672,\n",
      "               1.9290024042129517,\n",
      "               1.9285732507705688,\n",
      "               1.928267478942871,\n",
      "               1.927939772605896,\n",
      "               1.927778959274292,\n",
      "               1.9277044534683228]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.0956,\n",
      "                 1.2224,\n",
      "                 0.3798,\n",
      "                 1.321,\n",
      "                 0.7715,\n",
      "                 0.6648,\n",
      "                 0.1136,\n",
      "                 0.6746,\n",
      "                 0.1157,\n",
      "                 0.1048,\n",
      "                 0.4935,\n",
      "                 0.9511,\n",
      "                 0.2983,\n",
      "                 0.1566,\n",
      "                 0.6185,\n",
      "                 0.2052,\n",
      "                 0.2542,\n",
      "                 0.1333,\n",
      "                 0.0238,\n",
      "                 0.0706,\n",
      "                 0.0556,\n",
      "                 0.2207,\n",
      "                 0.0124,\n",
      "                 0.0945,\n",
      "                 0.0214,\n",
      "                 0.0027,\n",
      "                 0.0012,\n",
      "                 0.0139,\n",
      "                 0.0021,\n",
      "                 0.0018,\n",
      "                 0.0022,\n",
      "                 0.0013,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.907230019569397,\n",
      "               0.9672287702560425,\n",
      "               1.0167524814605713,\n",
      "               1.4534963369369507,\n",
      "               2.1940016746520996,\n",
      "               2.655916690826416,\n",
      "               2.834686756134033,\n",
      "               2.8566977977752686,\n",
      "               2.8265483379364014,\n",
      "               2.7850921154022217,\n",
      "               2.7517921924591064,\n",
      "               2.730151653289795,\n",
      "               2.713266134262085,\n",
      "               2.690638780593872,\n",
      "               2.6764626502990723,\n",
      "               2.667039155960083,\n",
      "               2.6557259559631348,\n",
      "               2.6459548473358154,\n",
      "               2.6398634910583496,\n",
      "               2.6337783336639404,\n",
      "               2.627845287322998,\n",
      "               2.622405529022217,\n",
      "               2.61814022064209,\n",
      "               2.6140780448913574,\n",
      "               2.611759901046753,\n",
      "               2.607644557952881,\n",
      "               2.6051032543182373,\n",
      "               2.602828025817871,\n",
      "               2.6006808280944824,\n",
      "               2.599144697189331,\n",
      "               2.597501754760742,\n",
      "               2.594113349914551,\n",
      "               2.591714382171631,\n",
      "               2.590005874633789,\n",
      "               2.5889601707458496,\n",
      "               2.5883939266204834,\n",
      "               2.5876545906066895,\n",
      "               2.587390422821045,\n",
      "               2.5872693061828613,\n",
      "               2.5872273445129395]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8487,\n",
      "                 0.3542,\n",
      "                 1.3249,\n",
      "                 0.5857,\n",
      "                 0.6069,\n",
      "                 1.0325,\n",
      "                 0.804,\n",
      "                 0.6246,\n",
      "                 0.691,\n",
      "                 0.485,\n",
      "                 0.4533,\n",
      "                 0.5156,\n",
      "                 0.3922,\n",
      "                 0.4446,\n",
      "                 0.1822,\n",
      "                 0.1553,\n",
      "                 0.158,\n",
      "                 0.1357,\n",
      "                 0.0511,\n",
      "                 0.0706,\n",
      "                 0.1695,\n",
      "                 0.0764,\n",
      "                 0.0912,\n",
      "                 0.0508,\n",
      "                 0.0232,\n",
      "                 0.003,\n",
      "                 0.0084,\n",
      "                 0.0053,\n",
      "                 0.0003,\n",
      "                 0.0096,\n",
      "                 0.0044,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0009,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0004,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8795272707939148,\n",
      "               0.7666462063789368,\n",
      "               0.7588169574737549,\n",
      "               0.7224758863449097,\n",
      "               0.5760911703109741,\n",
      "               0.5842183828353882,\n",
      "               0.5835305452346802,\n",
      "               0.581332266330719,\n",
      "               0.5794763565063477,\n",
      "               0.5780448317527771,\n",
      "               0.5777506828308105,\n",
      "               0.5781170725822449,\n",
      "               0.5785375833511353,\n",
      "               0.5788941979408264,\n",
      "               0.5794000029563904,\n",
      "               0.579771101474762,\n",
      "               0.5800865888595581,\n",
      "               0.5803712606430054,\n",
      "               0.5807024836540222,\n",
      "               0.5812262296676636,\n",
      "               0.5818316340446472,\n",
      "               0.5822261571884155,\n",
      "               0.5827013254165649,\n",
      "               0.5831218957901001,\n",
      "               0.5834258794784546,\n",
      "               0.5840085744857788,\n",
      "               0.584333062171936,\n",
      "               0.5847623944282532,\n",
      "               0.5851824879646301,\n",
      "               0.5855380296707153,\n",
      "               0.5857491493225098,\n",
      "               0.5859877467155457,\n",
      "               0.5861704349517822,\n",
      "               0.58632892370224,\n",
      "               0.586489200592041,\n",
      "               0.586633563041687,\n",
      "               0.5868261456489563,\n",
      "               0.5868959426879883,\n",
      "               0.5869256258010864,\n",
      "               0.586937665939331]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.2762,\n",
      "                 1.4212,\n",
      "                 1.4601,\n",
      "                 1.4635,\n",
      "                 1.5245,\n",
      "                 0.6099,\n",
      "                 0.1663,\n",
      "                 0.3008,\n",
      "                 0.3037,\n",
      "                 0.2364,\n",
      "                 1.2164,\n",
      "                 1.074,\n",
      "                 0.2319,\n",
      "                 2.2092,\n",
      "                 0.3421,\n",
      "                 0.3748,\n",
      "                 0.098,\n",
      "                 0.0444,\n",
      "                 0.5671,\n",
      "                 0.0363,\n",
      "                 0.8141,\n",
      "                 0.2469,\n",
      "                 0.0113,\n",
      "                 0.3728,\n",
      "                 0.2134,\n",
      "                 0.0237,\n",
      "                 0.0039,\n",
      "                 0.0525,\n",
      "                 0.0458,\n",
      "                 0.0049,\n",
      "                 0.0372,\n",
      "                 0.0069,\n",
      "                 0.0002,\n",
      "                 0.0095,\n",
      "                 0.0003,\n",
      "                 0.0014,\n",
      "                 0.0003,\n",
      "                 0.0013,\n",
      "                 0.0003,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8750298619270325,\n",
      "               0.8525010943412781,\n",
      "               0.8499283790588379,\n",
      "               0.8061968684196472,\n",
      "               0.9605754613876343,\n",
      "               1.0733041763305664,\n",
      "               1.1361303329467773,\n",
      "               1.1676275730133057,\n",
      "               1.1831409931182861,\n",
      "               1.1891305446624756,\n",
      "               1.1914594173431396,\n",
      "               1.1929848194122314,\n",
      "               1.193004846572876,\n",
      "               1.1933739185333252,\n",
      "               1.1929070949554443,\n",
      "               1.1926487684249878,\n",
      "               1.1926122903823853,\n",
      "               1.1927909851074219,\n",
      "               1.1931862831115723,\n",
      "               1.1935160160064697,\n",
      "               1.1939033269882202,\n",
      "               1.1955792903900146,\n",
      "               1.1973679065704346,\n",
      "               1.1986780166625977,\n",
      "               1.1994975805282593,\n",
      "               1.1999871730804443,\n",
      "               1.20023775100708,\n",
      "               1.200891375541687,\n",
      "               1.2011909484863281,\n",
      "               1.2012602090835571,\n",
      "               1.2013351917266846,\n",
      "               1.2014997005462646,\n",
      "               1.2017104625701904,\n",
      "               1.2016770839691162,\n",
      "               1.201816201210022,\n",
      "               1.2019946575164795,\n",
      "               1.2021129131317139,\n",
      "               1.2021576166152954,\n",
      "               1.2022290229797363,\n",
      "               1.2022433280944824]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6391,\n",
      "                 1.7244,\n",
      "                 0.895,\n",
      "                 1.023,\n",
      "                 1.4546,\n",
      "                 0.7115,\n",
      "                 0.9837,\n",
      "                 1.207,\n",
      "                 0.6064,\n",
      "                 1.037,\n",
      "                 0.8325,\n",
      "                 0.558,\n",
      "                 0.659,\n",
      "                 1.4215,\n",
      "                 1.1226,\n",
      "                 0.2385,\n",
      "                 0.2284,\n",
      "                 0.2551,\n",
      "                 0.4783,\n",
      "                 0.1388,\n",
      "                 0.9233,\n",
      "                 0.2188,\n",
      "                 0.1262,\n",
      "                 0.9351,\n",
      "                 0.4806,\n",
      "                 0.0386,\n",
      "                 0.0235,\n",
      "                 0.1537,\n",
      "                 0.0684,\n",
      "                 0.0206,\n",
      "                 0.1089,\n",
      "                 0.0025,\n",
      "                 0.0015,\n",
      "                 0.0217,\n",
      "                 0.0008,\n",
      "                 0.0028,\n",
      "                 0.0012,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0092,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0005,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.8534821271896362,\n",
      "               0.7980222702026367,\n",
      "               0.8801971673965454,\n",
      "               0.791556715965271,\n",
      "               1.3831108808517456,\n",
      "               1.3363503217697144,\n",
      "               1.376341462135315,\n",
      "               1.4111831188201904,\n",
      "               1.429439663887024,\n",
      "               1.4391810894012451,\n",
      "               1.4453266859054565,\n",
      "               1.4484610557556152,\n",
      "               1.4504050016403198,\n",
      "               1.4510811567306519,\n",
      "               1.4516472816467285,\n",
      "               1.4526054859161377,\n",
      "               1.4542430639266968,\n",
      "               1.4558857679367065,\n",
      "               1.4579918384552002,\n",
      "               1.4594303369522095,\n",
      "               1.4605436325073242,\n",
      "               1.4616191387176514,\n",
      "               1.463125228881836,\n",
      "               1.4639431238174438,\n",
      "               1.4645613431930542,\n",
      "               1.4651811122894287,\n",
      "               1.465669870376587,\n",
      "               1.4663608074188232,\n",
      "               1.4666506052017212,\n",
      "               1.4668793678283691,\n",
      "               1.4670950174331665,\n",
      "               1.4673110246658325,\n",
      "               1.4675732851028442,\n",
      "               1.4678025245666504,\n",
      "               1.467998743057251,\n",
      "               1.4681494235992432,\n",
      "               1.4682564735412598,\n",
      "               1.4683289527893066,\n",
      "               1.4683712720870972,\n",
      "               1.468385934829712]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.4755,\n",
      "                 1.3895,\n",
      "                 0.7788,\n",
      "                 0.7886,\n",
      "                 0.4668,\n",
      "                 1.6613,\n",
      "                 0.7932,\n",
      "                 2.5027,\n",
      "                 0.8283,\n",
      "                 0.7816,\n",
      "                 0.5258,\n",
      "                 0.7514,\n",
      "                 2.7589,\n",
      "                 0.0241,\n",
      "                 0.9859,\n",
      "                 1.8049,\n",
      "                 1.2653,\n",
      "                 2.4204,\n",
      "                 0.0127,\n",
      "                 0.4318,\n",
      "                 0.0133,\n",
      "                 0.0164,\n",
      "                 0.0192,\n",
      "                 0.0514,\n",
      "                 0.0264,\n",
      "                 0.022,\n",
      "                 0.2085,\n",
      "                 0.0001,\n",
      "                 0.0118,\n",
      "                 0.2607,\n",
      "                 0.0003,\n",
      "                 0.0525,\n",
      "                 0.0029,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.004,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0001,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [0.9004920125007629,\n",
      "               1.2432339191436768,\n",
      "               1.3045610189437866,\n",
      "               1.7850713729858398,\n",
      "               1.6386629343032837,\n",
      "               1.8538919687271118,\n",
      "               1.992245078086853,\n",
      "               2.093550205230713,\n",
      "               2.2069342136383057,\n",
      "               2.2717337608337402,\n",
      "               2.323643445968628,\n",
      "               2.3533823490142822,\n",
      "               2.370731830596924,\n",
      "               2.3822243213653564,\n",
      "               2.390761613845825,\n",
      "               2.3971877098083496,\n",
      "               2.403360366821289,\n",
      "               2.408397674560547,\n",
      "               2.4123053550720215,\n",
      "               2.416243076324463,\n",
      "               2.4197144508361816,\n",
      "               2.423210620880127,\n",
      "               2.426750421524048,\n",
      "               2.4299397468566895,\n",
      "               2.4324841499328613,\n",
      "               2.435580015182495,\n",
      "               2.4378607273101807,\n",
      "               2.4395968914031982,\n",
      "               2.442202568054199,\n",
      "               2.445106029510498,\n",
      "               2.4472594261169434,\n",
      "               2.4493510723114014,\n",
      "               2.450589656829834,\n",
      "               2.451456069946289,\n",
      "               2.4523262977600098,\n",
      "               2.452932834625244,\n",
      "               2.4533193111419678,\n",
      "               2.4536798000335693,\n",
      "               2.453920364379883,\n",
      "               2.45398211479187]}]\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.fewshot import batch_fine_tune\n",
    "\n",
    "metrics, training_histories = batch_fine_tune(model_names=['opt-125m', 'opt-350m'], \n",
    "                                              train_datasets=train_datasets, \n",
    "                                              eval_dataset_in=eval_dataset_in, \n",
    "                                              eval_dataset_out=eval_dataset_out, \n",
    "                                              exp_label='final', \n",
    "                                              save_trials=False)\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)\n",
    "print(\"Training histories:\")\n",
    "pprint.pprint(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot with LoRA (Low Rank Adaptation)\n",
    "\n",
    "We fine-tune both models identically to few-shot fine-tuning, but with each model converted to a `LoraModel` for Parameter-Efficient Fine-tuning (PEFT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630e0e8caae343cb818354ae7e307422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 167424 || all params: 125389824 || trainable%: 0.13%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ceac3a515042e4abbe97c431be6366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc81416f90044097953e3b47f577d43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ae1b7c5d34d878cb060100837e893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7554c114c666423d828766c728259f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 443392 || all params: 331591680 || trainable%: 0.13%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d6f7e38cb34f4fb4a40758d43eaa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42514d0bd3c648629d385ed8a7c52e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00443603b7244ca8b2f12f32d1ef928b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "[{'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.763865053653717,\n",
      "  'eval_in_peak_memory_gb': 1.020885944366455,\n",
      "  'eval_in_runtime': 2.3579,\n",
      "  'eval_in_samples_per_second': 21.206,\n",
      "  'eval_in_steps_per_second': 2.969,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8135073781013489,\n",
      "  'eval_out_peak_memory_gb': 1.020885944366455,\n",
      "  'eval_out_runtime': 2.4241,\n",
      "  'eval_out_samples_per_second': 20.627,\n",
      "  'eval_out_steps_per_second': 2.888,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.6975186601281166,\n",
      "  'train_peak_memory_gb': 1.5204076766967773,\n",
      "  'train_runtime': 72.6062,\n",
      "  'train_samples_per_second': 1.102,\n",
      "  'train_steps_per_second': 0.551},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.821978747844696,\n",
      "  'eval_in_peak_memory_gb': 1.020153522491455,\n",
      "  'eval_in_runtime': 2.3876,\n",
      "  'eval_in_samples_per_second': 20.941,\n",
      "  'eval_in_steps_per_second': 2.932,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8736296892166138,\n",
      "  'eval_out_peak_memory_gb': 1.020153522491455,\n",
      "  'eval_out_runtime': 2.3525,\n",
      "  'eval_out_samples_per_second': 21.254,\n",
      "  'eval_out_steps_per_second': 2.976,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.3954311065375805,\n",
      "  'train_peak_memory_gb': 1.5196752548217773,\n",
      "  'train_runtime': 72.3017,\n",
      "  'train_samples_per_second': 1.106,\n",
      "  'train_steps_per_second': 0.553},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7103204131126404,\n",
      "  'eval_in_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_in_runtime': 2.3528,\n",
      "  'eval_in_samples_per_second': 21.251,\n",
      "  'eval_in_steps_per_second': 2.975,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7171524167060852,\n",
      "  'eval_out_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_out_runtime': 2.4178,\n",
      "  'eval_out_samples_per_second': 20.68,\n",
      "  'eval_out_steps_per_second': 2.895,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.6342633910477161,\n",
      "  'train_peak_memory_gb': 1.5211400985717773,\n",
      "  'train_runtime': 72.7591,\n",
      "  'train_samples_per_second': 1.1,\n",
      "  'train_steps_per_second': 0.55},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7040294408798218,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.3694,\n",
      "  'eval_in_samples_per_second': 21.103,\n",
      "  'eval_in_steps_per_second': 2.954,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7197412252426147,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.3359,\n",
      "  'eval_out_samples_per_second': 21.405,\n",
      "  'eval_out_steps_per_second': 2.997,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 1.2158010870218277,\n",
      "  'train_peak_memory_gb': 1.520401954650879,\n",
      "  'train_runtime': 72.6223,\n",
      "  'train_samples_per_second': 1.102,\n",
      "  'train_steps_per_second': 0.551},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7280494570732117,\n",
      "  'eval_in_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_in_runtime': 2.4723,\n",
      "  'eval_in_samples_per_second': 20.224,\n",
      "  'eval_in_steps_per_second': 2.831,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7468773126602173,\n",
      "  'eval_out_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_out_runtime': 2.372,\n",
      "  'eval_out_samples_per_second': 21.079,\n",
      "  'eval_out_steps_per_second': 2.951,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.7586250752210617,\n",
      "  'train_peak_memory_gb': 1.5211400985717773,\n",
      "  'train_runtime': 72.2372,\n",
      "  'train_samples_per_second': 1.107,\n",
      "  'train_steps_per_second': 0.554},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7466523051261902,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.3248,\n",
      "  'eval_in_samples_per_second': 21.507,\n",
      "  'eval_in_steps_per_second': 3.011,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.784130871295929,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.3729,\n",
      "  'eval_out_samples_per_second': 21.071,\n",
      "  'eval_out_steps_per_second': 2.95,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.6517287716269493,\n",
      "  'train_peak_memory_gb': 1.520401954650879,\n",
      "  'train_runtime': 72.6612,\n",
      "  'train_samples_per_second': 1.101,\n",
      "  'train_steps_per_second': 0.551},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.70514315366745,\n",
      "  'eval_in_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_in_runtime': 2.4041,\n",
      "  'eval_in_samples_per_second': 20.798,\n",
      "  'eval_in_steps_per_second': 2.912,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7120581269264221,\n",
      "  'eval_out_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_out_runtime': 2.3976,\n",
      "  'eval_out_samples_per_second': 20.854,\n",
      "  'eval_out_steps_per_second': 2.92,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.8658725053071976,\n",
      "  'train_peak_memory_gb': 1.5211400985717773,\n",
      "  'train_runtime': 72.0621,\n",
      "  'train_samples_per_second': 1.11,\n",
      "  'train_steps_per_second': 0.555},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7471736669540405,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.425,\n",
      "  'eval_in_samples_per_second': 20.618,\n",
      "  'eval_in_steps_per_second': 2.887,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7772668600082397,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.4028,\n",
      "  'eval_out_samples_per_second': 20.809,\n",
      "  'eval_out_steps_per_second': 2.913,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.5409570582211017,\n",
      "  'train_peak_memory_gb': 1.520401954650879,\n",
      "  'train_runtime': 72.4282,\n",
      "  'train_samples_per_second': 1.105,\n",
      "  'train_steps_per_second': 0.552},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7110151648521423,\n",
      "  'eval_in_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_in_runtime': 2.3643,\n",
      "  'eval_in_samples_per_second': 21.148,\n",
      "  'eval_in_steps_per_second': 2.961,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7147257924079895,\n",
      "  'eval_out_peak_memory_gb': 1.021618366241455,\n",
      "  'eval_out_runtime': 2.448,\n",
      "  'eval_out_samples_per_second': 20.425,\n",
      "  'eval_out_steps_per_second': 2.859,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.6250117540359497,\n",
      "  'train_peak_memory_gb': 1.5211400985717773,\n",
      "  'train_runtime': 71.736,\n",
      "  'train_samples_per_second': 1.115,\n",
      "  'train_steps_per_second': 0.558},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8177892565727234,\n",
      "  'eval_in_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_in_runtime': 2.3674,\n",
      "  'eval_in_samples_per_second': 21.12,\n",
      "  'eval_in_steps_per_second': 2.957,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8763330578804016,\n",
      "  'eval_out_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_out_runtime': 2.3614,\n",
      "  'eval_out_samples_per_second': 21.174,\n",
      "  'eval_out_steps_per_second': 2.964,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20940356321280.0,\n",
      "  'train_loss': 0.5626516059041023,\n",
      "  'train_peak_memory_gb': 1.5196752548217773,\n",
      "  'train_runtime': 72.2581,\n",
      "  'train_samples_per_second': 1.107,\n",
      "  'train_steps_per_second': 0.554},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.713660717010498,\n",
      "  'eval_in_peak_memory_gb': 1.022472858428955,\n",
      "  'eval_in_runtime': 2.3493,\n",
      "  'eval_in_samples_per_second': 21.283,\n",
      "  'eval_in_steps_per_second': 2.98,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.736757755279541,\n",
      "  'eval_out_peak_memory_gb': 1.022472858428955,\n",
      "  'eval_out_runtime': 2.3664,\n",
      "  'eval_out_samples_per_second': 21.129,\n",
      "  'eval_out_steps_per_second': 2.958,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.7233907163143158,\n",
      "  'train_peak_memory_gb': 2.564896583557129,\n",
      "  'train_runtime': 75.1043,\n",
      "  'train_samples_per_second': 2.13,\n",
      "  'train_steps_per_second': 0.533},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.705697238445282,\n",
      "  'eval_in_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_in_runtime': 2.2934,\n",
      "  'eval_in_samples_per_second': 21.801,\n",
      "  'eval_in_steps_per_second': 3.052,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7144421935081482,\n",
      "  'eval_out_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_out_runtime': 2.3274,\n",
      "  'eval_out_samples_per_second': 21.483,\n",
      "  'eval_out_steps_per_second': 3.008,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.8459259107708931,\n",
      "  'train_peak_memory_gb': 2.565018653869629,\n",
      "  'train_runtime': 75.6043,\n",
      "  'train_samples_per_second': 2.116,\n",
      "  'train_steps_per_second': 0.529},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7085283398628235,\n",
      "  'eval_in_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_in_runtime': 2.3449,\n",
      "  'eval_in_samples_per_second': 21.322,\n",
      "  'eval_in_steps_per_second': 2.985,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7210209369659424,\n",
      "  'eval_out_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_out_runtime': 2.3511,\n",
      "  'eval_out_samples_per_second': 21.267,\n",
      "  'eval_out_steps_per_second': 2.977,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.8059013664722443,\n",
      "  'train_peak_memory_gb': 2.563187599182129,\n",
      "  'train_runtime': 75.2072,\n",
      "  'train_samples_per_second': 2.127,\n",
      "  'train_steps_per_second': 0.532},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7031071186065674,\n",
      "  'eval_in_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_in_runtime': 2.381,\n",
      "  'eval_in_samples_per_second': 21.0,\n",
      "  'eval_in_steps_per_second': 2.94,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.724384605884552,\n",
      "  'eval_out_peak_memory_gb': 1.020397663116455,\n",
      "  'eval_out_runtime': 2.3834,\n",
      "  'eval_out_samples_per_second': 20.979,\n",
      "  'eval_out_steps_per_second': 2.937,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.7816615998744965,\n",
      "  'train_peak_memory_gb': 2.566483497619629,\n",
      "  'train_runtime': 74.944,\n",
      "  'train_samples_per_second': 2.135,\n",
      "  'train_steps_per_second': 0.534},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7641977071762085,\n",
      "  'eval_in_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_in_runtime': 2.2919,\n",
      "  'eval_in_samples_per_second': 21.816,\n",
      "  'eval_in_steps_per_second': 3.054,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8170057535171509,\n",
      "  'eval_out_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_out_runtime': 2.4807,\n",
      "  'eval_out_samples_per_second': 20.156,\n",
      "  'eval_out_steps_per_second': 2.822,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.6232099205255508,\n",
      "  'train_peak_memory_gb': 2.564164161682129,\n",
      "  'train_runtime': 75.3373,\n",
      "  'train_samples_per_second': 2.124,\n",
      "  'train_steps_per_second': 0.531},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7756639122962952,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.3449,\n",
      "  'eval_in_samples_per_second': 21.323,\n",
      "  'eval_in_steps_per_second': 2.985,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8371639251708984,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.3556,\n",
      "  'eval_out_samples_per_second': 21.226,\n",
      "  'eval_out_steps_per_second': 2.972,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.5095061719417572,\n",
      "  'train_peak_memory_gb': 2.565262794494629,\n",
      "  'train_runtime': 75.1039,\n",
      "  'train_samples_per_second': 2.13,\n",
      "  'train_steps_per_second': 0.533},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.713860034942627,\n",
      "  'eval_in_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_in_runtime': 2.354,\n",
      "  'eval_in_samples_per_second': 21.24,\n",
      "  'eval_in_steps_per_second': 2.974,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7365485429763794,\n",
      "  'eval_out_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_out_runtime': 2.406,\n",
      "  'eval_out_samples_per_second': 20.782,\n",
      "  'eval_out_steps_per_second': 2.909,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.8648473367094993,\n",
      "  'train_peak_memory_gb': 2.564408302307129,\n",
      "  'train_runtime': 75.3219,\n",
      "  'train_samples_per_second': 2.124,\n",
      "  'train_steps_per_second': 0.531},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7310923933982849,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.3966,\n",
      "  'eval_in_samples_per_second': 20.863,\n",
      "  'eval_in_steps_per_second': 2.921,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7617397308349609,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.3498,\n",
      "  'eval_out_samples_per_second': 21.279,\n",
      "  'eval_out_steps_per_second': 2.979,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.634762690961361,\n",
      "  'train_peak_memory_gb': 2.565506935119629,\n",
      "  'train_runtime': 76.0772,\n",
      "  'train_samples_per_second': 2.103,\n",
      "  'train_steps_per_second': 0.526},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7949028611183167,\n",
      "  'eval_in_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_in_runtime': 2.3298,\n",
      "  'eval_in_samples_per_second': 21.461,\n",
      "  'eval_in_steps_per_second': 3.005,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8398385643959045,\n",
      "  'eval_out_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_out_runtime': 2.4294,\n",
      "  'eval_out_samples_per_second': 20.581,\n",
      "  'eval_out_steps_per_second': 2.881,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.42544722408056257,\n",
      "  'train_peak_memory_gb': 2.565140724182129,\n",
      "  'train_runtime': 75.6782,\n",
      "  'train_samples_per_second': 2.114,\n",
      "  'train_steps_per_second': 0.529},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7609092593193054,\n",
      "  'eval_in_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_in_runtime': 2.3661,\n",
      "  'eval_in_samples_per_second': 21.132,\n",
      "  'eval_in_steps_per_second': 2.958,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8159015774726868,\n",
      "  'eval_out_peak_memory_gb': 1.0208802223205566,\n",
      "  'eval_out_runtime': 2.3761,\n",
      "  'eval_out_samples_per_second': 21.043,\n",
      "  'eval_out_steps_per_second': 2.946,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41880712642560.0,\n",
      "  'train_loss': 0.6489173695445061,\n",
      "  'train_peak_memory_gb': 2.565751075744629,\n",
      "  'train_runtime': 76.0342,\n",
      "  'train_samples_per_second': 2.104,\n",
      "  'train_steps_per_second': 0.526},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7181304097175598,\n",
      "  'eval_in_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_in_runtime': 2.3324,\n",
      "  'eval_in_samples_per_second': 21.437,\n",
      "  'eval_in_steps_per_second': 3.001,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.755013644695282,\n",
      "  'eval_out_peak_memory_gb': 1.0222229957580566,\n",
      "  'eval_out_runtime': 2.3876,\n",
      "  'eval_out_samples_per_second': 20.941,\n",
      "  'eval_out_steps_per_second': 2.932,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.736566287279129,\n",
      "  'train_peak_memory_gb': 4.626908302307129,\n",
      "  'train_runtime': 81.2609,\n",
      "  'train_samples_per_second': 3.938,\n",
      "  'train_steps_per_second': 0.492},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7312992811203003,\n",
      "  'eval_in_peak_memory_gb': 1.0352845191955566,\n",
      "  'eval_in_runtime': 2.3694,\n",
      "  'eval_in_samples_per_second': 21.102,\n",
      "  'eval_in_steps_per_second': 2.954,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7714830040931702,\n",
      "  'eval_out_peak_memory_gb': 1.0352845191955566,\n",
      "  'eval_out_runtime': 2.4161,\n",
      "  'eval_out_samples_per_second': 20.694,\n",
      "  'eval_out_steps_per_second': 2.897,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.6983273193240166,\n",
      "  'train_peak_memory_gb': 4.640580177307129,\n",
      "  'train_runtime': 81.0804,\n",
      "  'train_samples_per_second': 3.947,\n",
      "  'train_steps_per_second': 0.493},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7046827673912048,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.3792,\n",
      "  'eval_in_samples_per_second': 21.016,\n",
      "  'eval_in_steps_per_second': 2.942,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7230260372161865,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.3457,\n",
      "  'eval_out_samples_per_second': 21.315,\n",
      "  'eval_out_steps_per_second': 2.984,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.9278498440980911,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 81.7548,\n",
      "  'train_samples_per_second': 3.914,\n",
      "  'train_steps_per_second': 0.489},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8057844042778015,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.3982,\n",
      "  'eval_in_samples_per_second': 20.849,\n",
      "  'eval_in_steps_per_second': 2.919,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8688313364982605,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.9379,\n",
      "  'eval_out_samples_per_second': 17.019,\n",
      "  'eval_out_steps_per_second': 2.383,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.660245081782341,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 82.675,\n",
      "  'train_samples_per_second': 3.871,\n",
      "  'train_steps_per_second': 0.484},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7111334800720215,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.398,\n",
      "  'eval_in_samples_per_second': 20.851,\n",
      "  'eval_in_steps_per_second': 2.919,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.739565908908844,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.4285,\n",
      "  'eval_out_samples_per_second': 20.589,\n",
      "  'eval_out_steps_per_second': 2.882,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.78933886885643,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 83.299,\n",
      "  'train_samples_per_second': 3.842,\n",
      "  'train_steps_per_second': 0.48},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7196435332298279,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.4467,\n",
      "  'eval_in_samples_per_second': 20.436,\n",
      "  'eval_in_steps_per_second': 2.861,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7425679564476013,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.4105,\n",
      "  'eval_out_samples_per_second': 20.743,\n",
      "  'eval_out_steps_per_second': 2.904,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.6581328377127648,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 82.0442,\n",
      "  'train_samples_per_second': 3.9,\n",
      "  'train_steps_per_second': 0.488},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7296406626701355,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.4385,\n",
      "  'eval_in_samples_per_second': 20.505,\n",
      "  'eval_in_steps_per_second': 2.871,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7461798787117004,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.389,\n",
      "  'eval_out_samples_per_second': 20.929,\n",
      "  'eval_out_steps_per_second': 2.93,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.5275465540587903,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 83.0337,\n",
      "  'train_samples_per_second': 3.854,\n",
      "  'train_steps_per_second': 0.482},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7067683339118958,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.3895,\n",
      "  'eval_in_samples_per_second': 20.925,\n",
      "  'eval_in_steps_per_second': 2.929,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7170254588127136,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.3867,\n",
      "  'eval_out_samples_per_second': 20.95,\n",
      "  'eval_out_steps_per_second': 2.933,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.8969203367829323,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 82.8382,\n",
      "  'train_samples_per_second': 3.863,\n",
      "  'train_steps_per_second': 0.483},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.721127450466156,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.4475,\n",
      "  'eval_in_samples_per_second': 20.429,\n",
      "  'eval_in_steps_per_second': 2.86,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7572528719902039,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.388,\n",
      "  'eval_out_samples_per_second': 20.938,\n",
      "  'eval_out_steps_per_second': 2.931,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.7157522037625312,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 82.4601,\n",
      "  'train_samples_per_second': 3.881,\n",
      "  'train_steps_per_second': 0.485},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7038957476615906,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.3744,\n",
      "  'eval_in_samples_per_second': 21.058,\n",
      "  'eval_in_steps_per_second': 2.948,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7258123159408569,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.395,\n",
      "  'eval_out_samples_per_second': 20.877,\n",
      "  'eval_out_steps_per_second': 2.923,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 83761425285120.0,\n",
      "  'train_loss': 0.9111160889267922,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 82.9918,\n",
      "  'train_samples_per_second': 3.856,\n",
      "  'train_steps_per_second': 0.482},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7062017917633057,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.8359,\n",
      "  'eval_in_samples_per_second': 17.631,\n",
      "  'eval_in_steps_per_second': 2.468,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.721662700176239,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.5892,\n",
      "  'eval_out_samples_per_second': 19.311,\n",
      "  'eval_out_steps_per_second': 2.704,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.6691549122333527,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 96.5053,\n",
      "  'train_samples_per_second': 6.632,\n",
      "  'train_steps_per_second': 0.829},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.6981180310249329,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.5299,\n",
      "  'eval_in_samples_per_second': 19.764,\n",
      "  'eval_in_steps_per_second': 2.767,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7069111466407776,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.3994,\n",
      "  'eval_out_samples_per_second': 20.839,\n",
      "  'eval_out_steps_per_second': 2.917,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.7668648578226567,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 96.094,\n",
      "  'train_samples_per_second': 6.66,\n",
      "  'train_steps_per_second': 0.833},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7073007225990295,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.3911,\n",
      "  'eval_in_samples_per_second': 20.911,\n",
      "  'eval_in_steps_per_second': 2.928,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7147863507270813,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.374,\n",
      "  'eval_out_samples_per_second': 21.061,\n",
      "  'eval_out_steps_per_second': 2.949,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.734028959274292,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 95.4977,\n",
      "  'train_samples_per_second': 6.702,\n",
      "  'train_steps_per_second': 0.838},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7739936709403992,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.4157,\n",
      "  'eval_in_samples_per_second': 20.698,\n",
      "  'eval_in_steps_per_second': 2.898,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.8286612629890442,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.4291,\n",
      "  'eval_out_samples_per_second': 20.584,\n",
      "  'eval_out_steps_per_second': 2.882,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.5839723147451877,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 96.2244,\n",
      "  'train_samples_per_second': 6.651,\n",
      "  'train_steps_per_second': 0.831},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7140421867370605,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.356,\n",
      "  'eval_in_samples_per_second': 21.223,\n",
      "  'eval_in_steps_per_second': 2.971,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7371305227279663,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.4055,\n",
      "  'eval_out_samples_per_second': 20.786,\n",
      "  'eval_out_steps_per_second': 2.91,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.6663581289350986,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 95.928,\n",
      "  'train_samples_per_second': 6.672,\n",
      "  'train_steps_per_second': 0.834},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7286018133163452,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.4056,\n",
      "  'eval_in_samples_per_second': 20.785,\n",
      "  'eval_in_steps_per_second': 2.91,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7554962635040283,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.6051,\n",
      "  'eval_out_samples_per_second': 19.193,\n",
      "  'eval_out_steps_per_second': 2.687,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.6774545218795538,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 97.3931,\n",
      "  'train_samples_per_second': 6.571,\n",
      "  'train_steps_per_second': 0.821},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7303087711334229,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.4103,\n",
      "  'eval_in_samples_per_second': 20.744,\n",
      "  'eval_in_steps_per_second': 2.904,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7734926342964172,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.3959,\n",
      "  'eval_out_samples_per_second': 20.869,\n",
      "  'eval_out_steps_per_second': 2.922,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.70292344763875,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 96.7108,\n",
      "  'train_samples_per_second': 6.618,\n",
      "  'train_steps_per_second': 0.827},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7086500525474548,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.419,\n",
      "  'eval_in_samples_per_second': 20.669,\n",
      "  'eval_in_steps_per_second': 2.894,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.6893483996391296,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.3827,\n",
      "  'eval_out_samples_per_second': 20.984,\n",
      "  'eval_out_steps_per_second': 2.938,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.7702973380684852,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 95.6558,\n",
      "  'train_samples_per_second': 6.691,\n",
      "  'train_steps_per_second': 0.836},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7064851522445679,\n",
      "  'eval_in_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_in_runtime': 2.4708,\n",
      "  'eval_in_samples_per_second': 20.237,\n",
      "  'eval_in_steps_per_second': 2.833,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7431823015213013,\n",
      "  'eval_out_peak_memory_gb': 1.0388245582580566,\n",
      "  'eval_out_runtime': 2.4306,\n",
      "  'eval_out_samples_per_second': 20.571,\n",
      "  'eval_out_steps_per_second': 2.88,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.6943582698702813,\n",
      "  'train_peak_memory_gb': 4.641800880432129,\n",
      "  'train_runtime': 95.5306,\n",
      "  'train_samples_per_second': 6.699,\n",
      "  'train_steps_per_second': 0.837},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7125126719474792,\n",
      "  'eval_in_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_in_runtime': 2.422,\n",
      "  'eval_in_samples_per_second': 20.644,\n",
      "  'eval_in_steps_per_second': 2.89,\n",
      "  'eval_out_accuracy': 0.62,\n",
      "  'eval_out_loss': 0.6985746026039124,\n",
      "  'eval_out_peak_memory_gb': 1.0382142066955566,\n",
      "  'eval_out_runtime': 2.4677,\n",
      "  'eval_out_samples_per_second': 20.262,\n",
      "  'eval_out_steps_per_second': 2.837,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 167522850570240.0,\n",
      "  'train_loss': 0.7018830507993699,\n",
      "  'train_peak_memory_gb': 4.642045021057129,\n",
      "  'train_runtime': 95.939,\n",
      "  'train_samples_per_second': 6.671,\n",
      "  'train_steps_per_second': 0.834},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 1.0200151205062866,\n",
      "  'eval_in_peak_memory_gb': 2.3458142280578613,\n",
      "  'eval_in_runtime': 4.2751,\n",
      "  'eval_in_samples_per_second': 11.696,\n",
      "  'eval_in_steps_per_second': 1.637,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7147576212882996,\n",
      "  'eval_out_peak_memory_gb': 2.3458142280578613,\n",
      "  'eval_out_runtime': 4.2769,\n",
      "  'eval_out_samples_per_second': 11.691,\n",
      "  'eval_out_steps_per_second': 1.637,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.5763686515390873,\n",
      "  'train_peak_memory_gb': 3.968935966491699,\n",
      "  'train_runtime': 95.6688,\n",
      "  'train_samples_per_second': 0.836,\n",
      "  'train_steps_per_second': 0.418},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.1879794597625732,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1669,\n",
      "  'eval_in_samples_per_second': 11.999,\n",
      "  'eval_in_steps_per_second': 1.68,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.8105555772781372,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.2132,\n",
      "  'eval_out_samples_per_second': 11.867,\n",
      "  'eval_out_steps_per_second': 1.661,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.2156417173333466,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 94.5499,\n",
      "  'train_samples_per_second': 0.846,\n",
      "  'train_steps_per_second': 0.423},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.0712076425552368,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1067,\n",
      "  'eval_in_samples_per_second': 12.175,\n",
      "  'eval_in_steps_per_second': 1.705,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7977505326271057,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0718,\n",
      "  'eval_out_samples_per_second': 12.28,\n",
      "  'eval_out_steps_per_second': 1.719,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.761304946988821,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 94.4243,\n",
      "  'train_samples_per_second': 0.847,\n",
      "  'train_steps_per_second': 0.424},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.105648159980774,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1179,\n",
      "  'eval_in_samples_per_second': 12.142,\n",
      "  'eval_in_steps_per_second': 1.7,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7673619985580444,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.1211,\n",
      "  'eval_out_samples_per_second': 12.133,\n",
      "  'eval_out_steps_per_second': 1.699,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.2962923651561141,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 92.9532,\n",
      "  'train_samples_per_second': 0.861,\n",
      "  'train_steps_per_second': 0.43},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.0267692804336548,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.2397,\n",
      "  'eval_in_samples_per_second': 11.793,\n",
      "  'eval_in_steps_per_second': 1.651,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7108142375946045,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0839,\n",
      "  'eval_out_samples_per_second': 12.243,\n",
      "  'eval_out_steps_per_second': 1.714,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.6678216308355331,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 94.0968,\n",
      "  'train_samples_per_second': 0.85,\n",
      "  'train_steps_per_second': 0.425},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.024383544921875,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1192,\n",
      "  'eval_in_samples_per_second': 12.138,\n",
      "  'eval_in_steps_per_second': 1.699,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7222772240638733,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.1042,\n",
      "  'eval_out_samples_per_second': 12.183,\n",
      "  'eval_out_steps_per_second': 1.706,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.7878906242549419,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 93.3837,\n",
      "  'train_samples_per_second': 0.857,\n",
      "  'train_steps_per_second': 0.428},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.1033912897109985,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1148,\n",
      "  'eval_in_samples_per_second': 12.151,\n",
      "  'eval_in_steps_per_second': 1.701,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7798669338226318,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0969,\n",
      "  'eval_out_samples_per_second': 12.204,\n",
      "  'eval_out_steps_per_second': 1.709,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.4205555975437164,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 93.7414,\n",
      "  'train_samples_per_second': 0.853,\n",
      "  'train_steps_per_second': 0.427},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.34,\n",
      "  'eval_in_loss': 0.9950324296951294,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.0851,\n",
      "  'eval_in_samples_per_second': 12.24,\n",
      "  'eval_in_steps_per_second': 1.714,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.6993972659111023,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0956,\n",
      "  'eval_out_samples_per_second': 12.208,\n",
      "  'eval_out_steps_per_second': 1.709,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.6816607199609279,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 93.3717,\n",
      "  'train_samples_per_second': 0.857,\n",
      "  'train_steps_per_second': 0.428},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.0836914777755737,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.1081,\n",
      "  'eval_in_samples_per_second': 12.171,\n",
      "  'eval_in_steps_per_second': 1.704,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.8095176815986633,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0811,\n",
      "  'eval_out_samples_per_second': 12.252,\n",
      "  'eval_out_steps_per_second': 1.715,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.37054455280303955,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 94.1865,\n",
      "  'train_samples_per_second': 0.849,\n",
      "  'train_steps_per_second': 0.425},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.1637927293777466,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 4.0773,\n",
      "  'eval_in_samples_per_second': 12.263,\n",
      "  'eval_in_steps_per_second': 1.717,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.8181593418121338,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 4.0742,\n",
      "  'eval_out_samples_per_second': 12.272,\n",
      "  'eval_out_steps_per_second': 1.718,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74650390364160.0,\n",
      "  'train_loss': 0.2901137759909034,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 93.2786,\n",
      "  'train_samples_per_second': 0.858,\n",
      "  'train_steps_per_second': 0.429},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 1.019397497177124,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 13.5511,\n",
      "  'eval_in_samples_per_second': 3.69,\n",
      "  'eval_in_steps_per_second': 0.517,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7381919622421265,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 13.4657,\n",
      "  'eval_out_samples_per_second': 3.713,\n",
      "  'eval_out_steps_per_second': 0.52,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 1.06295298486948,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 196.6097,\n",
      "  'train_samples_per_second': 0.814,\n",
      "  'train_steps_per_second': 0.203},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.0978542566299438,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 14.9193,\n",
      "  'eval_in_samples_per_second': 3.351,\n",
      "  'eval_in_steps_per_second': 0.469,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7790064215660095,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 14.9258,\n",
      "  'eval_out_samples_per_second': 3.35,\n",
      "  'eval_out_steps_per_second': 0.469,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.358922915160656,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 225.9761,\n",
      "  'train_samples_per_second': 0.708,\n",
      "  'train_steps_per_second': 0.177},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 1.005492091178894,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 14.2152,\n",
      "  'eval_in_samples_per_second': 3.517,\n",
      "  'eval_in_steps_per_second': 0.492,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7064031362533569,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 14.2216,\n",
      "  'eval_out_samples_per_second': 3.516,\n",
      "  'eval_out_steps_per_second': 0.492,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.6193244688212871,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 197.3912,\n",
      "  'train_samples_per_second': 0.811,\n",
      "  'train_steps_per_second': 0.203},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.0457133054733276,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 13.442,\n",
      "  'eval_in_samples_per_second': 3.72,\n",
      "  'eval_in_steps_per_second': 0.521,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7180789113044739,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 13.469,\n",
      "  'eval_out_samples_per_second': 3.712,\n",
      "  'eval_out_steps_per_second': 0.52,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.41961178332567217,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 199.1878,\n",
      "  'train_samples_per_second': 0.803,\n",
      "  'train_steps_per_second': 0.201},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 1.0281023979187012,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 15.7722,\n",
      "  'eval_in_samples_per_second': 3.17,\n",
      "  'eval_in_steps_per_second': 0.444,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7273518443107605,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 15.9278,\n",
      "  'eval_out_samples_per_second': 3.139,\n",
      "  'eval_out_steps_per_second': 0.439,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.5188165992498398,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 215.4853,\n",
      "  'train_samples_per_second': 0.743,\n",
      "  'train_steps_per_second': 0.186},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.1286262273788452,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 15.4972,\n",
      "  'eval_in_samples_per_second': 3.226,\n",
      "  'eval_in_steps_per_second': 0.452,\n",
      "  'eval_out_accuracy': 0.58,\n",
      "  'eval_out_loss': 0.8094373345375061,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 15.6714,\n",
      "  'eval_out_samples_per_second': 3.191,\n",
      "  'eval_out_steps_per_second': 0.447,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.5932341076433658,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 228.2527,\n",
      "  'train_samples_per_second': 0.701,\n",
      "  'train_steps_per_second': 0.175},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.32,\n",
      "  'eval_in_loss': 1.008223056793213,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 14.9485,\n",
      "  'eval_in_samples_per_second': 3.345,\n",
      "  'eval_in_steps_per_second': 0.468,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7033131122589111,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 15.2272,\n",
      "  'eval_out_samples_per_second': 3.284,\n",
      "  'eval_out_steps_per_second': 0.46,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 1.3020227342844009,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 207.4598,\n",
      "  'train_samples_per_second': 0.771,\n",
      "  'train_steps_per_second': 0.193},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.34,\n",
      "  'eval_in_loss': 0.9921084642410278,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 14.8075,\n",
      "  'eval_in_samples_per_second': 3.377,\n",
      "  'eval_in_steps_per_second': 0.473,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.6938083171844482,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 14.9045,\n",
      "  'eval_out_samples_per_second': 3.355,\n",
      "  'eval_out_steps_per_second': 0.47,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.8273517176508903,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 220.0556,\n",
      "  'train_samples_per_second': 0.727,\n",
      "  'train_steps_per_second': 0.182},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.1400256156921387,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 15.8416,\n",
      "  'eval_in_samples_per_second': 3.156,\n",
      "  'eval_in_steps_per_second': 0.442,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.783449649810791,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 15.9969,\n",
      "  'eval_out_samples_per_second': 3.126,\n",
      "  'eval_out_steps_per_second': 0.438,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.6654212914407254,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 222.001,\n",
      "  'train_samples_per_second': 0.721,\n",
      "  'train_steps_per_second': 0.18},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 1.1548206806182861,\n",
      "  'eval_in_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_in_runtime': 14.3419,\n",
      "  'eval_in_samples_per_second': 3.486,\n",
      "  'eval_in_steps_per_second': 0.488,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7862339615821838,\n",
      "  'eval_out_peak_memory_gb': 2.3277478218078613,\n",
      "  'eval_out_runtime': 14.4801,\n",
      "  'eval_out_samples_per_second': 3.453,\n",
      "  'eval_out_steps_per_second': 0.483,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149300780728320.0,\n",
      "  'train_loss': 0.1728431588038802,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 213.6793,\n",
      "  'train_samples_per_second': 0.749,\n",
      "  'train_steps_per_second': 0.187},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.9869996905326843,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 7.3806,\n",
      "  'eval_in_samples_per_second': 6.775,\n",
      "  'eval_in_steps_per_second': 1.761,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7111024260520935,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 7.3447,\n",
      "  'eval_out_samples_per_second': 6.808,\n",
      "  'eval_out_steps_per_second': 1.77,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.726583632081747,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 213.5444,\n",
      "  'train_samples_per_second': 1.499,\n",
      "  'train_steps_per_second': 0.375},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 0.9766526818275452,\n",
      "  'eval_in_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_in_runtime': 5.8159,\n",
      "  'eval_in_samples_per_second': 8.597,\n",
      "  'eval_in_steps_per_second': 2.235,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.6994683742523193,\n",
      "  'eval_out_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_out_runtime': 5.8293,\n",
      "  'eval_out_samples_per_second': 8.577,\n",
      "  'eval_out_steps_per_second': 2.23,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.7210132364183665,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 179.2847,\n",
      "  'train_samples_per_second': 1.785,\n",
      "  'train_steps_per_second': 0.446},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.0281208753585815,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 5.0906,\n",
      "  'eval_in_samples_per_second': 9.822,\n",
      "  'eval_in_steps_per_second': 2.554,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.713161289691925,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 5.0314,\n",
      "  'eval_out_samples_per_second': 9.938,\n",
      "  'eval_out_steps_per_second': 2.584,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.4933850301429629,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 175.1633,\n",
      "  'train_samples_per_second': 1.827,\n",
      "  'train_steps_per_second': 0.457},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 1.241722583770752,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 7.2908,\n",
      "  'eval_in_samples_per_second': 6.858,\n",
      "  'eval_in_steps_per_second': 1.783,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.9453263878822327,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 6.7276,\n",
      "  'eval_out_samples_per_second': 7.432,\n",
      "  'eval_out_steps_per_second': 1.932,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.5339707661420107,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 190.4318,\n",
      "  'train_samples_per_second': 1.68,\n",
      "  'train_steps_per_second': 0.42},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.34,\n",
      "  'eval_in_loss': 1.0142260789871216,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 5.2914,\n",
      "  'eval_in_samples_per_second': 9.449,\n",
      "  'eval_in_steps_per_second': 2.457,\n",
      "  'eval_out_accuracy': 0.62,\n",
      "  'eval_out_loss': 0.7446430921554565,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 5.2971,\n",
      "  'eval_out_samples_per_second': 9.439,\n",
      "  'eval_out_steps_per_second': 2.454,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.7234230455011129,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 180.9165,\n",
      "  'train_samples_per_second': 1.769,\n",
      "  'train_steps_per_second': 0.442},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.0330554246902466,\n",
      "  'eval_in_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_in_runtime': 4.3036,\n",
      "  'eval_in_samples_per_second': 11.618,\n",
      "  'eval_in_steps_per_second': 3.021,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7849755883216858,\n",
      "  'eval_out_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_out_runtime': 4.3845,\n",
      "  'eval_out_samples_per_second': 11.404,\n",
      "  'eval_out_steps_per_second': 2.965,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.5143752258270979,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 187.6781,\n",
      "  'train_samples_per_second': 1.705,\n",
      "  'train_steps_per_second': 0.426},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 0.9891657829284668,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 5.3974,\n",
      "  'eval_in_samples_per_second': 9.264,\n",
      "  'eval_in_steps_per_second': 2.409,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7262564897537231,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 5.3602,\n",
      "  'eval_out_samples_per_second': 9.328,\n",
      "  'eval_out_steps_per_second': 2.425,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.7012737464159727,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 182.8135,\n",
      "  'train_samples_per_second': 1.75,\n",
      "  'train_steps_per_second': 0.438},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 1.1733620166778564,\n",
      "  'eval_in_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_in_runtime': 6.0926,\n",
      "  'eval_in_samples_per_second': 8.207,\n",
      "  'eval_in_steps_per_second': 2.134,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7927089929580688,\n",
      "  'eval_out_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_out_runtime': 6.5604,\n",
      "  'eval_out_samples_per_second': 7.621,\n",
      "  'eval_out_steps_per_second': 1.982,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.4528445038944483,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 221.6679,\n",
      "  'train_samples_per_second': 1.444,\n",
      "  'train_steps_per_second': 0.361},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.34,\n",
      "  'eval_in_loss': 0.9981803894042969,\n",
      "  'eval_in_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_in_runtime': 5.7238,\n",
      "  'eval_in_samples_per_second': 8.735,\n",
      "  'eval_in_steps_per_second': 2.271,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.710095226764679,\n",
      "  'eval_out_peak_memory_gb': 1.7935376167297363,\n",
      "  'eval_out_runtime': 5.5996,\n",
      "  'eval_out_samples_per_second': 8.929,\n",
      "  'eval_out_steps_per_second': 2.322,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.7075376685708761,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 188.0893,\n",
      "  'train_samples_per_second': 1.701,\n",
      "  'train_steps_per_second': 0.425},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.1560779809951782,\n",
      "  'eval_in_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_in_runtime': 6.1335,\n",
      "  'eval_in_samples_per_second': 8.152,\n",
      "  'eval_in_steps_per_second': 2.12,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7630157470703125,\n",
      "  'eval_out_peak_memory_gb': 1.7945141792297363,\n",
      "  'eval_out_runtime': 6.1158,\n",
      "  'eval_out_samples_per_second': 8.176,\n",
      "  'eval_out_steps_per_second': 2.126,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'total_flos': 298601561456640.0,\n",
      "  'train_loss': 0.30088053867220876,\n",
      "  'train_peak_memory_gb': 6.645327568054199,\n",
      "  'train_runtime': 189.3637,\n",
      "  'train_samples_per_second': 1.69,\n",
      "  'train_steps_per_second': 0.422},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.34,\n",
      "  'eval_in_loss': 0.9728612303733826,\n",
      "  'eval_in_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_in_runtime': 4.4834,\n",
      "  'eval_in_samples_per_second': 11.152,\n",
      "  'eval_in_steps_per_second': 5.576,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7060052752494812,\n",
      "  'eval_out_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_out_runtime': 4.5313,\n",
      "  'eval_out_samples_per_second': 11.034,\n",
      "  'eval_out_steps_per_second': 5.517,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.8095592551631853,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 178.4236,\n",
      "  'train_samples_per_second': 3.587,\n",
      "  'train_steps_per_second': 1.793},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 1.0118420124053955,\n",
      "  'eval_in_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_in_runtime': 4.5521,\n",
      "  'eval_in_samples_per_second': 10.984,\n",
      "  'eval_in_steps_per_second': 5.492,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7130058407783508,\n",
      "  'eval_out_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_out_runtime': 4.5764,\n",
      "  'eval_out_samples_per_second': 10.926,\n",
      "  'eval_out_steps_per_second': 5.463,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.5107013254892081,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 176.5296,\n",
      "  'train_samples_per_second': 3.625,\n",
      "  'train_steps_per_second': 1.813},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 1.0250109434127808,\n",
      "  'eval_in_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_in_runtime': 4.4894,\n",
      "  'eval_in_samples_per_second': 11.137,\n",
      "  'eval_in_steps_per_second': 5.569,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7398499846458435,\n",
      "  'eval_out_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_out_runtime': 4.4882,\n",
      "  'eval_out_samples_per_second': 11.14,\n",
      "  'eval_out_steps_per_second': 5.57,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.5499713982455432,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 177.092,\n",
      "  'train_samples_per_second': 3.614,\n",
      "  'train_steps_per_second': 1.807},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 1.266458511352539,\n",
      "  'eval_in_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_in_runtime': 4.4729,\n",
      "  'eval_in_samples_per_second': 11.179,\n",
      "  'eval_in_steps_per_second': 5.589,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7862338423728943,\n",
      "  'eval_out_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_out_runtime': 4.4552,\n",
      "  'eval_out_samples_per_second': 11.223,\n",
      "  'eval_out_steps_per_second': 5.611,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.5290714550530538,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 176.8922,\n",
      "  'train_samples_per_second': 3.618,\n",
      "  'train_steps_per_second': 1.809},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.9833840131759644,\n",
      "  'eval_in_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_in_runtime': 4.5198,\n",
      "  'eval_in_samples_per_second': 11.062,\n",
      "  'eval_in_steps_per_second': 5.531,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7989174127578735,\n",
      "  'eval_out_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_out_runtime': 4.6379,\n",
      "  'eval_out_samples_per_second': 10.781,\n",
      "  'eval_out_steps_per_second': 5.39,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.7427294386085123,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 177.0595,\n",
      "  'train_samples_per_second': 3.615,\n",
      "  'train_steps_per_second': 1.807},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 1.0197787284851074,\n",
      "  'eval_in_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_in_runtime': 4.557,\n",
      "  'eval_in_samples_per_second': 10.972,\n",
      "  'eval_in_steps_per_second': 5.486,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7419705986976624,\n",
      "  'eval_out_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_out_runtime': 4.5204,\n",
      "  'eval_out_samples_per_second': 11.061,\n",
      "  'eval_out_steps_per_second': 5.53,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.5030025236075744,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 179.4619,\n",
      "  'train_samples_per_second': 3.566,\n",
      "  'train_steps_per_second': 1.783},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 0.9977893829345703,\n",
      "  'eval_in_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_in_runtime': 4.5298,\n",
      "  'eval_in_samples_per_second': 11.038,\n",
      "  'eval_in_steps_per_second': 5.519,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.728563129901886,\n",
      "  'eval_out_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_out_runtime': 4.5308,\n",
      "  'eval_out_samples_per_second': 11.036,\n",
      "  'eval_out_steps_per_second': 5.518,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.5637440774124116,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 175.8163,\n",
      "  'train_samples_per_second': 3.64,\n",
      "  'train_steps_per_second': 1.82},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 1.0451923608779907,\n",
      "  'eval_in_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_in_runtime': 4.4804,\n",
      "  'eval_in_samples_per_second': 11.16,\n",
      "  'eval_in_steps_per_second': 5.58,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.808504581451416,\n",
      "  'eval_out_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_out_runtime': 4.4444,\n",
      "  'eval_out_samples_per_second': 11.25,\n",
      "  'eval_out_steps_per_second': 5.625,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.7181582871126011,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 175.0967,\n",
      "  'train_samples_per_second': 3.655,\n",
      "  'train_steps_per_second': 1.828},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 0.8553858995437622,\n",
      "  'eval_in_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_in_runtime': 4.5102,\n",
      "  'eval_in_samples_per_second': 11.086,\n",
      "  'eval_in_steps_per_second': 5.543,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.7195879220962524,\n",
      "  'eval_out_peak_memory_gb': 1.5259442329406738,\n",
      "  'eval_out_runtime': 4.5985,\n",
      "  'eval_out_samples_per_second': 10.873,\n",
      "  'eval_out_steps_per_second': 5.437,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.9048312320373952,\n",
      "  'train_peak_memory_gb': 3.950869560241699,\n",
      "  'train_runtime': 175.4274,\n",
      "  'train_samples_per_second': 3.648,\n",
      "  'train_steps_per_second': 1.824},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.9881778955459595,\n",
      "  'eval_in_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_in_runtime': 4.4871,\n",
      "  'eval_in_samples_per_second': 11.143,\n",
      "  'eval_in_steps_per_second': 5.571,\n",
      "  'eval_out_accuracy': 0.58,\n",
      "  'eval_out_loss': 0.7286532521247864,\n",
      "  'eval_out_peak_memory_gb': 1.5269207954406738,\n",
      "  'eval_out_runtime': 4.5176,\n",
      "  'eval_out_samples_per_second': 11.068,\n",
      "  'eval_out_steps_per_second': 5.534,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'total_flos': 597203122913280.0,\n",
      "  'train_loss': 0.8250088006956503,\n",
      "  'train_peak_memory_gb': 3.951846122741699,\n",
      "  'train_runtime': 176.3728,\n",
      "  'train_samples_per_second': 3.629,\n",
      "  'train_steps_per_second': 1.814}]\n",
      "Training histories:\n",
      "[{'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7163,\n",
      "                 0.854,\n",
      "                 0.7275,\n",
      "                 0.7902,\n",
      "                 0.8125,\n",
      "                 0.7758,\n",
      "                 0.7125,\n",
      "                 0.6974,\n",
      "                 0.785,\n",
      "                 0.7823,\n",
      "                 0.748,\n",
      "                 0.7382,\n",
      "                 0.7935,\n",
      "                 0.6308,\n",
      "                 0.6791,\n",
      "                 0.7445,\n",
      "                 0.7064,\n",
      "                 0.5039,\n",
      "                 0.7863,\n",
      "                 0.6672,\n",
      "                 0.7949,\n",
      "                 0.6477,\n",
      "                 0.6869,\n",
      "                 0.7474,\n",
      "                 0.6285,\n",
      "                 0.6511,\n",
      "                 0.7161,\n",
      "                 0.702,\n",
      "                 0.6001,\n",
      "                 0.7468,\n",
      "                 0.6294,\n",
      "                 0.6969,\n",
      "                 0.5355,\n",
      "                 0.6562,\n",
      "                 0.6803,\n",
      "                 0.6768,\n",
      "                 0.7257,\n",
      "                 0.453,\n",
      "                 0.6661,\n",
      "                 0.6079],\n",
      "  'val_loss': [0.8814101219177246,\n",
      "               0.8818359375,\n",
      "               0.8826626539230347,\n",
      "               0.8841611742973328,\n",
      "               0.8863226175308228,\n",
      "               0.8883417844772339,\n",
      "               0.8903830647468567,\n",
      "               0.8922654390335083,\n",
      "               0.8942033648490906,\n",
      "               0.8961371183395386,\n",
      "               0.8979066610336304,\n",
      "               0.8995196223258972,\n",
      "               0.9010517001152039,\n",
      "               0.9025139808654785,\n",
      "               0.904009222984314,\n",
      "               0.9054580926895142,\n",
      "               0.9067695736885071,\n",
      "               0.9080495834350586,\n",
      "               0.9092880487442017,\n",
      "               0.9105332493782043,\n",
      "               0.9117452502250671,\n",
      "               0.9129422307014465,\n",
      "               0.9139930009841919,\n",
      "               0.915002167224884,\n",
      "               0.9158873558044434,\n",
      "               0.9167488813400269,\n",
      "               0.9175370335578918,\n",
      "               0.9182464480400085,\n",
      "               0.9188936352729797,\n",
      "               0.9194713830947876,\n",
      "               0.9199814796447754,\n",
      "               0.9204327464103699,\n",
      "               0.920846164226532,\n",
      "               0.921221137046814,\n",
      "               0.9215499758720398,\n",
      "               0.9218265414237976,\n",
      "               0.9220353960990906,\n",
      "               0.9222061038017273,\n",
      "               0.9223129153251648,\n",
      "               0.9223664999008179]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.4849,\n",
      "                 0.4794,\n",
      "                 0.5217,\n",
      "                 0.5278,\n",
      "                 0.4996,\n",
      "                 0.4023,\n",
      "                 0.4857,\n",
      "                 0.47,\n",
      "                 0.5532,\n",
      "                 0.5223,\n",
      "                 0.3638,\n",
      "                 0.5157,\n",
      "                 0.4165,\n",
      "                 0.4227,\n",
      "                 0.3974,\n",
      "                 0.4526,\n",
      "                 0.3946,\n",
      "                 0.4447,\n",
      "                 0.4186,\n",
      "                 0.3939,\n",
      "                 0.3147,\n",
      "                 0.4043,\n",
      "                 0.3496,\n",
      "                 0.3789,\n",
      "                 0.4433,\n",
      "                 0.3542,\n",
      "                 0.3512,\n",
      "                 0.3634,\n",
      "                 0.3459,\n",
      "                 0.2785,\n",
      "                 0.2698,\n",
      "                 0.3405,\n",
      "                 0.298,\n",
      "                 0.3002,\n",
      "                 0.3657,\n",
      "                 0.3017,\n",
      "                 0.3208,\n",
      "                 0.2586,\n",
      "                 0.3145,\n",
      "                 0.2964],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.839826226234436,\n",
      "               0.8428308367729187,\n",
      "               0.8473345041275024,\n",
      "               0.8535428047180176,\n",
      "               0.8596742749214172,\n",
      "               0.8658025860786438,\n",
      "               0.8718520998954773,\n",
      "               0.8778136968612671,\n",
      "               0.8836036920547485,\n",
      "               0.8892095685005188,\n",
      "               0.8946801424026489,\n",
      "               0.900002121925354,\n",
      "               0.905173122882843,\n",
      "               0.9102201461791992,\n",
      "               0.9150630831718445,\n",
      "               0.9197391271591187,\n",
      "               0.9242545366287231,\n",
      "               0.9285458326339722,\n",
      "               0.9326173663139343,\n",
      "               0.9365425109863281,\n",
      "               0.9402902722358704,\n",
      "               0.9438415765762329,\n",
      "               0.9472198486328125,\n",
      "               0.9503933191299438,\n",
      "               0.9533916711807251,\n",
      "               0.9561896324157715,\n",
      "               0.9588183164596558,\n",
      "               0.961254894733429,\n",
      "               0.9634958505630493,\n",
      "               0.9655362963676453,\n",
      "               0.9673728942871094,\n",
      "               0.969012439250946,\n",
      "               0.9704580307006836,\n",
      "               0.9716976881027222,\n",
      "               0.9727327227592468,\n",
      "               0.97356116771698,\n",
      "               0.9741859436035156,\n",
      "               0.9746028780937195,\n",
      "               0.9748133420944214]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7769,\n",
      "                 0.7325,\n",
      "                 0.9441,\n",
      "                 0.7246,\n",
      "                 0.8561,\n",
      "                 0.8171,\n",
      "                 0.8051,\n",
      "                 0.7427,\n",
      "                 0.7444,\n",
      "                 0.6319,\n",
      "                 0.7003,\n",
      "                 0.7315,\n",
      "                 0.6167,\n",
      "                 0.6885,\n",
      "                 0.5964,\n",
      "                 0.7896,\n",
      "                 0.603,\n",
      "                 0.5721,\n",
      "                 0.5438,\n",
      "                 0.5884,\n",
      "                 0.6366,\n",
      "                 0.6557,\n",
      "                 0.5854,\n",
      "                 0.6019,\n",
      "                 0.6502,\n",
      "                 0.4842,\n",
      "                 0.5317,\n",
      "                 0.5705,\n",
      "                 0.4855,\n",
      "                 0.5402,\n",
      "                 0.5181,\n",
      "                 0.6082,\n",
      "                 0.5933,\n",
      "                 0.5015,\n",
      "                 0.5198,\n",
      "                 0.4959,\n",
      "                 0.5492,\n",
      "                 0.5651,\n",
      "                 0.4809,\n",
      "                 0.5914],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8366472125053406,\n",
      "               0.8334590196609497,\n",
      "               0.8288182020187378,\n",
      "               0.8226602673530579,\n",
      "               0.8166723251342773,\n",
      "               0.8108912706375122,\n",
      "               0.8053128123283386,\n",
      "               0.7999898195266724,\n",
      "               0.794899046421051,\n",
      "               0.789989709854126,\n",
      "               0.7852577567100525,\n",
      "               0.7807257175445557,\n",
      "               0.7763975858688354,\n",
      "               0.7722744941711426,\n",
      "               0.768328070640564,\n",
      "               0.7645928859710693,\n",
      "               0.7610717415809631,\n",
      "               0.7577350735664368,\n",
      "               0.7545720338821411,\n",
      "               0.7515641450881958,\n",
      "               0.7487132549285889,\n",
      "               0.7460245490074158,\n",
      "               0.7435168027877808,\n",
      "               0.7411905527114868,\n",
      "               0.7390144467353821,\n",
      "               0.7369951009750366,\n",
      "               0.7351325154304504,\n",
      "               0.7334168553352356,\n",
      "               0.7318588495254517,\n",
      "               0.7304348349571228,\n",
      "               0.7291617393493652,\n",
      "               0.7280302047729492,\n",
      "               0.7270445823669434,\n",
      "               0.7262049913406372,\n",
      "               0.725504994392395,\n",
      "               0.7249451279640198,\n",
      "               0.7245250940322876,\n",
      "               0.7242461442947388,\n",
      "               0.7241063714027405]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.5244,\n",
      "                 1.5237,\n",
      "                 1.3671,\n",
      "                 1.4926,\n",
      "                 1.6977,\n",
      "                 1.4472,\n",
      "                 1.4462,\n",
      "                 1.4909,\n",
      "                 1.5935,\n",
      "                 1.3795,\n",
      "                 1.244,\n",
      "                 1.3381,\n",
      "                 1.2571,\n",
      "                 1.1733,\n",
      "                 1.1101,\n",
      "                 1.0831,\n",
      "                 1.257,\n",
      "                 1.2208,\n",
      "                 1.3557,\n",
      "                 1.1053,\n",
      "                 1.0669,\n",
      "                 1.1151,\n",
      "                 1.1282,\n",
      "                 1.3545,\n",
      "                 1.3177,\n",
      "                 1.0817,\n",
      "                 1.0472,\n",
      "                 1.0061,\n",
      "                 1.1433,\n",
      "                 1.0005,\n",
      "                 0.9251,\n",
      "                 1.0477,\n",
      "                 1.1287,\n",
      "                 1.1059,\n",
      "                 0.9661,\n",
      "                 1.1341,\n",
      "                 0.9822,\n",
      "                 1.0787,\n",
      "                 1.0127,\n",
      "                 0.8821],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.836833119392395,\n",
      "               0.8340074419975281,\n",
      "               0.8298638463020325,\n",
      "               0.8244225382804871,\n",
      "               0.8192054629325867,\n",
      "               0.8141809701919556,\n",
      "               0.8093504905700684,\n",
      "               0.8047207593917847,\n",
      "               0.8003255724906921,\n",
      "               0.7960706949234009,\n",
      "               0.7919346690177917,\n",
      "               0.7879465818405151,\n",
      "               0.7841259241104126,\n",
      "               0.7804790735244751,\n",
      "               0.7770445942878723,\n",
      "               0.7737659215927124,\n",
      "               0.770675778388977,\n",
      "               0.7677598595619202,\n",
      "               0.7649924159049988,\n",
      "               0.762352466583252,\n",
      "               0.759875476360321,\n",
      "               0.7575761079788208,\n",
      "               0.7554190754890442,\n",
      "               0.7533971667289734,\n",
      "               0.7514875531196594,\n",
      "               0.7496998310089111,\n",
      "               0.7480225563049316,\n",
      "               0.7464824914932251,\n",
      "               0.7450810670852661,\n",
      "               0.7437947988510132,\n",
      "               0.7426434755325317,\n",
      "               0.7416163682937622,\n",
      "               0.7407140731811523,\n",
      "               0.7399370074272156,\n",
      "               0.7392905354499817,\n",
      "               0.7387775778770447,\n",
      "               0.7383958101272583,\n",
      "               0.7381414175033569,\n",
      "               0.7380141019821167]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7294,\n",
      "                 0.8021,\n",
      "                 0.8159,\n",
      "                 0.7633,\n",
      "                 0.802,\n",
      "                 1.0006,\n",
      "                 0.9157,\n",
      "                 0.7274,\n",
      "                 0.728,\n",
      "                 0.6796,\n",
      "                 0.8554,\n",
      "                 0.7938,\n",
      "                 0.6264,\n",
      "                 0.8016,\n",
      "                 0.817,\n",
      "                 0.8653,\n",
      "                 0.6911,\n",
      "                 0.728,\n",
      "                 0.7016,\n",
      "                 0.7035,\n",
      "                 0.641,\n",
      "                 0.8701,\n",
      "                 0.7593,\n",
      "                 0.6277,\n",
      "                 0.8144,\n",
      "                 0.7341,\n",
      "                 0.6878,\n",
      "                 0.7697,\n",
      "                 0.767,\n",
      "                 0.7415,\n",
      "                 0.7058,\n",
      "                 0.8346,\n",
      "                 0.7265,\n",
      "                 0.6703,\n",
      "                 0.8432,\n",
      "                 0.8998,\n",
      "                 0.649,\n",
      "                 0.7248,\n",
      "                 0.7083,\n",
      "                 0.6226],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8373836278915405,\n",
      "               0.8357805013656616,\n",
      "               0.833696722984314,\n",
      "               0.8309265375137329,\n",
      "               0.8285626173019409,\n",
      "               0.8261510133743286,\n",
      "               0.8236845135688782,\n",
      "               0.8211408853530884,\n",
      "               0.8186895251274109,\n",
      "               0.8162118792533875,\n",
      "               0.8139151334762573,\n",
      "               0.8117580413818359,\n",
      "               0.809597373008728,\n",
      "               0.807603657245636,\n",
      "               0.8057724833488464,\n",
      "               0.8041569590568542,\n",
      "               0.8026402592658997,\n",
      "               0.8012349009513855,\n",
      "               0.7998940348625183,\n",
      "               0.7986108660697937,\n",
      "               0.7972811460494995,\n",
      "               0.7959913015365601,\n",
      "               0.7947483062744141,\n",
      "               0.7936169505119324,\n",
      "               0.7926115393638611,\n",
      "               0.7916653752326965,\n",
      "               0.7908417582511902,\n",
      "               0.7901127934455872,\n",
      "               0.7893975377082825,\n",
      "               0.7887751460075378,\n",
      "               0.7882174253463745,\n",
      "               0.7877016067504883,\n",
      "               0.7872666716575623,\n",
      "               0.7868783473968506,\n",
      "               0.7865422964096069,\n",
      "               0.7862826585769653,\n",
      "               0.7860790491104126,\n",
      "               0.7859374284744263,\n",
      "               0.7858710885047913]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6834,\n",
      "                 0.6001,\n",
      "                 0.8027,\n",
      "                 0.7396,\n",
      "                 0.6661,\n",
      "                 0.6085,\n",
      "                 0.5526,\n",
      "                 0.634,\n",
      "                 0.6407,\n",
      "                 0.8415,\n",
      "                 0.6979,\n",
      "                 0.7415,\n",
      "                 0.7228,\n",
      "                 0.7138,\n",
      "                 0.7424,\n",
      "                 0.6328,\n",
      "                 0.6962,\n",
      "                 0.5943,\n",
      "                 0.6235,\n",
      "                 0.598,\n",
      "                 0.6157,\n",
      "                 0.7735,\n",
      "                 0.6492,\n",
      "                 0.6407,\n",
      "                 0.6655,\n",
      "                 0.5163,\n",
      "                 0.6785,\n",
      "                 0.6314,\n",
      "                 0.523,\n",
      "                 0.5947,\n",
      "                 0.5923,\n",
      "                 0.6384,\n",
      "                 0.6674,\n",
      "                 0.5984,\n",
      "                 0.5615,\n",
      "                 0.6048,\n",
      "                 0.6062,\n",
      "                 0.5735,\n",
      "                 0.7304,\n",
      "                 0.6753],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8381708264350891,\n",
      "               0.8381195068359375,\n",
      "               0.8379429578781128,\n",
      "               0.8381155133247375,\n",
      "               0.8382915258407593,\n",
      "               0.8380153775215149,\n",
      "               0.8377485275268555,\n",
      "               0.8376733660697937,\n",
      "               0.8378151059150696,\n",
      "               0.8379721641540527,\n",
      "               0.8379091024398804,\n",
      "               0.8378008604049683,\n",
      "               0.8376182317733765,\n",
      "               0.8374699354171753,\n",
      "               0.8376910090446472,\n",
      "               0.8379597663879395,\n",
      "               0.8382209539413452,\n",
      "               0.8383579254150391,\n",
      "               0.8384504318237305,\n",
      "               0.8386656045913696,\n",
      "               0.8387318849563599,\n",
      "               0.8386801481246948,\n",
      "               0.8387110829353333,\n",
      "               0.8388069868087769,\n",
      "               0.8389055132865906,\n",
      "               0.8389317393302917,\n",
      "               0.8390525579452515,\n",
      "               0.8391348123550415,\n",
      "               0.8392289280891418,\n",
      "               0.8392783999443054,\n",
      "               0.8393121957778931,\n",
      "               0.8393357992172241,\n",
      "               0.8393437266349792,\n",
      "               0.8393682241439819,\n",
      "               0.8393804430961609,\n",
      "               0.8393756151199341,\n",
      "               0.8393502235412598,\n",
      "               0.8393389582633972,\n",
      "               0.8393279910087585]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.1003,\n",
      "                 1.2592,\n",
      "                 1.043,\n",
      "                 1.0405,\n",
      "                 1.1394,\n",
      "                 1.0547,\n",
      "                 0.8794,\n",
      "                 0.9828,\n",
      "                 0.9536,\n",
      "                 1.0456,\n",
      "                 0.8458,\n",
      "                 0.9916,\n",
      "                 0.7682,\n",
      "                 0.8706,\n",
      "                 0.8872,\n",
      "                 0.9913,\n",
      "                 0.9706,\n",
      "                 0.8505,\n",
      "                 0.8084,\n",
      "                 0.908,\n",
      "                 0.6991,\n",
      "                 0.8798,\n",
      "                 0.6887,\n",
      "                 0.776,\n",
      "                 0.9872,\n",
      "                 0.8377,\n",
      "                 0.7536,\n",
      "                 0.8377,\n",
      "                 0.813,\n",
      "                 0.8053,\n",
      "                 0.7435,\n",
      "                 0.7137,\n",
      "                 0.6657,\n",
      "                 0.7128,\n",
      "                 0.7116,\n",
      "                 0.8441,\n",
      "                 0.7416,\n",
      "                 0.6926,\n",
      "                 0.6937,\n",
      "                 0.647],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8365761041641235,\n",
      "               0.8332207798957825,\n",
      "               0.82830411195755,\n",
      "               0.8217746615409851,\n",
      "               0.8154309988021851,\n",
      "               0.8093518018722534,\n",
      "               0.8034915924072266,\n",
      "               0.7979252934455872,\n",
      "               0.7926465272903442,\n",
      "               0.7875702977180481,\n",
      "               0.7826648354530334,\n",
      "               0.7779645919799805,\n",
      "               0.7734850645065308,\n",
      "               0.7692133188247681,\n",
      "               0.7651292681694031,\n",
      "               0.7612456679344177,\n",
      "               0.7575720548629761,\n",
      "               0.7541009783744812,\n",
      "               0.7507710456848145,\n",
      "               0.7476153373718262,\n",
      "               0.7446481585502625,\n",
      "               0.7418535351753235,\n",
      "               0.7392340898513794,\n",
      "               0.7368015050888062,\n",
      "               0.7345224022865295,\n",
      "               0.7324059009552002,\n",
      "               0.7304588556289673,\n",
      "               0.7286694049835205,\n",
      "               0.7270393371582031,\n",
      "               0.7255740761756897,\n",
      "               0.72425776720047,\n",
      "               0.7230846285820007,\n",
      "               0.7220609188079834,\n",
      "               0.7211823463439941,\n",
      "               0.7204494476318359,\n",
      "               0.7198613882064819,\n",
      "               0.7194257974624634,\n",
      "               0.7191339731216431,\n",
      "               0.7189873456954956]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.5708,\n",
      "                 0.6407,\n",
      "                 0.5601,\n",
      "                 0.4973,\n",
      "                 0.6891,\n",
      "                 0.577,\n",
      "                 0.5314,\n",
      "                 0.5538,\n",
      "                 0.5139,\n",
      "                 0.5486,\n",
      "                 0.5388,\n",
      "                 0.4995,\n",
      "                 0.6559,\n",
      "                 0.5846,\n",
      "                 0.5503,\n",
      "                 0.5057,\n",
      "                 0.5605,\n",
      "                 0.5403,\n",
      "                 0.5292,\n",
      "                 0.5895,\n",
      "                 0.4641,\n",
      "                 0.5253,\n",
      "                 0.5776,\n",
      "                 0.5246,\n",
      "                 0.5522,\n",
      "                 0.4983,\n",
      "                 0.5132,\n",
      "                 0.4977,\n",
      "                 0.5374,\n",
      "                 0.5382,\n",
      "                 0.6008,\n",
      "                 0.4842,\n",
      "                 0.5022,\n",
      "                 0.4403,\n",
      "                 0.479,\n",
      "                 0.5313,\n",
      "                 0.5225,\n",
      "                 0.5455,\n",
      "                 0.538,\n",
      "                 0.529],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8385715484619141,\n",
      "               0.8388675451278687,\n",
      "               0.8389708399772644,\n",
      "               0.8393646478652954,\n",
      "               0.839931845664978,\n",
      "               0.8401473760604858,\n",
      "               0.8403266668319702,\n",
      "               0.8402953147888184,\n",
      "               0.8401268720626831,\n",
      "               0.839743971824646,\n",
      "               0.8392793536186218,\n",
      "               0.8388096690177917,\n",
      "               0.8382529020309448,\n",
      "               0.8377920985221863,\n",
      "               0.8373295068740845,\n",
      "               0.8369532823562622,\n",
      "               0.8366895914077759,\n",
      "               0.8364879488945007,\n",
      "               0.8361572027206421,\n",
      "               0.8359025716781616,\n",
      "               0.8356168866157532,\n",
      "               0.8354206085205078,\n",
      "               0.8351532816886902,\n",
      "               0.8349482417106628,\n",
      "               0.8348619341850281,\n",
      "               0.8347395062446594,\n",
      "               0.8347102403640747,\n",
      "               0.8346474766731262,\n",
      "               0.8345667123794556,\n",
      "               0.8344951868057251,\n",
      "               0.8344656229019165,\n",
      "               0.8344444036483765,\n",
      "               0.8344197273254395,\n",
      "               0.8343943357467651,\n",
      "               0.8343551754951477,\n",
      "               0.8343454599380493,\n",
      "               0.8343192338943481,\n",
      "               0.8342982530593872,\n",
      "               0.8342930674552917]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7802,\n",
      "                 0.8688,\n",
      "                 0.7628,\n",
      "                 0.8256,\n",
      "                 0.8126,\n",
      "                 0.7414,\n",
      "                 0.6977,\n",
      "                 0.6878,\n",
      "                 0.6307,\n",
      "                 0.7064,\n",
      "                 0.6562,\n",
      "                 0.6589,\n",
      "                 0.5832,\n",
      "                 0.5638,\n",
      "                 0.6389,\n",
      "                 0.6223,\n",
      "                 0.7056,\n",
      "                 0.6368,\n",
      "                 0.7107,\n",
      "                 0.549,\n",
      "                 0.6101,\n",
      "                 0.6064,\n",
      "                 0.5287,\n",
      "                 0.5635,\n",
      "                 0.5544,\n",
      "                 0.5558,\n",
      "                 0.5839,\n",
      "                 0.5264,\n",
      "                 0.5385,\n",
      "                 0.5918,\n",
      "                 0.6061,\n",
      "                 0.5492,\n",
      "                 0.6019,\n",
      "                 0.5662,\n",
      "                 0.5167,\n",
      "                 0.6217,\n",
      "                 0.4377,\n",
      "                 0.5576,\n",
      "                 0.532,\n",
      "                 0.5124],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8365353345870972,\n",
      "               0.8331998586654663,\n",
      "               0.8282468914985657,\n",
      "               0.8216317892074585,\n",
      "               0.8152546882629395,\n",
      "               0.8091030120849609,\n",
      "               0.8032078742980957,\n",
      "               0.7975411415100098,\n",
      "               0.7921627759933472,\n",
      "               0.7869551777839661,\n",
      "               0.7819747924804688,\n",
      "               0.7771870493888855,\n",
      "               0.7726253271102905,\n",
      "               0.7682515382766724,\n",
      "               0.7640889883041382,\n",
      "               0.7601186633110046,\n",
      "               0.7563576698303223,\n",
      "               0.752792239189148,\n",
      "               0.7494146823883057,\n",
      "               0.7462334036827087,\n",
      "               0.7432421445846558,\n",
      "               0.7404267191886902,\n",
      "               0.7377889752388,\n",
      "               0.7353491187095642,\n",
      "               0.7330576181411743,\n",
      "               0.7309209108352661,\n",
      "               0.7289352416992188,\n",
      "               0.727105975151062,\n",
      "               0.7254334688186646,\n",
      "               0.7239063382148743,\n",
      "               0.7225439548492432,\n",
      "               0.7213395237922668,\n",
      "               0.7202836275100708,\n",
      "               0.7193829417228699,\n",
      "               0.7186336517333984,\n",
      "               0.7180342674255371,\n",
      "               0.7175880670547485,\n",
      "               0.717288613319397,\n",
      "               0.7171388864517212]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.7667,\n",
      "                 0.6157,\n",
      "                 0.7504,\n",
      "                 0.7639,\n",
      "                 0.8115,\n",
      "                 0.7865,\n",
      "                 0.5551,\n",
      "                 0.5104,\n",
      "                 0.6893,\n",
      "                 0.6301,\n",
      "                 0.7162,\n",
      "                 0.5855,\n",
      "                 0.5799,\n",
      "                 0.4859,\n",
      "                 0.6318,\n",
      "                 0.5935,\n",
      "                 0.5285,\n",
      "                 0.5035,\n",
      "                 0.5392,\n",
      "                 0.4875,\n",
      "                 0.5437,\n",
      "                 0.4721,\n",
      "                 0.3797,\n",
      "                 0.6535,\n",
      "                 0.5394,\n",
      "                 0.4725,\n",
      "                 0.5279,\n",
      "                 0.55,\n",
      "                 0.4517,\n",
      "                 0.4711,\n",
      "                 0.5339,\n",
      "                 0.4299,\n",
      "                 0.454,\n",
      "                 0.5386,\n",
      "                 0.5096,\n",
      "                 0.4945,\n",
      "                 0.4833,\n",
      "                 0.4426,\n",
      "                 0.5066,\n",
      "                 0.5202],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8400249481201172,\n",
      "               0.8434267044067383,\n",
      "               0.8483834266662598,\n",
      "               0.8551067113876343,\n",
      "               0.8617541193962097,\n",
      "               0.8683603405952454,\n",
      "               0.8748628497123718,\n",
      "               0.8811985850334167,\n",
      "               0.8873252868652344,\n",
      "               0.8933359384536743,\n",
      "               0.8991876840591431,\n",
      "               0.9049324989318848,\n",
      "               0.9105015993118286,\n",
      "               0.915939450263977,\n",
      "               0.9212082624435425,\n",
      "               0.9262863397598267,\n",
      "               0.9311552047729492,\n",
      "               0.93580561876297,\n",
      "               0.940298855304718,\n",
      "               0.9446352124214172,\n",
      "               0.9487816691398621,\n",
      "               0.9527454376220703,\n",
      "               0.956494152545929,\n",
      "               0.9599750638008118,\n",
      "               0.9632620811462402,\n",
      "               0.9663491249084473,\n",
      "               0.9692336320877075,\n",
      "               0.9719161987304688,\n",
      "               0.9743897318840027,\n",
      "               0.976637065410614,\n",
      "               0.9786514043807983,\n",
      "               0.9804484248161316,\n",
      "               0.9820218086242676,\n",
      "               0.9833663702011108,\n",
      "               0.9844835996627808,\n",
      "               0.9853809475898743,\n",
      "               0.9860550165176392,\n",
      "               0.9865058660507202,\n",
      "               0.9867327809333801]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.8176,\n",
      "                 0.7948,\n",
      "                 0.8172,\n",
      "                 0.7828,\n",
      "                 0.7605,\n",
      "                 0.644,\n",
      "                 0.7875,\n",
      "                 0.7325,\n",
      "                 0.8029,\n",
      "                 0.8978,\n",
      "                 0.8182,\n",
      "                 0.7157,\n",
      "                 0.6824,\n",
      "                 0.7377,\n",
      "                 0.7114,\n",
      "                 0.7006,\n",
      "                 0.702,\n",
      "                 0.6957,\n",
      "                 0.7594,\n",
      "                 0.6658,\n",
      "                 0.7526,\n",
      "                 0.7806,\n",
      "                 0.7544,\n",
      "                 0.694,\n",
      "                 0.6542,\n",
      "                 0.68,\n",
      "                 0.7421,\n",
      "                 0.6681,\n",
      "                 0.6219,\n",
      "                 0.5972,\n",
      "                 0.7292,\n",
      "                 0.6753,\n",
      "                 0.793,\n",
      "                 0.7247,\n",
      "                 0.7052,\n",
      "                 0.6899,\n",
      "                 0.6496,\n",
      "                 0.6708,\n",
      "                 0.6252,\n",
      "                 0.701],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8371468782424927,\n",
      "               0.834870457649231,\n",
      "               0.831485390663147,\n",
      "               0.827157199382782,\n",
      "               0.8228093981742859,\n",
      "               0.8186981081962585,\n",
      "               0.8147729635238647,\n",
      "               0.810961127281189,\n",
      "               0.8075528144836426,\n",
      "               0.80427086353302,\n",
      "               0.8011224865913391,\n",
      "               0.7982320189476013,\n",
      "               0.7953518629074097,\n",
      "               0.792686939239502,\n",
      "               0.7901559472084045,\n",
      "               0.7877174019813538,\n",
      "               0.7852964997291565,\n",
      "               0.782932698726654,\n",
      "               0.7806605100631714,\n",
      "               0.7785732746124268,\n",
      "               0.7767273783683777,\n",
      "               0.7750632166862488,\n",
      "               0.7735502123832703,\n",
      "               0.7721004486083984,\n",
      "               0.7707972526550293,\n",
      "               0.7695158123970032,\n",
      "               0.7683590650558472,\n",
      "               0.767294704914093,\n",
      "               0.7663000822067261,\n",
      "               0.7653964757919312,\n",
      "               0.7645779848098755,\n",
      "               0.7638760805130005,\n",
      "               0.7632646560668945,\n",
      "               0.7627431750297546,\n",
      "               0.7623006105422974,\n",
      "               0.7619549036026001,\n",
      "               0.7617043256759644,\n",
      "               0.7615377902984619,\n",
      "               0.7614547610282898]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.0362,\n",
      "                 0.9827,\n",
      "                 1.1346,\n",
      "                 0.9791,\n",
      "                 1.005,\n",
      "                 0.8956,\n",
      "                 0.8751,\n",
      "                 0.8749,\n",
      "                 0.975,\n",
      "                 0.8794,\n",
      "                 1.1489,\n",
      "                 0.9127,\n",
      "                 0.8598,\n",
      "                 0.9325,\n",
      "                 0.8897,\n",
      "                 0.8617,\n",
      "                 0.9373,\n",
      "                 0.734,\n",
      "                 0.796,\n",
      "                 0.7888,\n",
      "                 0.8148,\n",
      "                 0.8342,\n",
      "                 0.9213,\n",
      "                 0.79,\n",
      "                 0.8742,\n",
      "                 0.724,\n",
      "                 0.8093,\n",
      "                 0.7792,\n",
      "                 0.8204,\n",
      "                 0.6922,\n",
      "                 0.7494,\n",
      "                 0.8126,\n",
      "                 0.7157,\n",
      "                 0.655,\n",
      "                 0.654,\n",
      "                 0.7663,\n",
      "                 0.7289,\n",
      "                 0.8617,\n",
      "                 0.6974,\n",
      "                 0.6378],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8367248773574829,\n",
      "               0.8335945010185242,\n",
      "               0.8289785385131836,\n",
      "               0.8229163289070129,\n",
      "               0.8170871734619141,\n",
      "               0.8114610910415649,\n",
      "               0.8060730695724487,\n",
      "               0.8009151220321655,\n",
      "               0.7959704399108887,\n",
      "               0.7911924719810486,\n",
      "               0.7866256833076477,\n",
      "               0.7822470664978027,\n",
      "               0.7780932188034058,\n",
      "               0.7741025686264038,\n",
      "               0.7703441381454468,\n",
      "               0.7667660713195801,\n",
      "               0.7633376121520996,\n",
      "               0.7600306272506714,\n",
      "               0.7569320797920227,\n",
      "               0.7540193796157837,\n",
      "               0.7512860894203186,\n",
      "               0.7487231492996216,\n",
      "               0.7463052272796631,\n",
      "               0.7440436482429504,\n",
      "               0.7419143915176392,\n",
      "               0.7399385571479797,\n",
      "               0.7381256222724915,\n",
      "               0.7364803552627563,\n",
      "               0.7349789142608643,\n",
      "               0.73361736536026,\n",
      "               0.732381284236908,\n",
      "               0.7312818765640259,\n",
      "               0.7303240299224854,\n",
      "               0.7295042276382446,\n",
      "               0.7288199663162231,\n",
      "               0.7282792329788208,\n",
      "               0.7278774976730347,\n",
      "               0.7276092171669006,\n",
      "               0.7274749279022217]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.0316,\n",
      "                 0.9606,\n",
      "                 0.9143,\n",
      "                 0.8833,\n",
      "                 0.8204,\n",
      "                 0.8338,\n",
      "                 0.8785,\n",
      "                 0.8943,\n",
      "                 0.8911,\n",
      "                 0.8174,\n",
      "                 0.948,\n",
      "                 0.8385,\n",
      "                 0.8595,\n",
      "                 0.8483,\n",
      "                 0.7887,\n",
      "                 0.8801,\n",
      "                 0.7924,\n",
      "                 0.7265,\n",
      "                 0.7634,\n",
      "                 0.9305,\n",
      "                 0.8614,\n",
      "                 0.7005,\n",
      "                 0.8924,\n",
      "                 0.7373,\n",
      "                 0.6219,\n",
      "                 0.711,\n",
      "                 0.6845,\n",
      "                 0.738,\n",
      "                 0.7421,\n",
      "                 0.7306,\n",
      "                 0.6817,\n",
      "                 0.7807,\n",
      "                 0.7342,\n",
      "                 0.7231,\n",
      "                 0.7006,\n",
      "                 0.7653,\n",
      "                 0.7406,\n",
      "                 0.8006,\n",
      "                 0.799,\n",
      "                 0.7893],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8367847204208374,\n",
      "               0.8337475657463074,\n",
      "               0.8291719555854797,\n",
      "               0.8233469128608704,\n",
      "               0.8178138732910156,\n",
      "               0.8124549984931946,\n",
      "               0.8072188496589661,\n",
      "               0.8022071719169617,\n",
      "               0.797559380531311,\n",
      "               0.7931311130523682,\n",
      "               0.7888302803039551,\n",
      "               0.7847743034362793,\n",
      "               0.7809020280838013,\n",
      "               0.7772542834281921,\n",
      "               0.7737755179405212,\n",
      "               0.7704212069511414,\n",
      "               0.7671944499015808,\n",
      "               0.764093816280365,\n",
      "               0.7611504793167114,\n",
      "               0.7583804130554199,\n",
      "               0.7557810544967651,\n",
      "               0.7533566951751709,\n",
      "               0.7510523796081543,\n",
      "               0.7488579154014587,\n",
      "               0.7468292117118835,\n",
      "               0.7449280023574829,\n",
      "               0.743181586265564,\n",
      "               0.7416427731513977,\n",
      "               0.7402229309082031,\n",
      "               0.7389448285102844,\n",
      "               0.7377955317497253,\n",
      "               0.7367683053016663,\n",
      "               0.7358887791633606,\n",
      "               0.7351417541503906,\n",
      "               0.7345090508460999,\n",
      "               0.7340057492256165,\n",
      "               0.733635425567627,\n",
      "               0.7333882451057434,\n",
      "               0.7332631349563599]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.8665,\n",
      "                 0.8922,\n",
      "                 0.8527,\n",
      "                 0.7967,\n",
      "                 0.8004,\n",
      "                 0.8292,\n",
      "                 0.9606,\n",
      "                 0.8069,\n",
      "                 0.8429,\n",
      "                 0.9379,\n",
      "                 0.8134,\n",
      "                 0.8859,\n",
      "                 0.7996,\n",
      "                 0.7461,\n",
      "                 0.7964,\n",
      "                 0.7274,\n",
      "                 0.7546,\n",
      "                 0.804,\n",
      "                 0.6635,\n",
      "                 0.7476,\n",
      "                 0.7844,\n",
      "                 0.7422,\n",
      "                 0.6999,\n",
      "                 0.7501,\n",
      "                 0.7235,\n",
      "                 0.8246,\n",
      "                 0.7902,\n",
      "                 0.711,\n",
      "                 0.7405,\n",
      "                 0.7672,\n",
      "                 0.8375,\n",
      "                 0.8409,\n",
      "                 0.7212,\n",
      "                 0.7367,\n",
      "                 0.8046,\n",
      "                 0.672,\n",
      "                 0.7042,\n",
      "                 0.5864,\n",
      "                 0.7275,\n",
      "                 0.7773],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8368927836418152,\n",
      "               0.8340654373168945,\n",
      "               0.829816997051239,\n",
      "               0.8243236541748047,\n",
      "               0.8190168142318726,\n",
      "               0.8139604330062866,\n",
      "               0.8091158866882324,\n",
      "               0.8045085072517395,\n",
      "               0.8002458810806274,\n",
      "               0.7962170839309692,\n",
      "               0.7923606634140015,\n",
      "               0.7886988520622253,\n",
      "               0.7852798104286194,\n",
      "               0.7821545600891113,\n",
      "               0.7791754007339478,\n",
      "               0.7763231992721558,\n",
      "               0.7735540270805359,\n",
      "               0.7708702683448792,\n",
      "               0.7683112025260925,\n",
      "               0.7658751010894775,\n",
      "               0.7635430097579956,\n",
      "               0.7613245248794556,\n",
      "               0.7592074871063232,\n",
      "               0.7572327852249146,\n",
      "               0.7555035352706909,\n",
      "               0.7538320422172546,\n",
      "               0.7523180842399597,\n",
      "               0.7509676218032837,\n",
      "               0.7497438192367554,\n",
      "               0.7486444711685181,\n",
      "               0.7476500868797302,\n",
      "               0.746780276298523,\n",
      "               0.7460214495658875,\n",
      "               0.745368480682373,\n",
      "               0.7448195219039917,\n",
      "               0.7443817853927612,\n",
      "               0.7440541386604309,\n",
      "               0.7438328862190247,\n",
      "               0.7437213659286499]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.6224,\n",
      "                 0.6614,\n",
      "                 0.6547,\n",
      "                 0.6348,\n",
      "                 0.7266,\n",
      "                 0.7676,\n",
      "                 0.6728,\n",
      "                 0.6318,\n",
      "                 0.6996,\n",
      "                 0.6682,\n",
      "                 0.6845,\n",
      "                 0.7345,\n",
      "                 0.6033,\n",
      "                 0.6768,\n",
      "                 0.6006,\n",
      "                 0.5409,\n",
      "                 0.5275,\n",
      "                 0.6212,\n",
      "                 0.6288,\n",
      "                 0.6499,\n",
      "                 0.6605,\n",
      "                 0.5434,\n",
      "                 0.6205,\n",
      "                 0.6035,\n",
      "                 0.6284,\n",
      "                 0.6115,\n",
      "                 0.6217,\n",
      "                 0.6236,\n",
      "                 0.5819,\n",
      "                 0.6073,\n",
      "                 0.5848,\n",
      "                 0.5575,\n",
      "                 0.563,\n",
      "                 0.6271,\n",
      "                 0.5075,\n",
      "                 0.5737,\n",
      "                 0.5656,\n",
      "                 0.5653,\n",
      "                 0.6322,\n",
      "                 0.641],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8391131162643433,\n",
      "               0.8406420946121216,\n",
      "               0.8428934812545776,\n",
      "               0.8458962440490723,\n",
      "               0.848733127117157,\n",
      "               0.8518103361129761,\n",
      "               0.854781985282898,\n",
      "               0.8576629757881165,\n",
      "               0.8604329228401184,\n",
      "               0.8630291223526001,\n",
      "               0.8653774261474609,\n",
      "               0.8676044344902039,\n",
      "               0.869529128074646,\n",
      "               0.8713424801826477,\n",
      "               0.8731347918510437,\n",
      "               0.8749669194221497,\n",
      "               0.8768559694290161,\n",
      "               0.8787193298339844,\n",
      "               0.8805125951766968,\n",
      "               0.8820847272872925,\n",
      "               0.8834918141365051,\n",
      "               0.8847302198410034,\n",
      "               0.8858267664909363,\n",
      "               0.886862576007843,\n",
      "               0.8878372311592102,\n",
      "               0.888736367225647,\n",
      "               0.8895813822746277,\n",
      "               0.8902894854545593,\n",
      "               0.8909589052200317,\n",
      "               0.8915582895278931,\n",
      "               0.892093300819397,\n",
      "               0.8925296664237976,\n",
      "               0.892905592918396,\n",
      "               0.8932483792304993,\n",
      "               0.8935270309448242,\n",
      "               0.8937324285507202,\n",
      "               0.8938862681388855,\n",
      "               0.8939841389656067,\n",
      "               0.8940377235412598]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.4867,\n",
      "                 0.5259,\n",
      "                 0.5111,\n",
      "                 0.5408,\n",
      "                 0.5882,\n",
      "                 0.5879,\n",
      "                 0.4992,\n",
      "                 0.5905,\n",
      "                 0.5656,\n",
      "                 0.6299,\n",
      "                 0.5743,\n",
      "                 0.4777,\n",
      "                 0.5979,\n",
      "                 0.5064,\n",
      "                 0.5519,\n",
      "                 0.4636,\n",
      "                 0.5134,\n",
      "                 0.5808,\n",
      "                 0.4594,\n",
      "                 0.495,\n",
      "                 0.5211,\n",
      "                 0.4654,\n",
      "                 0.5005,\n",
      "                 0.4975,\n",
      "                 0.4827,\n",
      "                 0.4611,\n",
      "                 0.4946,\n",
      "                 0.4595,\n",
      "                 0.4713,\n",
      "                 0.4761,\n",
      "                 0.4913,\n",
      "                 0.4803,\n",
      "                 0.4368,\n",
      "                 0.4046,\n",
      "                 0.6405,\n",
      "                 0.4911,\n",
      "                 0.475,\n",
      "                 0.5072,\n",
      "                 0.4532,\n",
      "                 0.4244],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8392434120178223,\n",
      "               0.8413189053535461,\n",
      "               0.8446102142333984,\n",
      "               0.8487512469291687,\n",
      "               0.852892279624939,\n",
      "               0.8569591641426086,\n",
      "               0.8607743382453918,\n",
      "               0.8647061586380005,\n",
      "               0.8682196736335754,\n",
      "               0.8717679977416992,\n",
      "               0.8754218816757202,\n",
      "               0.8787018060684204,\n",
      "               0.8818743824958801,\n",
      "               0.8849199414253235,\n",
      "               0.887945294380188,\n",
      "               0.8908435106277466,\n",
      "               0.8936978578567505,\n",
      "               0.8965497016906738,\n",
      "               0.8991448283195496,\n",
      "               0.9016605615615845,\n",
      "               0.9040117263793945,\n",
      "               0.9062539339065552,\n",
      "               0.9083221554756165,\n",
      "               0.9101699590682983,\n",
      "               0.911896824836731,\n",
      "               0.9135778546333313,\n",
      "               0.9151839017868042,\n",
      "               0.916488528251648,\n",
      "               0.9176535606384277,\n",
      "               0.9186466336250305,\n",
      "               0.9195523262023926,\n",
      "               0.9203813672065735,\n",
      "               0.9211217761039734,\n",
      "               0.9217382669448853,\n",
      "               0.9222674369812012,\n",
      "               0.9226996302604675,\n",
      "               0.9230243563652039,\n",
      "               0.9232460260391235,\n",
      "               0.9233585596084595]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9977,\n",
      "                 0.9464,\n",
      "                 0.9998,\n",
      "                 0.9096,\n",
      "                 0.9588,\n",
      "                 0.9022,\n",
      "                 1.0364,\n",
      "                 0.883,\n",
      "                 0.9516,\n",
      "                 0.8861,\n",
      "                 0.9291,\n",
      "                 0.9731,\n",
      "                 0.9124,\n",
      "                 0.8362,\n",
      "                 0.8302,\n",
      "                 0.8606,\n",
      "                 0.823,\n",
      "                 0.9534,\n",
      "                 0.9576,\n",
      "                 0.8081,\n",
      "                 0.9004,\n",
      "                 0.816,\n",
      "                 0.9191,\n",
      "                 0.6954,\n",
      "                 0.9755,\n",
      "                 0.7584,\n",
      "                 0.8826,\n",
      "                 0.7972,\n",
      "                 0.7346,\n",
      "                 0.7901,\n",
      "                 0.7801,\n",
      "                 0.7735,\n",
      "                 0.8423,\n",
      "                 0.8235,\n",
      "                 0.7817,\n",
      "                 0.7371,\n",
      "                 0.7968,\n",
      "                 0.8658,\n",
      "                 0.8037,\n",
      "                 0.7646],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8372626304626465,\n",
      "               0.8352320790290833,\n",
      "               0.8323277235031128,\n",
      "               0.8287407159805298,\n",
      "               0.825151801109314,\n",
      "               0.8215454816818237,\n",
      "               0.8180838823318481,\n",
      "               0.8148362040519714,\n",
      "               0.8116388320922852,\n",
      "               0.808539867401123,\n",
      "               0.8056228756904602,\n",
      "               0.8027690052986145,\n",
      "               0.8001136779785156,\n",
      "               0.7975220084190369,\n",
      "               0.7950899600982666,\n",
      "               0.7927761673927307,\n",
      "               0.7906100153923035,\n",
      "               0.7886263132095337,\n",
      "               0.7867584824562073,\n",
      "               0.7849870920181274,\n",
      "               0.7832930088043213,\n",
      "               0.781730592250824,\n",
      "               0.7802640199661255,\n",
      "               0.7788690328598022,\n",
      "               0.7775596976280212,\n",
      "               0.7763506174087524,\n",
      "               0.775191068649292,\n",
      "               0.774083137512207,\n",
      "               0.7730878591537476,\n",
      "               0.7721691131591797,\n",
      "               0.7713502049446106,\n",
      "               0.7706456184387207,\n",
      "               0.7700267434120178,\n",
      "               0.7695118188858032,\n",
      "               0.7690821886062622,\n",
      "               0.7687456011772156,\n",
      "               0.7684970498085022,\n",
      "               0.7683374285697937,\n",
      "               0.7682541608810425]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.6538,\n",
      "                 0.7028,\n",
      "                 0.7838,\n",
      "                 0.656,\n",
      "                 0.7074,\n",
      "                 0.6733,\n",
      "                 0.656,\n",
      "                 0.6845,\n",
      "                 0.6644,\n",
      "                 0.6948,\n",
      "                 0.6648,\n",
      "                 0.6516,\n",
      "                 0.6752,\n",
      "                 0.647,\n",
      "                 0.5813,\n",
      "                 0.6197,\n",
      "                 0.6054,\n",
      "                 0.6909,\n",
      "                 0.6596,\n",
      "                 0.5834,\n",
      "                 0.7253,\n",
      "                 0.5436,\n",
      "                 0.6264,\n",
      "                 0.5639,\n",
      "                 0.6013,\n",
      "                 0.5625,\n",
      "                 0.6464,\n",
      "                 0.5614,\n",
      "                 0.661,\n",
      "                 0.5694,\n",
      "                 0.649,\n",
      "                 0.6638,\n",
      "                 0.6707,\n",
      "                 0.5545,\n",
      "                 0.5521,\n",
      "                 0.6438,\n",
      "                 0.6245,\n",
      "                 0.5746,\n",
      "                 0.6043,\n",
      "                 0.5363],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8374837636947632,\n",
      "               0.8360451459884644,\n",
      "               0.8341123461723328,\n",
      "               0.8316156268119812,\n",
      "               0.8294057846069336,\n",
      "               0.8274255990982056,\n",
      "               0.8257361650466919,\n",
      "               0.8241060972213745,\n",
      "               0.822675347328186,\n",
      "               0.821300208568573,\n",
      "               0.8199481964111328,\n",
      "               0.8188410997390747,\n",
      "               0.8177505731582642,\n",
      "               0.8168737292289734,\n",
      "               0.8160001635551453,\n",
      "               0.8150016665458679,\n",
      "               0.8140323758125305,\n",
      "               0.813127338886261,\n",
      "               0.8121532201766968,\n",
      "               0.811125636100769,\n",
      "               0.8101979494094849,\n",
      "               0.8093819618225098,\n",
      "               0.8085861206054688,\n",
      "               0.8078818321228027,\n",
      "               0.8072522878646851,\n",
      "               0.8066000938415527,\n",
      "               0.805994987487793,\n",
      "               0.8054854273796082,\n",
      "               0.8050006031990051,\n",
      "               0.8046002388000488,\n",
      "               0.8042498826980591,\n",
      "               0.8039146661758423,\n",
      "               0.8036262392997742,\n",
      "               0.8033967018127441,\n",
      "               0.8031989336013794,\n",
      "               0.8030552864074707,\n",
      "               0.8029578328132629,\n",
      "               0.8028866052627563,\n",
      "               0.8028535842895508]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.4909,\n",
      "                 0.4628,\n",
      "                 0.4642,\n",
      "                 0.4932,\n",
      "                 0.4718,\n",
      "                 0.4891,\n",
      "                 0.435,\n",
      "                 0.4586,\n",
      "                 0.4002,\n",
      "                 0.4293,\n",
      "                 0.4449,\n",
      "                 0.4538,\n",
      "                 0.3825,\n",
      "                 0.3796,\n",
      "                 0.4194,\n",
      "                 0.3881,\n",
      "                 0.4477,\n",
      "                 0.5098,\n",
      "                 0.4551,\n",
      "                 0.4486,\n",
      "                 0.3919,\n",
      "                 0.3918,\n",
      "                 0.424,\n",
      "                 0.3837,\n",
      "                 0.3752,\n",
      "                 0.3725,\n",
      "                 0.387,\n",
      "                 0.4286,\n",
      "                 0.4676,\n",
      "                 0.4234,\n",
      "                 0.4662,\n",
      "                 0.3998,\n",
      "                 0.3668,\n",
      "                 0.4185,\n",
      "                 0.3517,\n",
      "                 0.4197,\n",
      "                 0.4056,\n",
      "                 0.3917,\n",
      "                 0.3809,\n",
      "                 0.4466],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.839296817779541,\n",
      "               0.8416329622268677,\n",
      "               0.8452697992324829,\n",
      "               0.8501421213150024,\n",
      "               0.8547970056533813,\n",
      "               0.859131932258606,\n",
      "               0.8632022738456726,\n",
      "               0.8669235110282898,\n",
      "               0.8706215620040894,\n",
      "               0.8742960095405579,\n",
      "               0.8778302073478699,\n",
      "               0.8809340596199036,\n",
      "               0.8840646743774414,\n",
      "               0.8870447874069214,\n",
      "               0.8898614645004272,\n",
      "               0.8926698565483093,\n",
      "               0.8953388929367065,\n",
      "               0.8978397250175476,\n",
      "               0.9001437425613403,\n",
      "               0.9023644328117371,\n",
      "               0.9045090675354004,\n",
      "               0.9066510200500488,\n",
      "               0.9085897207260132,\n",
      "               0.9104428291320801,\n",
      "               0.9121297597885132,\n",
      "               0.9136093854904175,\n",
      "               0.9149556159973145,\n",
      "               0.9162298440933228,\n",
      "               0.9173702001571655,\n",
      "               0.9183799624443054,\n",
      "               0.9192696809768677,\n",
      "               0.9200539588928223,\n",
      "               0.9207357168197632,\n",
      "               0.9212683439254761,\n",
      "               0.9216974973678589,\n",
      "               0.9220229387283325,\n",
      "               0.9222935438156128,\n",
      "               0.9224767684936523,\n",
      "               0.922563374042511]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7366,\n",
      "                 0.7141,\n",
      "                 0.6582,\n",
      "                 0.7064,\n",
      "                 0.7445,\n",
      "                 0.7519,\n",
      "                 0.6739,\n",
      "                 0.6441,\n",
      "                 0.6038,\n",
      "                 0.7555,\n",
      "                 0.6809,\n",
      "                 0.7041,\n",
      "                 0.5969,\n",
      "                 0.6428,\n",
      "                 0.6332,\n",
      "                 0.6405,\n",
      "                 0.6688,\n",
      "                 0.6817,\n",
      "                 0.6799,\n",
      "                 0.6994,\n",
      "                 0.6015,\n",
      "                 0.6669,\n",
      "                 0.5451,\n",
      "                 0.6965,\n",
      "                 0.6321,\n",
      "                 0.5905,\n",
      "                 0.6115,\n",
      "                 0.7085,\n",
      "                 0.6586,\n",
      "                 0.5817,\n",
      "                 0.5605,\n",
      "                 0.6462,\n",
      "                 0.5838,\n",
      "                 0.5671,\n",
      "                 0.587,\n",
      "                 0.5291,\n",
      "                 0.6411,\n",
      "                 0.6414,\n",
      "                 0.675,\n",
      "                 0.6156],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8388895988464355,\n",
      "               0.8400810360908508,\n",
      "               0.8420160412788391,\n",
      "               0.8447100520133972,\n",
      "               0.8474580645561218,\n",
      "               0.8504306077957153,\n",
      "               0.8532744646072388,\n",
      "               0.856092095375061,\n",
      "               0.8587623834609985,\n",
      "               0.8612181544303894,\n",
      "               0.8633328676223755,\n",
      "               0.8653209805488586,\n",
      "               0.8671654462814331,\n",
      "               0.8691180944442749,\n",
      "               0.8708910942077637,\n",
      "               0.8725569844245911,\n",
      "               0.8741118311882019,\n",
      "               0.8755477070808411,\n",
      "               0.8769108057022095,\n",
      "               0.878197193145752,\n",
      "               0.8794838190078735,\n",
      "               0.8806155920028687,\n",
      "               0.8816746473312378,\n",
      "               0.8827330470085144,\n",
      "               0.8837445974349976,\n",
      "               0.884589672088623,\n",
      "               0.8854085803031921,\n",
      "               0.8861002922058105,\n",
      "               0.8867451548576355,\n",
      "               0.8873456716537476,\n",
      "               0.8878622055053711,\n",
      "               0.8883363008499146,\n",
      "               0.8887201547622681,\n",
      "               0.8890591859817505,\n",
      "               0.8893564939498901,\n",
      "               0.8895791172981262,\n",
      "               0.8897354006767273,\n",
      "               0.8898326754570007,\n",
      "               0.8898881673812866]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7503,\n",
      "                 0.7235,\n",
      "                 0.7909,\n",
      "                 0.8082,\n",
      "                 0.7885,\n",
      "                 0.7837,\n",
      "                 0.7598,\n",
      "                 0.6582,\n",
      "                 0.8337,\n",
      "                 0.8291,\n",
      "                 0.7,\n",
      "                 0.7424,\n",
      "                 0.869,\n",
      "                 0.7219,\n",
      "                 0.7176,\n",
      "                 0.7325,\n",
      "                 0.7313,\n",
      "                 0.7128,\n",
      "                 0.6908,\n",
      "                 0.773,\n",
      "                 0.7472,\n",
      "                 0.7301,\n",
      "                 0.7141,\n",
      "                 0.6996,\n",
      "                 0.7596,\n",
      "                 0.7119,\n",
      "                 0.7217,\n",
      "                 0.719,\n",
      "                 0.7131,\n",
      "                 0.6504,\n",
      "                 0.6725,\n",
      "                 0.7385,\n",
      "                 0.7646,\n",
      "                 0.6299,\n",
      "                 0.7358,\n",
      "                 0.6816,\n",
      "                 0.6921,\n",
      "                 0.7023,\n",
      "                 0.8075,\n",
      "                 0.7539],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8377082943916321,\n",
      "               0.836483359336853,\n",
      "               0.8345521688461304,\n",
      "               0.8318138122558594,\n",
      "               0.8291277885437012,\n",
      "               0.8267423510551453,\n",
      "               0.8244526982307434,\n",
      "               0.8224269151687622,\n",
      "               0.8204337954521179,\n",
      "               0.8186072111129761,\n",
      "               0.8168544769287109,\n",
      "               0.8152721524238586,\n",
      "               0.813711941242218,\n",
      "               0.8121530413627625,\n",
      "               0.8106857538223267,\n",
      "               0.809227466583252,\n",
      "               0.8077586889266968,\n",
      "               0.8064359426498413,\n",
      "               0.8052646517753601,\n",
      "               0.8041858673095703,\n",
      "               0.8031805157661438,\n",
      "               0.8021830320358276,\n",
      "               0.8012798428535461,\n",
      "               0.8004664182662964,\n",
      "               0.7996892929077148,\n",
      "               0.7989139556884766,\n",
      "               0.7981963157653809,\n",
      "               0.7975529432296753,\n",
      "               0.7969744801521301,\n",
      "               0.7965294718742371,\n",
      "               0.7960912585258484,\n",
      "               0.7957374453544617,\n",
      "               0.7954185605049133,\n",
      "               0.7951720952987671,\n",
      "               0.7949720621109009,\n",
      "               0.794833779335022,\n",
      "               0.7947267889976501,\n",
      "               0.7946500778198242,\n",
      "               0.7946124076843262]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.6989,\n",
      "                 0.7139,\n",
      "                 0.7868,\n",
      "                 0.7715,\n",
      "                 0.8022,\n",
      "                 0.7247,\n",
      "                 0.6289,\n",
      "                 0.7153,\n",
      "                 0.7147,\n",
      "                 0.7105,\n",
      "                 0.6532,\n",
      "                 0.7037,\n",
      "                 0.7083,\n",
      "                 0.6741,\n",
      "                 0.6828,\n",
      "                 0.7322,\n",
      "                 0.7,\n",
      "                 0.7528,\n",
      "                 0.7901,\n",
      "                 0.7384,\n",
      "                 0.7521,\n",
      "                 0.648,\n",
      "                 0.6778,\n",
      "                 0.6707,\n",
      "                 0.716,\n",
      "                 0.6888,\n",
      "                 0.6539,\n",
      "                 0.6284,\n",
      "                 0.7015,\n",
      "                 0.6962,\n",
      "                 0.6457,\n",
      "                 0.6513,\n",
      "                 0.6435,\n",
      "                 0.6806,\n",
      "                 0.6465,\n",
      "                 0.6906,\n",
      "                 0.704,\n",
      "                 0.702,\n",
      "                 0.6533,\n",
      "                 0.679],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8383771777153015,\n",
      "               0.8383373022079468,\n",
      "               0.8382280468940735,\n",
      "               0.8382284045219421,\n",
      "               0.8380154371261597,\n",
      "               0.8374838829040527,\n",
      "               0.8369379043579102,\n",
      "               0.8362904787063599,\n",
      "               0.8357852101325989,\n",
      "               0.8353085517883301,\n",
      "               0.8347444534301758,\n",
      "               0.8343059420585632,\n",
      "               0.8339168429374695,\n",
      "               0.8335250616073608,\n",
      "               0.8331260681152344,\n",
      "               0.8326698541641235,\n",
      "               0.8323119878768921,\n",
      "               0.8319661021232605,\n",
      "               0.8316017389297485,\n",
      "               0.8312745094299316,\n",
      "               0.8309998512268066,\n",
      "               0.8307681083679199,\n",
      "               0.8304935693740845,\n",
      "               0.8303030133247375,\n",
      "               0.8300786018371582,\n",
      "               0.8298488855361938,\n",
      "               0.8295852541923523,\n",
      "               0.8293402791023254,\n",
      "               0.8291994333267212,\n",
      "               0.8291170001029968,\n",
      "               0.8290414810180664,\n",
      "               0.828963577747345,\n",
      "               0.8288894891738892,\n",
      "               0.8288592100143433,\n",
      "               0.8288623690605164,\n",
      "               0.8288472294807434,\n",
      "               0.8288336992263794,\n",
      "               0.8288056254386902,\n",
      "               0.8287936449050903]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.9559,\n",
      "                 1.0126,\n",
      "                 1.0031,\n",
      "                 0.9995,\n",
      "                 0.9941,\n",
      "                 0.9641,\n",
      "                 0.9975,\n",
      "                 0.9145,\n",
      "                 0.9751,\n",
      "                 0.9325,\n",
      "                 0.9131,\n",
      "                 0.964,\n",
      "                 0.9167,\n",
      "                 0.945,\n",
      "                 0.9163,\n",
      "                 0.917,\n",
      "                 0.8506,\n",
      "                 0.92,\n",
      "                 1.027,\n",
      "                 0.9447,\n",
      "                 0.9521,\n",
      "                 0.9383,\n",
      "                 0.9587,\n",
      "                 0.9012,\n",
      "                 0.9212,\n",
      "                 0.9289,\n",
      "                 0.874,\n",
      "                 0.8857,\n",
      "                 0.8969,\n",
      "                 0.9536,\n",
      "                 0.909,\n",
      "                 0.8558,\n",
      "                 0.9531,\n",
      "                 0.8373,\n",
      "                 0.9228,\n",
      "                 0.8922,\n",
      "                 0.888,\n",
      "                 0.782,\n",
      "                 0.8903,\n",
      "                 0.9093],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8369391560554504,\n",
      "               0.8341901898384094,\n",
      "               0.8300803899765015,\n",
      "               0.8245345950126648,\n",
      "               0.8191636800765991,\n",
      "               0.8140174746513367,\n",
      "               0.8091474771499634,\n",
      "               0.8044654130935669,\n",
      "               0.8001815676689148,\n",
      "               0.7961193919181824,\n",
      "               0.7922932505607605,\n",
      "               0.7886159420013428,\n",
      "               0.7850790619850159,\n",
      "               0.7816788554191589,\n",
      "               0.778476357460022,\n",
      "               0.7753719687461853,\n",
      "               0.7723922729492188,\n",
      "               0.7695649862289429,\n",
      "               0.7668948769569397,\n",
      "               0.764371395111084,\n",
      "               0.7619950175285339,\n",
      "               0.7597750425338745,\n",
      "               0.7576698660850525,\n",
      "               0.7557429075241089,\n",
      "               0.7539671659469604,\n",
      "               0.7523359656333923,\n",
      "               0.7508127093315125,\n",
      "               0.7493983507156372,\n",
      "               0.7481277585029602,\n",
      "               0.7469890713691711,\n",
      "               0.745984673500061,\n",
      "               0.7450860142707825,\n",
      "               0.7443073391914368,\n",
      "               0.7436548471450806,\n",
      "               0.7431114315986633,\n",
      "               0.7426751852035522,\n",
      "               0.7423516511917114,\n",
      "               0.7421354055404663,\n",
      "               0.7420274019241333]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7112,\n",
      "                 0.7358,\n",
      "                 0.6886,\n",
      "                 0.7464,\n",
      "                 0.6895,\n",
      "                 0.6535,\n",
      "                 0.7502,\n",
      "                 0.7252,\n",
      "                 0.7036,\n",
      "                 0.6874,\n",
      "                 0.7061,\n",
      "                 0.6778,\n",
      "                 0.6579,\n",
      "                 0.7003,\n",
      "                 0.6909,\n",
      "                 0.6733,\n",
      "                 0.6811,\n",
      "                 0.6537,\n",
      "                 0.6345,\n",
      "                 0.6206,\n",
      "                 0.6923,\n",
      "                 0.5879,\n",
      "                 0.6517,\n",
      "                 0.6861,\n",
      "                 0.5668,\n",
      "                 0.6599,\n",
      "                 0.6296,\n",
      "                 0.66,\n",
      "                 0.6326,\n",
      "                 0.5891,\n",
      "                 0.6303,\n",
      "                 0.6918,\n",
      "                 0.5801,\n",
      "                 0.6309,\n",
      "                 0.5697,\n",
      "                 0.6732,\n",
      "                 0.6218,\n",
      "                 0.6193,\n",
      "                 0.6434,\n",
      "                 0.6058],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8398874402046204,\n",
      "               0.8431111574172974,\n",
      "               0.8479722738265991,\n",
      "               0.8546045422554016,\n",
      "               0.8611181378364563,\n",
      "               0.8675225973129272,\n",
      "               0.8738148808479309,\n",
      "               0.879830002784729,\n",
      "               0.8855500221252441,\n",
      "               0.8910977244377136,\n",
      "               0.896477222442627,\n",
      "               0.9016776084899902,\n",
      "               0.9067466855049133,\n",
      "               0.9116471409797668,\n",
      "               0.9163850545883179,\n",
      "               0.9209205508232117,\n",
      "               0.9252691268920898,\n",
      "               0.9294598698616028,\n",
      "               0.9334667325019836,\n",
      "               0.9372779726982117,\n",
      "               0.9409516453742981,\n",
      "               0.9444077610969543,\n",
      "               0.9476491808891296,\n",
      "               0.9507158398628235,\n",
      "               0.9535786509513855,\n",
      "               0.9562360048294067,\n",
      "               0.9586957097053528,\n",
      "               0.9609380960464478,\n",
      "               0.9629901051521301,\n",
      "               0.964877724647522,\n",
      "               0.9665805697441101,\n",
      "               0.9681010246276855,\n",
      "               0.9694204330444336,\n",
      "               0.970548152923584,\n",
      "               0.9714788198471069,\n",
      "               0.9722288250923157,\n",
      "               0.972794234752655,\n",
      "               0.9731711149215698,\n",
      "               0.973361611366272]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.8225,\n",
      "                 0.7892,\n",
      "                 0.8692,\n",
      "                 0.8185,\n",
      "                 0.8968,\n",
      "                 0.7903,\n",
      "                 0.7766,\n",
      "                 0.7828,\n",
      "                 0.8217,\n",
      "                 0.8335,\n",
      "                 0.8948,\n",
      "                 0.817,\n",
      "                 0.7965,\n",
      "                 0.8041,\n",
      "                 0.8107,\n",
      "                 0.8283,\n",
      "                 0.7332,\n",
      "                 0.853,\n",
      "                 0.8237,\n",
      "                 0.7858,\n",
      "                 0.7719,\n",
      "                 0.7656,\n",
      "                 0.7475,\n",
      "                 0.7596,\n",
      "                 0.7325,\n",
      "                 0.8194,\n",
      "                 0.7392,\n",
      "                 0.7614,\n",
      "                 0.7825,\n",
      "                 0.7822,\n",
      "                 0.7515,\n",
      "                 0.7455,\n",
      "                 0.7639,\n",
      "                 0.7643,\n",
      "                 0.7564,\n",
      "                 0.7934,\n",
      "                 0.7799,\n",
      "                 0.7686,\n",
      "                 0.6852,\n",
      "                 0.7548],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8370851278305054,\n",
      "               0.8347137570381165,\n",
      "               0.831150233745575,\n",
      "               0.8264414072036743,\n",
      "               0.8219760060310364,\n",
      "               0.8176784515380859,\n",
      "               0.8137346506118774,\n",
      "               0.8101509213447571,\n",
      "               0.8067153096199036,\n",
      "               0.8034513592720032,\n",
      "               0.8003736734390259,\n",
      "               0.7974953651428223,\n",
      "               0.7947297096252441,\n",
      "               0.7920457124710083,\n",
      "               0.7896272540092468,\n",
      "               0.787405788898468,\n",
      "               0.7853193283081055,\n",
      "               0.7833375930786133,\n",
      "               0.7815716862678528,\n",
      "               0.7799032926559448,\n",
      "               0.7783514857292175,\n",
      "               0.7768357992172241,\n",
      "               0.7754457592964172,\n",
      "               0.7741662859916687,\n",
      "               0.7729607820510864,\n",
      "               0.7718361020088196,\n",
      "               0.7708511352539062,\n",
      "               0.7699285745620728,\n",
      "               0.7690647840499878,\n",
      "               0.7682877779006958,\n",
      "               0.767554759979248,\n",
      "               0.7669097781181335,\n",
      "               0.7663798332214355,\n",
      "               0.7659268379211426,\n",
      "               0.7655657529830933,\n",
      "               0.7652899026870728,\n",
      "               0.7650790214538574,\n",
      "               0.7649425864219666,\n",
      "               0.7648736238479614]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.6319,\n",
      "                 0.675,\n",
      "                 0.6721,\n",
      "                 0.6816,\n",
      "                 0.7457,\n",
      "                 0.7246,\n",
      "                 0.7087,\n",
      "                 0.7185,\n",
      "                 0.6985,\n",
      "                 0.6544,\n",
      "                 0.6741,\n",
      "                 0.6743,\n",
      "                 0.701,\n",
      "                 0.6855,\n",
      "                 0.6501,\n",
      "                 0.6309,\n",
      "                 0.6739,\n",
      "                 0.6604,\n",
      "                 0.6543,\n",
      "                 0.6558,\n",
      "                 0.6113,\n",
      "                 0.6453,\n",
      "                 0.6598,\n",
      "                 0.598,\n",
      "                 0.6069,\n",
      "                 0.6581,\n",
      "                 0.5873,\n",
      "                 0.6312,\n",
      "                 0.6408,\n",
      "                 0.6779,\n",
      "                 0.6146,\n",
      "                 0.6915,\n",
      "                 0.6826,\n",
      "                 0.6228,\n",
      "                 0.6222,\n",
      "                 0.6533,\n",
      "                 0.657,\n",
      "                 0.6362,\n",
      "                 0.6282,\n",
      "                 0.6293],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8372281789779663,\n",
      "               0.8349199295043945,\n",
      "               0.8314167261123657,\n",
      "               0.8273465037345886,\n",
      "               0.8235068321228027,\n",
      "               0.8198496103286743,\n",
      "               0.8166362047195435,\n",
      "               0.8134740591049194,\n",
      "               0.810456395149231,\n",
      "               0.8076461553573608,\n",
      "               0.804943859577179,\n",
      "               0.8022992014884949,\n",
      "               0.8000375032424927,\n",
      "               0.7978681325912476,\n",
      "               0.7958003878593445,\n",
      "               0.7937971353530884,\n",
      "               0.7919119000434875,\n",
      "               0.7902144193649292,\n",
      "               0.7886244058609009,\n",
      "               0.7871212959289551,\n",
      "               0.7857065200805664,\n",
      "               0.784278929233551,\n",
      "               0.7829343676567078,\n",
      "               0.7816795706748962,\n",
      "               0.7805315256118774,\n",
      "               0.7794320583343506,\n",
      "               0.7785285711288452,\n",
      "               0.7776960134506226,\n",
      "               0.7769333720207214,\n",
      "               0.7762210965156555,\n",
      "               0.7756473422050476,\n",
      "               0.7751973271369934,\n",
      "               0.7748411297798157,\n",
      "               0.774540901184082,\n",
      "               0.7742902040481567,\n",
      "               0.7740920186042786,\n",
      "               0.7739547491073608,\n",
      "               0.773862361907959,\n",
      "               0.7738133668899536]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.5198,\n",
      "                 0.5569,\n",
      "                 0.612,\n",
      "                 0.6233,\n",
      "                 0.6144,\n",
      "                 0.5414,\n",
      "                 0.5343,\n",
      "                 0.5295,\n",
      "                 0.5061,\n",
      "                 0.5358,\n",
      "                 0.5881,\n",
      "                 0.5769,\n",
      "                 0.5264,\n",
      "                 0.5413,\n",
      "                 0.5322,\n",
      "                 0.5402,\n",
      "                 0.5242,\n",
      "                 0.5364,\n",
      "                 0.5381,\n",
      "                 0.516,\n",
      "                 0.5069,\n",
      "                 0.5025,\n",
      "                 0.4506,\n",
      "                 0.5058,\n",
      "                 0.535,\n",
      "                 0.4864,\n",
      "                 0.5574,\n",
      "                 0.4616,\n",
      "                 0.5013,\n",
      "                 0.5136,\n",
      "                 0.5009,\n",
      "                 0.5176,\n",
      "                 0.5099,\n",
      "                 0.5369,\n",
      "                 0.5345,\n",
      "                 0.4991,\n",
      "                 0.496,\n",
      "                 0.4856,\n",
      "                 0.5446,\n",
      "                 0.4622],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8373832702636719,\n",
      "               0.8354666829109192,\n",
      "               0.8327585458755493,\n",
      "               0.8289623260498047,\n",
      "               0.825290322303772,\n",
      "               0.8219884037971497,\n",
      "               0.8186616897583008,\n",
      "               0.815590500831604,\n",
      "               0.8125460743904114,\n",
      "               0.809735894203186,\n",
      "               0.8069168329238892,\n",
      "               0.8043631315231323,\n",
      "               0.8018642663955688,\n",
      "               0.7995551228523254,\n",
      "               0.7975634336471558,\n",
      "               0.7957627177238464,\n",
      "               0.7941047549247742,\n",
      "               0.7926182150840759,\n",
      "               0.7912168502807617,\n",
      "               0.7898961901664734,\n",
      "               0.7886637449264526,\n",
      "               0.7875695824623108,\n",
      "               0.786571204662323,\n",
      "               0.7856787443161011,\n",
      "               0.7847690582275391,\n",
      "               0.7839486002922058,\n",
      "               0.7831633687019348,\n",
      "               0.7824803590774536,\n",
      "               0.7818154096603394,\n",
      "               0.7811353206634521,\n",
      "               0.7805516123771667,\n",
      "               0.7800289392471313,\n",
      "               0.7795632481575012,\n",
      "               0.779172956943512,\n",
      "               0.7788480520248413,\n",
      "               0.7786095142364502,\n",
      "               0.7784308195114136,\n",
      "               0.7783175706863403,\n",
      "               0.7782630324363708]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.9851,\n",
      "                 0.9364,\n",
      "                 0.8831,\n",
      "                 1.0521,\n",
      "                 0.9693,\n",
      "                 1.0275,\n",
      "                 0.9661,\n",
      "                 0.9479,\n",
      "                 0.9395,\n",
      "                 0.9245,\n",
      "                 0.9419,\n",
      "                 0.8926,\n",
      "                 0.8957,\n",
      "                 0.9159,\n",
      "                 0.8453,\n",
      "                 0.9559,\n",
      "                 0.9232,\n",
      "                 0.9342,\n",
      "                 0.8966,\n",
      "                 0.9411,\n",
      "                 0.8293,\n",
      "                 0.854,\n",
      "                 0.8587,\n",
      "                 0.9045,\n",
      "                 0.8797,\n",
      "                 0.8612,\n",
      "                 0.8869,\n",
      "                 0.8527,\n",
      "                 0.8184,\n",
      "                 0.95,\n",
      "                 0.856,\n",
      "                 0.8703,\n",
      "                 0.9146,\n",
      "                 0.823,\n",
      "                 0.8114,\n",
      "                 0.8371,\n",
      "                 0.8072,\n",
      "                 0.8408,\n",
      "                 0.819,\n",
      "                 0.828],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.836652398109436,\n",
      "               0.833500862121582,\n",
      "               0.8288909792900085,\n",
      "               0.8227999806404114,\n",
      "               0.8170811533927917,\n",
      "               0.8115680813789368,\n",
      "               0.8061776161193848,\n",
      "               0.8011524081230164,\n",
      "               0.7963608503341675,\n",
      "               0.7917741537094116,\n",
      "               0.7873996496200562,\n",
      "               0.7833014726638794,\n",
      "               0.7794485688209534,\n",
      "               0.7758331298828125,\n",
      "               0.7723732590675354,\n",
      "               0.769090473651886,\n",
      "               0.7659065127372742,\n",
      "               0.7628833055496216,\n",
      "               0.7600498199462891,\n",
      "               0.7573498487472534,\n",
      "               0.7548254132270813,\n",
      "               0.7524294853210449,\n",
      "               0.7502044439315796,\n",
      "               0.7481304407119751,\n",
      "               0.746198296546936,\n",
      "               0.7444025278091431,\n",
      "               0.7427505850791931,\n",
      "               0.7412313222885132,\n",
      "               0.7398348450660706,\n",
      "               0.7385837435722351,\n",
      "               0.7374641299247742,\n",
      "               0.736476719379425,\n",
      "               0.73562091588974,\n",
      "               0.734898030757904,\n",
      "               0.7342947721481323,\n",
      "               0.7338137030601501,\n",
      "               0.7334579229354858,\n",
      "               0.7332242131233215,\n",
      "               0.7331058979034424]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.7641,\n",
      "                 0.745,\n",
      "                 0.7225,\n",
      "                 0.764,\n",
      "                 0.6896,\n",
      "                 0.781,\n",
      "                 0.7413,\n",
      "                 0.7012,\n",
      "                 0.7202,\n",
      "                 0.6982,\n",
      "                 0.75,\n",
      "                 0.7705,\n",
      "                 0.6951,\n",
      "                 0.7509,\n",
      "                 0.777,\n",
      "                 0.7074,\n",
      "                 0.7363,\n",
      "                 0.6864,\n",
      "                 0.7325,\n",
      "                 0.6758,\n",
      "                 0.7167,\n",
      "                 0.7062,\n",
      "                 0.7891,\n",
      "                 0.6009,\n",
      "                 0.7575,\n",
      "                 0.7133,\n",
      "                 0.7345,\n",
      "                 0.7062,\n",
      "                 0.6705,\n",
      "                 0.7391,\n",
      "                 0.697,\n",
      "                 0.7254,\n",
      "                 0.6631,\n",
      "                 0.6259,\n",
      "                 0.6848,\n",
      "                 0.6686,\n",
      "                 0.7735,\n",
      "                 0.672,\n",
      "                 0.7166,\n",
      "                 0.66],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8377828598022461,\n",
      "               0.8366157412528992,\n",
      "               0.8349214792251587,\n",
      "               0.8329312205314636,\n",
      "               0.8310596346855164,\n",
      "               0.8294044733047485,\n",
      "               0.8281370997428894,\n",
      "               0.8269907832145691,\n",
      "               0.8256151080131531,\n",
      "               0.8240810632705688,\n",
      "               0.8224776983261108,\n",
      "               0.8209554553031921,\n",
      "               0.8193296194076538,\n",
      "               0.817879319190979,\n",
      "               0.8166483044624329,\n",
      "               0.8154220581054688,\n",
      "               0.814247727394104,\n",
      "               0.8131623268127441,\n",
      "               0.812166690826416,\n",
      "               0.8112516403198242,\n",
      "               0.8104971647262573,\n",
      "               0.8098092079162598,\n",
      "               0.809177041053772,\n",
      "               0.8086091876029968,\n",
      "               0.8080245852470398,\n",
      "               0.807442307472229,\n",
      "               0.8068841695785522,\n",
      "               0.8063551783561707,\n",
      "               0.8059210777282715,\n",
      "               0.8055672645568848,\n",
      "               0.8052988052368164,\n",
      "               0.8051498532295227,\n",
      "               0.8050047159194946,\n",
      "               0.8048876523971558,\n",
      "               0.8048027157783508,\n",
      "               0.8047300577163696,\n",
      "               0.8046597242355347,\n",
      "               0.8046095967292786,\n",
      "               0.804580807685852]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0114,\n",
      "                 1.0383,\n",
      "                 1.0361,\n",
      "                 0.9705,\n",
      "                 0.9128,\n",
      "                 1.0151,\n",
      "                 0.9607,\n",
      "                 0.9818,\n",
      "                 1.0031,\n",
      "                 0.9723,\n",
      "                 0.9001,\n",
      "                 0.8926,\n",
      "                 0.9335,\n",
      "                 0.9468,\n",
      "                 0.9937,\n",
      "                 0.9456,\n",
      "                 0.9194,\n",
      "                 0.9191,\n",
      "                 0.884,\n",
      "                 0.9309,\n",
      "                 0.8909,\n",
      "                 0.8791,\n",
      "                 0.9188,\n",
      "                 0.8633,\n",
      "                 0.8985,\n",
      "                 0.8803,\n",
      "                 0.8573,\n",
      "                 0.878,\n",
      "                 0.8251,\n",
      "                 0.8636,\n",
      "                 0.8336,\n",
      "                 0.8496,\n",
      "                 0.8911,\n",
      "                 0.8233,\n",
      "                 0.8665,\n",
      "                 0.8831,\n",
      "                 0.8011,\n",
      "                 0.7954,\n",
      "                 0.8971,\n",
      "                 0.881],\n",
      "  'val_loss': [0.8382819294929504,\n",
      "               0.8371206521987915,\n",
      "               0.8348246812820435,\n",
      "               0.8313820958137512,\n",
      "               0.8266996145248413,\n",
      "               0.8221149444580078,\n",
      "               0.8176776766777039,\n",
      "               0.8133689761161804,\n",
      "               0.809225857257843,\n",
      "               0.8053183555603027,\n",
      "               0.8016331791877747,\n",
      "               0.7980638146400452,\n",
      "               0.7947134375572205,\n",
      "               0.7915362119674683,\n",
      "               0.7884777188301086,\n",
      "               0.7855964303016663,\n",
      "               0.7828317880630493,\n",
      "               0.78023761510849,\n",
      "               0.7777958512306213,\n",
      "               0.7755157947540283,\n",
      "               0.7733948230743408,\n",
      "               0.7714148759841919,\n",
      "               0.7695831060409546,\n",
      "               0.7678594589233398,\n",
      "               0.7662782669067383,\n",
      "               0.7648051977157593,\n",
      "               0.7634526491165161,\n",
      "               0.7622102499008179,\n",
      "               0.761064887046814,\n",
      "               0.7600380778312683,\n",
      "               0.7591037750244141,\n",
      "               0.7582763433456421,\n",
      "               0.7575461268424988,\n",
      "               0.7568968534469604,\n",
      "               0.7563422918319702,\n",
      "               0.7558828592300415,\n",
      "               0.7555363774299622,\n",
      "               0.7552781105041504,\n",
      "               0.7551039457321167,\n",
      "               0.7550191879272461]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6732,\n",
      "                 0.7629,\n",
      "                 0.7371,\n",
      "                 0.7558,\n",
      "                 0.8559,\n",
      "                 0.5785,\n",
      "                 0.7158,\n",
      "                 0.8539,\n",
      "                 0.7033,\n",
      "                 0.7558,\n",
      "                 0.7198,\n",
      "                 0.7069,\n",
      "                 0.6027,\n",
      "                 0.8311,\n",
      "                 0.7419,\n",
      "                 0.6725,\n",
      "                 0.7107,\n",
      "                 0.6458,\n",
      "                 0.722,\n",
      "                 0.6553,\n",
      "                 0.7548,\n",
      "                 0.5418,\n",
      "                 0.7269,\n",
      "                 0.6414,\n",
      "                 0.6415,\n",
      "                 0.6877,\n",
      "                 0.6416,\n",
      "                 0.7378,\n",
      "                 0.6561,\n",
      "                 0.5971,\n",
      "                 0.6674,\n",
      "                 0.7294,\n",
      "                 0.6563,\n",
      "                 0.6595,\n",
      "                 0.7672,\n",
      "                 0.5333,\n",
      "                 0.6642,\n",
      "                 0.6414,\n",
      "                 0.7529,\n",
      "                 0.5153,\n",
      "                 0.5439,\n",
      "                 0.7911,\n",
      "                 0.6573,\n",
      "                 0.7006,\n",
      "                 0.5575,\n",
      "                 0.7214,\n",
      "                 0.5677,\n",
      "                 0.6989,\n",
      "                 0.6417,\n",
      "                 0.6893,\n",
      "                 0.5063,\n",
      "                 0.846,\n",
      "                 0.6066,\n",
      "                 0.7143,\n",
      "                 0.7019,\n",
      "                 0.5465,\n",
      "                 0.5034,\n",
      "                 0.818,\n",
      "                 0.8143,\n",
      "                 0.5818,\n",
      "                 0.5714,\n",
      "                 0.7237,\n",
      "                 0.6211,\n",
      "                 0.6088,\n",
      "                 0.6557,\n",
      "                 0.6351,\n",
      "                 0.7946,\n",
      "                 0.5379,\n",
      "                 0.6051,\n",
      "                 0.6863,\n",
      "                 0.6174,\n",
      "                 0.6053,\n",
      "                 0.5674,\n",
      "                 0.6905,\n",
      "                 0.6503,\n",
      "                 0.6115,\n",
      "                 0.6419,\n",
      "                 0.6352,\n",
      "                 0.6374,\n",
      "                 0.6129],\n",
      "  'val_loss': [0.8377065658569336,\n",
      "               0.8349188566207886,\n",
      "               0.8313117027282715,\n",
      "               0.8272234201431274,\n",
      "               0.8212597966194153,\n",
      "               0.8153085708618164,\n",
      "               0.8093353509902954,\n",
      "               0.8032792806625366,\n",
      "               0.7978264689445496,\n",
      "               0.7932421565055847,\n",
      "               0.7885902523994446,\n",
      "               0.7846353054046631,\n",
      "               0.780693531036377,\n",
      "               0.7780404090881348,\n",
      "               0.7750921249389648,\n",
      "               0.7722203135490417,\n",
      "               0.769283652305603,\n",
      "               0.7667841911315918,\n",
      "               0.7645701766014099,\n",
      "               0.7627322673797607,\n",
      "               0.7610877752304077,\n",
      "               0.7593311071395874,\n",
      "               0.7574936151504517,\n",
      "               0.756194531917572,\n",
      "               0.7548931837081909,\n",
      "               0.7541365623474121,\n",
      "               0.7534117102622986,\n",
      "               0.7525219321250916,\n",
      "               0.7519317865371704,\n",
      "               0.7513096928596497,\n",
      "               0.7507089376449585,\n",
      "               0.7502120733261108,\n",
      "               0.7497795820236206,\n",
      "               0.7493348121643066,\n",
      "               0.7490607500076294,\n",
      "               0.7487627267837524,\n",
      "               0.748688817024231,\n",
      "               0.7485685348510742,\n",
      "               0.748502790927887,\n",
      "               0.7484692335128784]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8039,\n",
      "                 0.8247,\n",
      "                 0.8698,\n",
      "                 0.9016,\n",
      "                 0.8155,\n",
      "                 0.9511,\n",
      "                 1.0728,\n",
      "                 0.6111,\n",
      "                 0.7847,\n",
      "                 0.8096,\n",
      "                 0.939,\n",
      "                 0.8212,\n",
      "                 0.6055,\n",
      "                 0.954,\n",
      "                 0.9209,\n",
      "                 0.7016,\n",
      "                 0.7823,\n",
      "                 0.771,\n",
      "                 0.9391,\n",
      "                 0.6721,\n",
      "                 0.5977,\n",
      "                 0.8969,\n",
      "                 0.9708,\n",
      "                 0.7051,\n",
      "                 0.8828,\n",
      "                 0.684,\n",
      "                 0.6692,\n",
      "                 0.824,\n",
      "                 0.7275,\n",
      "                 0.7139,\n",
      "                 1.0308,\n",
      "                 0.5766,\n",
      "                 0.717,\n",
      "                 0.8018,\n",
      "                 0.7831,\n",
      "                 0.8068,\n",
      "                 0.5968,\n",
      "                 0.8526,\n",
      "                 0.9681,\n",
      "                 0.626,\n",
      "                 0.6809,\n",
      "                 0.8544,\n",
      "                 0.7307,\n",
      "                 0.7014,\n",
      "                 0.7316,\n",
      "                 0.8158,\n",
      "                 0.7476,\n",
      "                 0.6508,\n",
      "                 0.7801,\n",
      "                 0.7325,\n",
      "                 0.7437,\n",
      "                 0.7467,\n",
      "                 0.7251,\n",
      "                 0.7249,\n",
      "                 0.6464,\n",
      "                 0.7807,\n",
      "                 0.6571,\n",
      "                 0.7942,\n",
      "                 0.6835,\n",
      "                 0.7885,\n",
      "                 0.8926,\n",
      "                 0.6003,\n",
      "                 0.8733,\n",
      "                 0.6314,\n",
      "                 0.6853,\n",
      "                 0.7856,\n",
      "                 0.6556,\n",
      "                 0.8854,\n",
      "                 0.715,\n",
      "                 0.6899,\n",
      "                 0.8296,\n",
      "                 0.6811,\n",
      "                 0.7825,\n",
      "                 0.6369,\n",
      "                 0.5799,\n",
      "                 0.8555,\n",
      "                 0.7737,\n",
      "                 0.6398,\n",
      "                 0.7726,\n",
      "                 0.6837],\n",
      "  'val_loss': [0.8376167416572571,\n",
      "               0.8351284861564636,\n",
      "               0.8298718333244324,\n",
      "               0.822150707244873,\n",
      "               0.8133455514907837,\n",
      "               0.8044763803482056,\n",
      "               0.7981487512588501,\n",
      "               0.7914052605628967,\n",
      "               0.7847260236740112,\n",
      "               0.7788881659507751,\n",
      "               0.7740828394889832,\n",
      "               0.7691786885261536,\n",
      "               0.7649121284484863,\n",
      "               0.7606292963027954,\n",
      "               0.7560698986053467,\n",
      "               0.7518892288208008,\n",
      "               0.7482506632804871,\n",
      "               0.7446132898330688,\n",
      "               0.7411932945251465,\n",
      "               0.7377574443817139,\n",
      "               0.7350135445594788,\n",
      "               0.7321740388870239,\n",
      "               0.7298983335494995,\n",
      "               0.7279191017150879,\n",
      "               0.7258328199386597,\n",
      "               0.724054217338562,\n",
      "               0.7221818566322327,\n",
      "               0.7204003930091858,\n",
      "               0.7190686464309692,\n",
      "               0.7176684737205505,\n",
      "               0.7164071798324585,\n",
      "               0.7152027487754822,\n",
      "               0.7140592336654663,\n",
      "               0.7130370736122131,\n",
      "               0.7121642827987671,\n",
      "               0.7114144563674927,\n",
      "               0.7108572721481323,\n",
      "               0.7104766964912415,\n",
      "               0.7102234363555908,\n",
      "               0.7101305723190308]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.7207,\n",
      "                 0.9018,\n",
      "                 0.7464,\n",
      "                 0.8382,\n",
      "                 0.9239,\n",
      "                 0.6658,\n",
      "                 0.829,\n",
      "                 0.8456,\n",
      "                 0.5815,\n",
      "                 1.0235,\n",
      "                 1.0413,\n",
      "                 0.6142,\n",
      "                 0.6368,\n",
      "                 0.9018,\n",
      "                 0.7096,\n",
      "                 0.8046,\n",
      "                 0.7212,\n",
      "                 0.7237,\n",
      "                 0.9276,\n",
      "                 0.5214,\n",
      "                 0.7841,\n",
      "                 0.7929,\n",
      "                 0.8785,\n",
      "                 0.5674,\n",
      "                 0.7545,\n",
      "                 0.8116,\n",
      "                 0.6097,\n",
      "                 0.9239,\n",
      "                 0.7145,\n",
      "                 0.7243,\n",
      "                 0.8859,\n",
      "                 0.6408,\n",
      "                 0.8071,\n",
      "                 0.6196,\n",
      "                 0.8512,\n",
      "                 0.6116,\n",
      "                 0.7252,\n",
      "                 0.7095,\n",
      "                 0.6501,\n",
      "                 0.8118,\n",
      "                 0.6055,\n",
      "                 0.756,\n",
      "                 0.5451,\n",
      "                 0.8686,\n",
      "                 0.6491,\n",
      "                 0.779,\n",
      "                 0.5975,\n",
      "                 0.8832,\n",
      "                 0.5239,\n",
      "                 0.9252,\n",
      "                 0.5686,\n",
      "                 0.9087,\n",
      "                 0.7835,\n",
      "                 0.5695,\n",
      "                 0.8496,\n",
      "                 0.5413,\n",
      "                 0.6899,\n",
      "                 0.7434,\n",
      "                 0.6561,\n",
      "                 0.7621,\n",
      "                 0.7136,\n",
      "                 0.6708,\n",
      "                 0.6658,\n",
      "                 0.7195,\n",
      "                 0.8126,\n",
      "                 0.5738,\n",
      "                 0.7035,\n",
      "                 0.7232,\n",
      "                 0.7303,\n",
      "                 0.6203,\n",
      "                 0.6574,\n",
      "                 0.8085,\n",
      "                 0.7073,\n",
      "                 0.7072,\n",
      "                 0.9121,\n",
      "                 0.5585,\n",
      "                 0.6356,\n",
      "                 0.6805,\n",
      "                 0.8696,\n",
      "                 0.4937],\n",
      "  'val_loss': [0.8380734324455261,\n",
      "               0.8361444473266602,\n",
      "               0.8323341608047485,\n",
      "               0.8259769678115845,\n",
      "               0.8200721740722656,\n",
      "               0.8138519525527954,\n",
      "               0.8073283433914185,\n",
      "               0.801672637462616,\n",
      "               0.7967172265052795,\n",
      "               0.7917212247848511,\n",
      "               0.7873477339744568,\n",
      "               0.7831351161003113,\n",
      "               0.7788470983505249,\n",
      "               0.7744001150131226,\n",
      "               0.770110011100769,\n",
      "               0.7667056322097778,\n",
      "               0.76307612657547,\n",
      "               0.7595988512039185,\n",
      "               0.7571264505386353,\n",
      "               0.7542673349380493,\n",
      "               0.751581072807312,\n",
      "               0.7493687868118286,\n",
      "               0.7470136880874634,\n",
      "               0.744779646396637,\n",
      "               0.743010938167572,\n",
      "               0.7413759231567383,\n",
      "               0.7396824359893799,\n",
      "               0.7381752133369446,\n",
      "               0.7366819381713867,\n",
      "               0.735466480255127,\n",
      "               0.7344435453414917,\n",
      "               0.733605682849884,\n",
      "               0.7330498099327087,\n",
      "               0.7326399087905884,\n",
      "               0.7321464419364929,\n",
      "               0.7316886186599731,\n",
      "               0.7312940359115601,\n",
      "               0.7309949994087219,\n",
      "               0.7307947874069214,\n",
      "               0.7307114005088806]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6219,\n",
      "                 0.6271,\n",
      "                 0.7049,\n",
      "                 0.5243,\n",
      "                 0.7313,\n",
      "                 0.6124,\n",
      "                 0.5749,\n",
      "                 0.7026,\n",
      "                 0.6963,\n",
      "                 0.4813,\n",
      "                 0.5937,\n",
      "                 0.5954,\n",
      "                 0.7479,\n",
      "                 0.4241,\n",
      "                 0.6007,\n",
      "                 0.6374,\n",
      "                 0.46,\n",
      "                 0.7271,\n",
      "                 0.5069,\n",
      "                 0.7029,\n",
      "                 0.759,\n",
      "                 0.4869,\n",
      "                 0.5143,\n",
      "                 0.728,\n",
      "                 0.6644,\n",
      "                 0.5241,\n",
      "                 0.7593,\n",
      "                 0.4889,\n",
      "                 0.6268,\n",
      "                 0.5542,\n",
      "                 0.557,\n",
      "                 0.5955,\n",
      "                 0.6914,\n",
      "                 0.514,\n",
      "                 0.4813,\n",
      "                 0.638,\n",
      "                 0.7037,\n",
      "                 0.4128,\n",
      "                 0.4141,\n",
      "                 0.7407,\n",
      "                 0.7326,\n",
      "                 0.4044,\n",
      "                 0.6067,\n",
      "                 0.5669,\n",
      "                 0.7299,\n",
      "                 0.4185,\n",
      "                 0.5845,\n",
      "                 0.5626,\n",
      "                 0.5147,\n",
      "                 0.5852,\n",
      "                 0.5858,\n",
      "                 0.6384,\n",
      "                 0.6288,\n",
      "                 0.5176,\n",
      "                 0.5897,\n",
      "                 0.5144,\n",
      "                 0.6729,\n",
      "                 0.4689,\n",
      "                 0.6163,\n",
      "                 0.4738,\n",
      "                 0.3944,\n",
      "                 0.7058,\n",
      "                 0.5471,\n",
      "                 0.5316,\n",
      "                 0.6569,\n",
      "                 0.5188,\n",
      "                 0.7551,\n",
      "                 0.3628,\n",
      "                 0.599,\n",
      "                 0.4773,\n",
      "                 0.6397,\n",
      "                 0.4892,\n",
      "                 0.4026,\n",
      "                 0.7698,\n",
      "                 0.7193,\n",
      "                 0.4418,\n",
      "                 0.5029,\n",
      "                 0.5753,\n",
      "                 0.4392,\n",
      "                 0.6493],\n",
      "  'val_loss': [0.8386602401733398,\n",
      "               0.8398197293281555,\n",
      "               0.8428863286972046,\n",
      "               0.8475230932235718,\n",
      "               0.8528536558151245,\n",
      "               0.8575295209884644,\n",
      "               0.8608339428901672,\n",
      "               0.8649992942810059,\n",
      "               0.8691322207450867,\n",
      "               0.8722232580184937,\n",
      "               0.8746539354324341,\n",
      "               0.8778322339057922,\n",
      "               0.8801141977310181,\n",
      "               0.8820726275444031,\n",
      "               0.8840516805648804,\n",
      "               0.8861812353134155,\n",
      "               0.887874960899353,\n",
      "               0.8898817300796509,\n",
      "               0.8911011815071106,\n",
      "               0.8930402994155884,\n",
      "               0.89403235912323,\n",
      "               0.8956331014633179,\n",
      "               0.8968467712402344,\n",
      "               0.8982425928115845,\n",
      "               0.8994209170341492,\n",
      "               0.900310218334198,\n",
      "               0.9008329510688782,\n",
      "               0.9015575647354126,\n",
      "               0.9021177291870117,\n",
      "               0.9025983810424805,\n",
      "               0.9033199548721313,\n",
      "               0.903876006603241,\n",
      "               0.9041852951049805,\n",
      "               0.9044170379638672,\n",
      "               0.9046328663825989,\n",
      "               0.9048343896865845,\n",
      "               0.9051162004470825,\n",
      "               0.9052049517631531,\n",
      "               0.9052952527999878,\n",
      "               0.9053528904914856]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.7702,\n",
      "                 0.6778,\n",
      "                 0.7735,\n",
      "                 0.5987,\n",
      "                 0.8543,\n",
      "                 0.5984,\n",
      "                 0.7369,\n",
      "                 0.6801,\n",
      "                 0.7332,\n",
      "                 0.7116,\n",
      "                 0.5908,\n",
      "                 0.6772,\n",
      "                 0.6313,\n",
      "                 0.7473,\n",
      "                 0.695,\n",
      "                 0.6337,\n",
      "                 0.82,\n",
      "                 0.6056,\n",
      "                 0.7685,\n",
      "                 0.7188,\n",
      "                 0.6209,\n",
      "                 0.7238,\n",
      "                 0.7257,\n",
      "                 0.6571,\n",
      "                 0.8196,\n",
      "                 0.57,\n",
      "                 0.5993,\n",
      "                 0.7666,\n",
      "                 0.654,\n",
      "                 0.7753,\n",
      "                 0.6446,\n",
      "                 0.6035,\n",
      "                 0.6789,\n",
      "                 0.6833,\n",
      "                 0.6701,\n",
      "                 0.6433,\n",
      "                 0.6735,\n",
      "                 0.6898,\n",
      "                 0.6187,\n",
      "                 0.6266,\n",
      "                 0.6554,\n",
      "                 0.7061,\n",
      "                 0.6867,\n",
      "                 0.6539,\n",
      "                 0.6657,\n",
      "                 0.7123,\n",
      "                 0.6304,\n",
      "                 0.6681,\n",
      "                 0.7748,\n",
      "                 0.5973,\n",
      "                 0.6133,\n",
      "                 0.6348,\n",
      "                 0.7339,\n",
      "                 0.538,\n",
      "                 0.7113,\n",
      "                 0.5874,\n",
      "                 0.6319,\n",
      "                 0.6694,\n",
      "                 0.5719,\n",
      "                 0.6909,\n",
      "                 0.7039,\n",
      "                 0.5472,\n",
      "                 0.666,\n",
      "                 0.6172,\n",
      "                 0.6055,\n",
      "                 0.6572,\n",
      "                 0.6661,\n",
      "                 0.6204,\n",
      "                 0.6771,\n",
      "                 0.6015,\n",
      "                 0.6435,\n",
      "                 0.5542,\n",
      "                 0.6524,\n",
      "                 0.6268,\n",
      "                 0.6583,\n",
      "                 0.6543,\n",
      "                 0.6854,\n",
      "                 0.5692,\n",
      "                 0.6418,\n",
      "                 0.6597],\n",
      "  'val_loss': [0.8378259539604187,\n",
      "               0.8356648683547974,\n",
      "               0.8322525024414062,\n",
      "               0.8273624181747437,\n",
      "               0.8215532302856445,\n",
      "               0.8174985647201538,\n",
      "               0.8146079778671265,\n",
      "               0.811098575592041,\n",
      "               0.8079516291618347,\n",
      "               0.8050573468208313,\n",
      "               0.8026501536369324,\n",
      "               0.7998256087303162,\n",
      "               0.7972546815872192,\n",
      "               0.7954012155532837,\n",
      "               0.7932270169258118,\n",
      "               0.7911586761474609,\n",
      "               0.789208710193634,\n",
      "               0.787632167339325,\n",
      "               0.7862066626548767,\n",
      "               0.7847785949707031,\n",
      "               0.7836127281188965,\n",
      "               0.7821625471115112,\n",
      "               0.7811476588249207,\n",
      "               0.7803995609283447,\n",
      "               0.7796705961227417,\n",
      "               0.7788587808609009,\n",
      "               0.7783310413360596,\n",
      "               0.777682363986969,\n",
      "               0.7770563364028931,\n",
      "               0.7764261364936829,\n",
      "               0.775816798210144,\n",
      "               0.7753034830093384,\n",
      "               0.7747982740402222,\n",
      "               0.774457573890686,\n",
      "               0.7742989659309387,\n",
      "               0.7741893529891968,\n",
      "               0.7741329073905945,\n",
      "               0.7740439176559448,\n",
      "               0.7739845514297485,\n",
      "               0.7739526033401489]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.5095,\n",
      "                 0.8831,\n",
      "                 0.5888,\n",
      "                 0.8294,\n",
      "                 0.6212,\n",
      "                 0.8757,\n",
      "                 0.7952,\n",
      "                 0.6665,\n",
      "                 0.5388,\n",
      "                 0.8834,\n",
      "                 0.7254,\n",
      "                 0.7198,\n",
      "                 0.9434,\n",
      "                 0.5267,\n",
      "                 0.8054,\n",
      "                 0.5799,\n",
      "                 0.5431,\n",
      "                 0.9024,\n",
      "                 0.707,\n",
      "                 0.6556,\n",
      "                 0.8076,\n",
      "                 0.5603,\n",
      "                 0.7543,\n",
      "                 0.6478,\n",
      "                 0.5505,\n",
      "                 0.8241,\n",
      "                 0.5964,\n",
      "                 0.7664,\n",
      "                 0.6044,\n",
      "                 0.762,\n",
      "                 0.6124,\n",
      "                 0.7213,\n",
      "                 0.6345,\n",
      "                 0.7817,\n",
      "                 0.6927,\n",
      "                 0.7179,\n",
      "                 0.4915,\n",
      "                 0.8424,\n",
      "                 0.7319,\n",
      "                 0.6745,\n",
      "                 0.7418,\n",
      "                 0.6268,\n",
      "                 0.5397,\n",
      "                 0.7577,\n",
      "                 0.7049,\n",
      "                 0.6411,\n",
      "                 0.7287,\n",
      "                 0.5861,\n",
      "                 0.5451,\n",
      "                 0.6471,\n",
      "                 0.6399,\n",
      "                 0.7042,\n",
      "                 0.5585,\n",
      "                 0.7928,\n",
      "                 0.7379,\n",
      "                 0.5726,\n",
      "                 0.6439,\n",
      "                 0.6341,\n",
      "                 0.6639,\n",
      "                 0.5994,\n",
      "                 0.7509,\n",
      "                 0.5407,\n",
      "                 0.7158,\n",
      "                 0.5618,\n",
      "                 0.4838,\n",
      "                 0.7532,\n",
      "                 0.6218,\n",
      "                 0.7996,\n",
      "                 0.6139,\n",
      "                 0.6879,\n",
      "                 0.6638,\n",
      "                 0.6713,\n",
      "                 0.7341,\n",
      "                 0.5269,\n",
      "                 0.5999,\n",
      "                 0.7029,\n",
      "                 0.6381,\n",
      "                 0.647,\n",
      "                 0.6811,\n",
      "                 0.6607],\n",
      "  'val_loss': [0.8381010890007019,\n",
      "               0.837640106678009,\n",
      "               0.8360850214958191,\n",
      "               0.8349374532699585,\n",
      "               0.8334161639213562,\n",
      "               0.8316553235054016,\n",
      "               0.8291061520576477,\n",
      "               0.8274019360542297,\n",
      "               0.8264662027359009,\n",
      "               0.8250604867935181,\n",
      "               0.8232382535934448,\n",
      "               0.8225030899047852,\n",
      "               0.8213343620300293,\n",
      "               0.8196134567260742,\n",
      "               0.8175687789916992,\n",
      "               0.8162645101547241,\n",
      "               0.8150815963745117,\n",
      "               0.8140767812728882,\n",
      "               0.8128231763839722,\n",
      "               0.8112761378288269,\n",
      "               0.8096896409988403,\n",
      "               0.8086608648300171,\n",
      "               0.8073087930679321,\n",
      "               0.8061041831970215,\n",
      "               0.8050020337104797,\n",
      "               0.8040663599967957,\n",
      "               0.803320586681366,\n",
      "               0.8026418685913086,\n",
      "               0.8017908334732056,\n",
      "               0.8011207580566406,\n",
      "               0.8005614280700684,\n",
      "               0.8002122044563293,\n",
      "               0.7998837828636169,\n",
      "               0.7994600534439087,\n",
      "               0.7990248203277588,\n",
      "               0.7987309694290161,\n",
      "               0.7984815835952759,\n",
      "               0.7982884645462036,\n",
      "               0.7981281280517578,\n",
      "               0.7980802059173584]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.629,\n",
      "                 0.8065,\n",
      "                 0.7191,\n",
      "                 0.7681,\n",
      "                 0.8313,\n",
      "                 0.7782,\n",
      "                 0.7629,\n",
      "                 0.7018,\n",
      "                 0.7839,\n",
      "                 0.6394,\n",
      "                 0.7373,\n",
      "                 0.769,\n",
      "                 0.5331,\n",
      "                 0.9513,\n",
      "                 0.7208,\n",
      "                 0.6475,\n",
      "                 0.7765,\n",
      "                 0.717,\n",
      "                 0.7153,\n",
      "                 0.8012,\n",
      "                 0.8413,\n",
      "                 0.6841,\n",
      "                 0.8,\n",
      "                 0.6666,\n",
      "                 0.7073,\n",
      "                 0.6995,\n",
      "                 0.6341,\n",
      "                 0.7756,\n",
      "                 0.5778,\n",
      "                 0.822,\n",
      "                 0.7202,\n",
      "                 0.6782,\n",
      "                 0.8184,\n",
      "                 0.6155,\n",
      "                 0.7244,\n",
      "                 0.569,\n",
      "                 0.7596,\n",
      "                 0.6359,\n",
      "                 0.6244,\n",
      "                 0.6975,\n",
      "                 0.6088,\n",
      "                 0.8625,\n",
      "                 0.6862,\n",
      "                 0.6846,\n",
      "                 0.6124,\n",
      "                 0.6664,\n",
      "                 0.5892,\n",
      "                 0.7877,\n",
      "                 0.6048,\n",
      "                 0.7802,\n",
      "                 0.6684,\n",
      "                 0.7599,\n",
      "                 0.6517,\n",
      "                 0.7792,\n",
      "                 0.7596,\n",
      "                 0.5827,\n",
      "                 0.615,\n",
      "                 0.8123,\n",
      "                 0.7874,\n",
      "                 0.6247,\n",
      "                 0.6248,\n",
      "                 0.6939,\n",
      "                 0.6566,\n",
      "                 0.6817,\n",
      "                 0.759,\n",
      "                 0.6073,\n",
      "                 0.672,\n",
      "                 0.6853,\n",
      "                 0.5111,\n",
      "                 0.8261,\n",
      "                 0.6818,\n",
      "                 0.6329,\n",
      "                 0.683,\n",
      "                 0.7129,\n",
      "                 0.7206,\n",
      "                 0.6214,\n",
      "                 0.6141,\n",
      "                 0.813,\n",
      "                 0.7313,\n",
      "                 0.5406],\n",
      "  'val_loss': [0.8383082151412964,\n",
      "               0.8386742472648621,\n",
      "               0.8382671475410461,\n",
      "               0.8373783230781555,\n",
      "               0.8364747166633606,\n",
      "               0.8363555669784546,\n",
      "               0.8368247151374817,\n",
      "               0.8362986445426941,\n",
      "               0.8353172540664673,\n",
      "               0.8344127535820007,\n",
      "               0.83399897813797,\n",
      "               0.8330996632575989,\n",
      "               0.8331354856491089,\n",
      "               0.8331354856491089,\n",
      "               0.8326647877693176,\n",
      "               0.832005500793457,\n",
      "               0.8314777612686157,\n",
      "               0.831251323223114,\n",
      "               0.8314892649650574,\n",
      "               0.831279456615448,\n",
      "               0.831743597984314,\n",
      "               0.8314935564994812,\n",
      "               0.8314419984817505,\n",
      "               0.8317238688468933,\n",
      "               0.8320762515068054,\n",
      "               0.8323181867599487,\n",
      "               0.8321548700332642,\n",
      "               0.8318988084793091,\n",
      "               0.8320202827453613,\n",
      "               0.8319042325019836,\n",
      "               0.8318692445755005,\n",
      "               0.8316481709480286,\n",
      "               0.8316276669502258,\n",
      "               0.8316265344619751,\n",
      "               0.831765353679657,\n",
      "               0.8317575454711914,\n",
      "               0.8317764401435852,\n",
      "               0.8317923545837402,\n",
      "               0.8318458795547485,\n",
      "               0.8318530321121216]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.9983,\n",
      "                 0.8802,\n",
      "                 1.0369,\n",
      "                 0.9451,\n",
      "                 0.8492,\n",
      "                 0.9892,\n",
      "                 1.1548,\n",
      "                 0.6028,\n",
      "                 0.7611,\n",
      "                 0.9623,\n",
      "                 0.896,\n",
      "                 0.8172,\n",
      "                 0.8689,\n",
      "                 0.8345,\n",
      "                 0.8368,\n",
      "                 0.91,\n",
      "                 0.7624,\n",
      "                 0.8104,\n",
      "                 0.8037,\n",
      "                 0.8625,\n",
      "                 0.8156,\n",
      "                 0.6847,\n",
      "                 0.8255,\n",
      "                 0.7977,\n",
      "                 0.8593,\n",
      "                 0.7408,\n",
      "                 0.9828,\n",
      "                 0.7226,\n",
      "                 0.6773,\n",
      "                 0.8603,\n",
      "                 0.8686,\n",
      "                 0.7818,\n",
      "                 0.7483,\n",
      "                 0.7366,\n",
      "                 0.753,\n",
      "                 0.6671,\n",
      "                 0.8505,\n",
      "                 0.7283,\n",
      "                 0.6709,\n",
      "                 0.7731,\n",
      "                 0.7852,\n",
      "                 0.7531,\n",
      "                 0.6787,\n",
      "                 0.7813,\n",
      "                 0.8381,\n",
      "                 0.673,\n",
      "                 0.7813,\n",
      "                 0.7044,\n",
      "                 0.6122,\n",
      "                 0.733,\n",
      "                 0.7129,\n",
      "                 0.7481,\n",
      "                 0.7633,\n",
      "                 0.708,\n",
      "                 0.8196,\n",
      "                 0.5435,\n",
      "                 0.7059,\n",
      "                 0.7055,\n",
      "                 0.6708,\n",
      "                 0.6706,\n",
      "                 0.6572,\n",
      "                 0.7328,\n",
      "                 0.7844,\n",
      "                 0.6487,\n",
      "                 0.7126,\n",
      "                 0.726,\n",
      "                 0.7578,\n",
      "                 0.667,\n",
      "                 0.7605,\n",
      "                 0.6761,\n",
      "                 0.7199,\n",
      "                 0.68,\n",
      "                 0.6475,\n",
      "                 0.6776,\n",
      "                 0.7225,\n",
      "                 0.699,\n",
      "                 0.6391,\n",
      "                 0.7614,\n",
      "                 0.7055,\n",
      "                 0.7329],\n",
      "  'val_loss': [0.8375385999679565,\n",
      "               0.8338304758071899,\n",
      "               0.8273832201957703,\n",
      "               0.8190444111824036,\n",
      "               0.809657096862793,\n",
      "               0.8001880645751953,\n",
      "               0.7909027338027954,\n",
      "               0.7817813158035278,\n",
      "               0.7727529406547546,\n",
      "               0.7640168070793152,\n",
      "               0.7557674050331116,\n",
      "               0.7480127811431885,\n",
      "               0.7408872842788696,\n",
      "               0.734468400478363,\n",
      "               0.7286535501480103,\n",
      "               0.7232512831687927,\n",
      "               0.7188175916671753,\n",
      "               0.714413046836853,\n",
      "               0.7102475762367249,\n",
      "               0.7061610221862793,\n",
      "               0.7027930021286011,\n",
      "               0.699440598487854,\n",
      "               0.6962175369262695,\n",
      "               0.6932061314582825,\n",
      "               0.6904667615890503,\n",
      "               0.6879384517669678,\n",
      "               0.6855668425559998,\n",
      "               0.6834234595298767,\n",
      "               0.6815900802612305,\n",
      "               0.6800015568733215,\n",
      "               0.6786108613014221,\n",
      "               0.677514910697937,\n",
      "               0.6766582727432251,\n",
      "               0.6760417222976685,\n",
      "               0.6754353642463684,\n",
      "               0.6748959422111511,\n",
      "               0.6744914054870605,\n",
      "               0.6742480397224426,\n",
      "               0.6740595102310181,\n",
      "               0.6739720702171326]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8131,\n",
      "                 0.6999,\n",
      "                 0.6775,\n",
      "                 0.7193,\n",
      "                 0.5443,\n",
      "                 0.9117,\n",
      "                 0.6899,\n",
      "                 0.7444,\n",
      "                 0.6891,\n",
      "                 0.8501,\n",
      "                 0.7701,\n",
      "                 0.7542,\n",
      "                 0.7899,\n",
      "                 0.5544,\n",
      "                 0.6548,\n",
      "                 0.8193,\n",
      "                 0.8245,\n",
      "                 0.6561,\n",
      "                 0.7457,\n",
      "                 0.7402,\n",
      "                 0.6827,\n",
      "                 0.6675,\n",
      "                 0.5286,\n",
      "                 0.8851,\n",
      "                 0.6543,\n",
      "                 0.7591,\n",
      "                 0.7932,\n",
      "                 0.6677,\n",
      "                 0.6708,\n",
      "                 0.7329,\n",
      "                 0.6755,\n",
      "                 0.744,\n",
      "                 0.5765,\n",
      "                 0.8533,\n",
      "                 0.5996,\n",
      "                 0.7262,\n",
      "                 0.6847,\n",
      "                 0.6766,\n",
      "                 0.7188,\n",
      "                 0.6652,\n",
      "                 0.7145,\n",
      "                 0.6476,\n",
      "                 0.7346,\n",
      "                 0.6372,\n",
      "                 0.6704,\n",
      "                 0.7324,\n",
      "                 0.7251,\n",
      "                 0.6352,\n",
      "                 0.8084,\n",
      "                 0.5222,\n",
      "                 0.6421,\n",
      "                 0.6262,\n",
      "                 0.6745,\n",
      "                 0.641,\n",
      "                 0.6535,\n",
      "                 0.7697,\n",
      "                 0.6108,\n",
      "                 0.7109,\n",
      "                 0.7496,\n",
      "                 0.5967,\n",
      "                 0.6684,\n",
      "                 0.5989,\n",
      "                 0.6334,\n",
      "                 0.6536,\n",
      "                 0.7094,\n",
      "                 0.6816,\n",
      "                 0.6472,\n",
      "                 0.6812,\n",
      "                 0.7795,\n",
      "                 0.6605,\n",
      "                 0.7796,\n",
      "                 0.6213,\n",
      "                 0.7358,\n",
      "                 0.611,\n",
      "                 0.6128,\n",
      "                 0.8083,\n",
      "                 0.6527,\n",
      "                 0.576,\n",
      "                 0.5508,\n",
      "                 0.7733],\n",
      "  'val_loss': [0.8379769325256348,\n",
      "               0.8362584114074707,\n",
      "               0.8345323801040649,\n",
      "               0.8312293887138367,\n",
      "               0.8270717859268188,\n",
      "               0.8226518630981445,\n",
      "               0.8181999325752258,\n",
      "               0.8142896890640259,\n",
      "               0.810498833656311,\n",
      "               0.8072371482849121,\n",
      "               0.8038370013237,\n",
      "               0.801761269569397,\n",
      "               0.7991471290588379,\n",
      "               0.7966843843460083,\n",
      "               0.7952083349227905,\n",
      "               0.7937015891075134,\n",
      "               0.7926721572875977,\n",
      "               0.7913503646850586,\n",
      "               0.7898972630500793,\n",
      "               0.7886942625045776,\n",
      "               0.787438690662384,\n",
      "               0.7868277430534363,\n",
      "               0.7864121198654175,\n",
      "               0.7856069207191467,\n",
      "               0.7849100828170776,\n",
      "               0.7844513654708862,\n",
      "               0.7840688228607178,\n",
      "               0.7838648557662964,\n",
      "               0.7835726141929626,\n",
      "               0.7832589745521545,\n",
      "               0.7830374240875244,\n",
      "               0.783016562461853,\n",
      "               0.7827365398406982,\n",
      "               0.7826173901557922,\n",
      "               0.7824745178222656,\n",
      "               0.7824443578720093,\n",
      "               0.7823630571365356,\n",
      "               0.782336413860321,\n",
      "               0.7822821736335754,\n",
      "               0.7822563052177429]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8237,\n",
      "                 0.9154,\n",
      "                 0.7389,\n",
      "                 0.8262,\n",
      "                 0.9148,\n",
      "                 0.6959,\n",
      "                 0.6442,\n",
      "                 0.9598,\n",
      "                 0.7273,\n",
      "                 0.7992,\n",
      "                 0.8897,\n",
      "                 0.6802,\n",
      "                 0.6897,\n",
      "                 0.7345,\n",
      "                 0.8435,\n",
      "                 0.762,\n",
      "                 0.7289,\n",
      "                 0.7689,\n",
      "                 0.7282,\n",
      "                 0.7724,\n",
      "                 0.88,\n",
      "                 0.6089,\n",
      "                 0.7084,\n",
      "                 0.7493,\n",
      "                 0.5775,\n",
      "                 0.8711,\n",
      "                 0.7207,\n",
      "                 0.7216,\n",
      "                 0.6364,\n",
      "                 0.6961,\n",
      "                 0.7262,\n",
      "                 0.7627,\n",
      "                 0.747,\n",
      "                 0.6126,\n",
      "                 0.7177,\n",
      "                 0.6346,\n",
      "                 0.7048,\n",
      "                 0.7309,\n",
      "                 0.7077,\n",
      "                 0.5784,\n",
      "                 0.6955,\n",
      "                 0.6066,\n",
      "                 0.6265,\n",
      "                 0.6426,\n",
      "                 0.6025,\n",
      "                 0.7738,\n",
      "                 0.6906,\n",
      "                 0.7044,\n",
      "                 0.687,\n",
      "                 0.6765,\n",
      "                 0.6076,\n",
      "                 0.6929,\n",
      "                 0.6661,\n",
      "                 0.6236,\n",
      "                 0.6374,\n",
      "                 0.7204,\n",
      "                 0.6523,\n",
      "                 0.6991,\n",
      "                 0.7649,\n",
      "                 0.4932,\n",
      "                 0.5939,\n",
      "                 0.6985,\n",
      "                 0.6377,\n",
      "                 0.7136,\n",
      "                 0.7096,\n",
      "                 0.5997,\n",
      "                 0.7729,\n",
      "                 0.5985,\n",
      "                 0.6826,\n",
      "                 0.6199,\n",
      "                 0.6324,\n",
      "                 0.6733,\n",
      "                 0.7469,\n",
      "                 0.5822,\n",
      "                 0.6798,\n",
      "                 0.6106,\n",
      "                 0.6079,\n",
      "                 0.6731,\n",
      "                 0.6616,\n",
      "                 0.6562],\n",
      "  'val_loss': [0.8375496864318848,\n",
      "               0.8341791033744812,\n",
      "               0.8281193971633911,\n",
      "               0.8195703625679016,\n",
      "               0.8091220855712891,\n",
      "               0.7993432283401489,\n",
      "               0.7907090187072754,\n",
      "               0.7825180888175964,\n",
      "               0.775282084941864,\n",
      "               0.7689939737319946,\n",
      "               0.7624770998954773,\n",
      "               0.7559727430343628,\n",
      "               0.7496445178985596,\n",
      "               0.7438873052597046,\n",
      "               0.7384040951728821,\n",
      "               0.7334074378013611,\n",
      "               0.728995680809021,\n",
      "               0.7249401807785034,\n",
      "               0.7209295034408569,\n",
      "               0.7172940969467163,\n",
      "               0.7138001322746277,\n",
      "               0.7107304334640503,\n",
      "               0.7079636454582214,\n",
      "               0.705607533454895,\n",
      "               0.7032874226570129,\n",
      "               0.7011780142784119,\n",
      "               0.6995461583137512,\n",
      "               0.6979526281356812,\n",
      "               0.6969468593597412,\n",
      "               0.6958389282226562,\n",
      "               0.6949219703674316,\n",
      "               0.6940451264381409,\n",
      "               0.6932268142700195,\n",
      "               0.6925948858261108,\n",
      "               0.6920641660690308,\n",
      "               0.691684365272522,\n",
      "               0.6914004683494568,\n",
      "               0.6911458969116211,\n",
      "               0.6909633874893188,\n",
      "               0.6908812522888184]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6312,\n",
      "                 0.7324,\n",
      "                 0.7742,\n",
      "                 0.5532,\n",
      "                 0.4992,\n",
      "                 0.4947,\n",
      "                 0.5642,\n",
      "                 0.5422,\n",
      "                 0.8834,\n",
      "                 0.5077,\n",
      "                 0.6308,\n",
      "                 0.6453,\n",
      "                 0.7662,\n",
      "                 0.5244,\n",
      "                 0.4855,\n",
      "                 0.5794,\n",
      "                 0.6832,\n",
      "                 0.5756,\n",
      "                 0.4283,\n",
      "                 0.4829,\n",
      "                 0.6633,\n",
      "                 0.5634,\n",
      "                 0.7014,\n",
      "                 0.6775,\n",
      "                 0.4949,\n",
      "                 0.5029,\n",
      "                 0.5822,\n",
      "                 0.3485,\n",
      "                 0.4139,\n",
      "                 0.5447,\n",
      "                 0.5568,\n",
      "                 0.6821,\n",
      "                 0.5802,\n",
      "                 0.4762,\n",
      "                 0.5834,\n",
      "                 0.5035,\n",
      "                 0.5457,\n",
      "                 0.5796,\n",
      "                 0.4576,\n",
      "                 0.6128],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.57745760679245,\n",
      "               0.5753026008605957,\n",
      "               0.5721268057823181,\n",
      "               0.5688502788543701,\n",
      "               0.5658209919929504,\n",
      "               0.5632616281509399,\n",
      "               0.5612854957580566,\n",
      "               0.5592943429946899,\n",
      "               0.5573409199714661,\n",
      "               0.5555916428565979,\n",
      "               0.5542250871658325,\n",
      "               0.5528786778450012,\n",
      "               0.5516281127929688,\n",
      "               0.5504664182662964,\n",
      "               0.5493770837783813,\n",
      "               0.5483916997909546,\n",
      "               0.54752516746521,\n",
      "               0.5467569231987,\n",
      "               0.5460313558578491,\n",
      "               0.545356035232544,\n",
      "               0.544727623462677,\n",
      "               0.5441800355911255,\n",
      "               0.5437018871307373,\n",
      "               0.5433425903320312,\n",
      "               0.5430310368537903,\n",
      "               0.5427398681640625,\n",
      "               0.5424655079841614,\n",
      "               0.5422146916389465,\n",
      "               0.5419927835464478,\n",
      "               0.5417889356613159,\n",
      "               0.5416162610054016,\n",
      "               0.5414559245109558,\n",
      "               0.5413187742233276,\n",
      "               0.5411929488182068,\n",
      "               0.5410882234573364,\n",
      "               0.5410073399543762,\n",
      "               0.5409406423568726,\n",
      "               0.5408928990364075,\n",
      "               0.5408695340156555]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.4135,\n",
      "                 0.482,\n",
      "                 0.429,\n",
      "                 0.4344,\n",
      "                 0.4843,\n",
      "                 0.6284,\n",
      "                 0.4642,\n",
      "                 0.3339,\n",
      "                 0.2347,\n",
      "                 0.3709,\n",
      "                 0.1773,\n",
      "                 0.2497,\n",
      "                 0.1394,\n",
      "                 0.1712,\n",
      "                 0.2694,\n",
      "                 0.1806,\n",
      "                 0.1768,\n",
      "                 0.1637,\n",
      "                 0.1732,\n",
      "                 0.1454,\n",
      "                 0.1511,\n",
      "                 0.1463,\n",
      "                 0.131,\n",
      "                 0.1749,\n",
      "                 0.1515,\n",
      "                 0.0751,\n",
      "                 0.1411,\n",
      "                 0.1275,\n",
      "                 0.1412,\n",
      "                 0.0912,\n",
      "                 0.1041,\n",
      "                 0.0865,\n",
      "                 0.2591,\n",
      "                 0.0651,\n",
      "                 0.1411,\n",
      "                 0.0593,\n",
      "                 0.0918,\n",
      "                 0.1204,\n",
      "                 0.1197,\n",
      "                 0.1258],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5800433158874512,\n",
      "               0.5829126834869385,\n",
      "               0.5875214338302612,\n",
      "               0.5940467715263367,\n",
      "               0.600712239742279,\n",
      "               0.6076474785804749,\n",
      "               0.6147996783256531,\n",
      "               0.6221701502799988,\n",
      "               0.6296199560165405,\n",
      "               0.6372594833374023,\n",
      "               0.6449936032295227,\n",
      "               0.652799129486084,\n",
      "               0.6606515049934387,\n",
      "               0.668389618396759,\n",
      "               0.6760823130607605,\n",
      "               0.6836885213851929,\n",
      "               0.6912075281143188,\n",
      "               0.6986724138259888,\n",
      "               0.7059646248817444,\n",
      "               0.7130813598632812,\n",
      "               0.7199665904045105,\n",
      "               0.726604163646698,\n",
      "               0.7330420613288879,\n",
      "               0.7391562461853027,\n",
      "               0.7449963688850403,\n",
      "               0.7505005598068237,\n",
      "               0.7556679844856262,\n",
      "               0.7605023384094238,\n",
      "               0.764994740486145,\n",
      "               0.7691071629524231,\n",
      "               0.7728503942489624,\n",
      "               0.7761889100074768,\n",
      "               0.7791367769241333,\n",
      "               0.7816740274429321,\n",
      "               0.7838196754455566,\n",
      "               0.7855566740036011,\n",
      "               0.7868642807006836,\n",
      "               0.7877294421195984,\n",
      "               0.7881677746772766]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.2283,\n",
      "                 1.369,\n",
      "                 1.0327,\n",
      "                 1.058,\n",
      "                 1.1464,\n",
      "                 1.3396,\n",
      "                 1.0699,\n",
      "                 0.9721,\n",
      "                 1.1226,\n",
      "                 0.9041,\n",
      "                 1.022,\n",
      "                 0.9141,\n",
      "                 0.8867,\n",
      "                 0.7913,\n",
      "                 0.6398,\n",
      "                 0.9533,\n",
      "                 0.5755,\n",
      "                 0.7384,\n",
      "                 0.7177,\n",
      "                 0.6744,\n",
      "                 0.6754,\n",
      "                 0.6673,\n",
      "                 0.6589,\n",
      "                 0.7339,\n",
      "                 0.6888,\n",
      "                 0.6371,\n",
      "                 0.6359,\n",
      "                 0.5092,\n",
      "                 0.5839,\n",
      "                 0.4511,\n",
      "                 0.4259,\n",
      "                 0.3569,\n",
      "                 0.4315,\n",
      "                 0.6399,\n",
      "                 0.4088,\n",
      "                 0.5726,\n",
      "                 0.416,\n",
      "                 0.632,\n",
      "                 0.5981,\n",
      "                 0.5735],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5771386623382568,\n",
      "               0.5742751359939575,\n",
      "               0.5701751112937927,\n",
      "               0.5652195811271667,\n",
      "               0.5610108375549316,\n",
      "               0.5573500394821167,\n",
      "               0.554232656955719,\n",
      "               0.5516671538352966,\n",
      "               0.549593448638916,\n",
      "               0.5479317307472229,\n",
      "               0.5466881394386292,\n",
      "               0.54582679271698,\n",
      "               0.5452815294265747,\n",
      "               0.5450116395950317,\n",
      "               0.5450016260147095,\n",
      "               0.5452372431755066,\n",
      "               0.5456898212432861,\n",
      "               0.5463075637817383,\n",
      "               0.5470708608627319,\n",
      "               0.5479602813720703,\n",
      "               0.548949658870697,\n",
      "               0.5499939322471619,\n",
      "               0.5511118769645691,\n",
      "               0.5522711277008057,\n",
      "               0.5534204840660095,\n",
      "               0.5545507669448853,\n",
      "               0.5556665658950806,\n",
      "               0.5567505955696106,\n",
      "               0.5578042268753052,\n",
      "               0.5587968826293945,\n",
      "               0.5597243309020996,\n",
      "               0.5605717301368713,\n",
      "               0.5613225698471069,\n",
      "               0.5619790554046631,\n",
      "               0.5625424385070801,\n",
      "               0.5629976987838745,\n",
      "               0.563339114189148,\n",
      "               0.5635687112808228,\n",
      "               0.5636848211288452]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6213,\n",
      "                 0.7618,\n",
      "                 0.3657,\n",
      "                 0.4952,\n",
      "                 0.5912,\n",
      "                 0.7154,\n",
      "                 0.5757,\n",
      "                 0.4783,\n",
      "                 0.2821,\n",
      "                 0.4491,\n",
      "                 0.2829,\n",
      "                 0.4355,\n",
      "                 0.3569,\n",
      "                 0.3086,\n",
      "                 0.2123,\n",
      "                 0.3556,\n",
      "                 0.2307,\n",
      "                 0.3531,\n",
      "                 0.1937,\n",
      "                 0.1642,\n",
      "                 0.1464,\n",
      "                 0.2993,\n",
      "                 0.193,\n",
      "                 0.2964,\n",
      "                 0.2952,\n",
      "                 0.362,\n",
      "                 0.1489,\n",
      "                 0.1077,\n",
      "                 0.1659,\n",
      "                 0.2074,\n",
      "                 0.1443,\n",
      "                 0.1277,\n",
      "                 0.1148,\n",
      "                 0.1037,\n",
      "                 0.0773,\n",
      "                 0.1214,\n",
      "                 0.2151,\n",
      "                 0.1523,\n",
      "                 0.2362,\n",
      "                 0.1074],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5772839784622192,\n",
      "               0.5746544003486633,\n",
      "               0.5709278583526611,\n",
      "               0.5663113594055176,\n",
      "               0.5623015761375427,\n",
      "               0.5587906837463379,\n",
      "               0.5557098388671875,\n",
      "               0.5530454516410828,\n",
      "               0.5508062839508057,\n",
      "               0.5488966703414917,\n",
      "               0.5472909212112427,\n",
      "               0.5459972620010376,\n",
      "               0.5449846386909485,\n",
      "               0.5441852807998657,\n",
      "               0.5436305403709412,\n",
      "               0.5432851314544678,\n",
      "               0.5431333780288696,\n",
      "               0.5431534051895142,\n",
      "               0.5433169603347778,\n",
      "               0.5435582995414734,\n",
      "               0.5438876748085022,\n",
      "               0.5442672371864319,\n",
      "               0.5446951985359192,\n",
      "               0.5451942682266235,\n",
      "               0.5457212924957275,\n",
      "               0.5462678074836731,\n",
      "               0.5468186140060425,\n",
      "               0.5473682880401611,\n",
      "               0.5479134321212769,\n",
      "               0.548454999923706,\n",
      "               0.548977255821228,\n",
      "               0.5494590997695923,\n",
      "               0.5498985052108765,\n",
      "               0.5502764582633972,\n",
      "               0.5506018400192261,\n",
      "               0.5508698225021362,\n",
      "               0.5510712265968323,\n",
      "               0.5512067675590515,\n",
      "               0.5512754321098328]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.8452,\n",
      "                 0.8579,\n",
      "                 0.9053,\n",
      "                 0.9095,\n",
      "                 0.8316,\n",
      "                 0.741,\n",
      "                 0.5246,\n",
      "                 0.8124,\n",
      "                 0.7938,\n",
      "                 0.6524,\n",
      "                 0.5112,\n",
      "                 0.7641,\n",
      "                 0.6185,\n",
      "                 0.7429,\n",
      "                 0.9017,\n",
      "                 0.6339,\n",
      "                 0.7951,\n",
      "                 0.4441,\n",
      "                 0.5471,\n",
      "                 0.6513,\n",
      "                 0.52,\n",
      "                 0.5888,\n",
      "                 0.828,\n",
      "                 0.7157,\n",
      "                 0.4868,\n",
      "                 0.6737,\n",
      "                 0.6117,\n",
      "                 0.8712,\n",
      "                 0.6982,\n",
      "                 0.6056,\n",
      "                 0.4736,\n",
      "                 0.5554,\n",
      "                 0.6653,\n",
      "                 0.5489,\n",
      "                 0.6074,\n",
      "                 0.507,\n",
      "                 0.5893,\n",
      "                 0.5796,\n",
      "                 0.6356,\n",
      "                 0.4672],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5783931612968445,\n",
      "               0.5775853395462036,\n",
      "               0.5759877562522888,\n",
      "               0.5739609003067017,\n",
      "               0.5720902681350708,\n",
      "               0.5703567862510681,\n",
      "               0.5692214369773865,\n",
      "               0.5679164528846741,\n",
      "               0.5668379664421082,\n",
      "               0.5658328533172607,\n",
      "               0.5650237798690796,\n",
      "               0.5643936395645142,\n",
      "               0.5639214515686035,\n",
      "               0.5636312365531921,\n",
      "               0.5633388757705688,\n",
      "               0.5630456209182739,\n",
      "               0.5629679560661316,\n",
      "               0.5629730820655823,\n",
      "               0.5630545616149902,\n",
      "               0.5630088448524475,\n",
      "               0.5630453824996948,\n",
      "               0.5630077123641968,\n",
      "               0.5630012154579163,\n",
      "               0.5629836916923523,\n",
      "               0.5629872679710388,\n",
      "               0.5630146265029907,\n",
      "               0.5630075931549072,\n",
      "               0.5629823803901672,\n",
      "               0.5629635453224182,\n",
      "               0.5629673600196838,\n",
      "               0.5629764795303345,\n",
      "               0.5629583597183228,\n",
      "               0.562947154045105,\n",
      "               0.5629202723503113,\n",
      "               0.5628922581672668,\n",
      "               0.5628783702850342,\n",
      "               0.5628758668899536,\n",
      "               0.5628695487976074,\n",
      "               0.5628679394721985]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.0271,\n",
      "                 1.0508,\n",
      "                 0.6861,\n",
      "                 1.1071,\n",
      "                 0.8515,\n",
      "                 0.9481,\n",
      "                 1.1609,\n",
      "                 1.0168,\n",
      "                 0.7708,\n",
      "                 0.8818,\n",
      "                 0.8065,\n",
      "                 1.0172,\n",
      "                 0.8324,\n",
      "                 1.0083,\n",
      "                 0.6834,\n",
      "                 0.9177,\n",
      "                 0.7926,\n",
      "                 0.6168,\n",
      "                 0.7904,\n",
      "                 0.4998,\n",
      "                 0.7728,\n",
      "                 0.7818,\n",
      "                 0.674,\n",
      "                 0.7934,\n",
      "                 0.701,\n",
      "                 0.9495,\n",
      "                 0.6223,\n",
      "                 0.6883,\n",
      "                 0.6891,\n",
      "                 0.5655,\n",
      "                 0.8068,\n",
      "                 0.6178,\n",
      "                 0.7032,\n",
      "                 0.6771,\n",
      "                 0.7184,\n",
      "                 0.6104,\n",
      "                 0.971,\n",
      "                 0.4958,\n",
      "                 0.7144,\n",
      "                 0.497],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5774034261703491,\n",
      "               0.5751227140426636,\n",
      "               0.5720127820968628,\n",
      "               0.5679027438163757,\n",
      "               0.5642406940460205,\n",
      "               0.5609256625175476,\n",
      "               0.5579118728637695,\n",
      "               0.5551793575286865,\n",
      "               0.5527599453926086,\n",
      "               0.5505743026733398,\n",
      "               0.5485742688179016,\n",
      "               0.546807587146759,\n",
      "               0.5452186465263367,\n",
      "               0.5437493920326233,\n",
      "               0.5424416065216064,\n",
      "               0.5413009524345398,\n",
      "               0.540241539478302,\n",
      "               0.5392888784408569,\n",
      "               0.5384644269943237,\n",
      "               0.537699818611145,\n",
      "               0.5370107889175415,\n",
      "               0.53639817237854,\n",
      "               0.5358468294143677,\n",
      "               0.5353357791900635,\n",
      "               0.5348953008651733,\n",
      "               0.5345160961151123,\n",
      "               0.5341753363609314,\n",
      "               0.5338764190673828,\n",
      "               0.5336061120033264,\n",
      "               0.5333613157272339,\n",
      "               0.5331544280052185,\n",
      "               0.5329753160476685,\n",
      "               0.532813310623169,\n",
      "               0.5326640009880066,\n",
      "               0.5325468182563782,\n",
      "               0.5324578285217285,\n",
      "               0.5323935747146606,\n",
      "               0.5323517918586731,\n",
      "               0.5323296785354614]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.6909,\n",
      "                 0.633,\n",
      "                 0.7314,\n",
      "                 0.7062,\n",
      "                 0.7149,\n",
      "                 0.9232,\n",
      "                 0.6162,\n",
      "                 0.7241,\n",
      "                 0.5093,\n",
      "                 0.6514,\n",
      "                 0.5256,\n",
      "                 0.7412,\n",
      "                 0.3923,\n",
      "                 0.5959,\n",
      "                 0.2743,\n",
      "                 0.3884,\n",
      "                 0.3381,\n",
      "                 0.708,\n",
      "                 0.3512,\n",
      "                 0.5149,\n",
      "                 0.2798,\n",
      "                 0.289,\n",
      "                 0.3162,\n",
      "                 0.2912,\n",
      "                 0.4472,\n",
      "                 0.4735,\n",
      "                 0.1602,\n",
      "                 0.1875,\n",
      "                 0.2396,\n",
      "                 0.2735,\n",
      "                 0.2018,\n",
      "                 0.2822,\n",
      "                 0.2659,\n",
      "                 0.1733,\n",
      "                 0.2319,\n",
      "                 0.1664,\n",
      "                 0.1441,\n",
      "                 0.149,\n",
      "                 0.1979,\n",
      "                 0.3215],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.577223002910614,\n",
      "               0.5745033025741577,\n",
      "               0.5706710815429688,\n",
      "               0.5661360025405884,\n",
      "               0.5622797608375549,\n",
      "               0.558931827545166,\n",
      "               0.5560763478279114,\n",
      "               0.5536550283432007,\n",
      "               0.5516756176948547,\n",
      "               0.5500530004501343,\n",
      "               0.5487426519393921,\n",
      "               0.5477367639541626,\n",
      "               0.547029972076416,\n",
      "               0.5465866923332214,\n",
      "               0.5464087724685669,\n",
      "               0.5464731454849243,\n",
      "               0.546707034111023,\n",
      "               0.5470935106277466,\n",
      "               0.5476102828979492,\n",
      "               0.5482468008995056,\n",
      "               0.5489684343338013,\n",
      "               0.5497610569000244,\n",
      "               0.5506206154823303,\n",
      "               0.5515117645263672,\n",
      "               0.5524206757545471,\n",
      "               0.5533221364021301,\n",
      "               0.554215669631958,\n",
      "               0.5550819635391235,\n",
      "               0.5559210777282715,\n",
      "               0.5567253232002258,\n",
      "               0.5574746131896973,\n",
      "               0.558164656162262,\n",
      "               0.5587800145149231,\n",
      "               0.5593053102493286,\n",
      "               0.5597644448280334,\n",
      "               0.5601328611373901,\n",
      "               0.5604076981544495,\n",
      "               0.560594916343689,\n",
      "               0.5606913566589355]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.0166,\n",
      "                 0.639,\n",
      "                 0.7197,\n",
      "                 0.8898,\n",
      "                 0.6759,\n",
      "                 0.7726,\n",
      "                 0.707,\n",
      "                 0.8278,\n",
      "                 0.7516,\n",
      "                 0.6857,\n",
      "                 0.9082,\n",
      "                 0.8764,\n",
      "                 0.6481,\n",
      "                 0.4878,\n",
      "                 0.7207,\n",
      "                 0.6992,\n",
      "                 0.5584,\n",
      "                 0.5925,\n",
      "                 0.8259,\n",
      "                 0.6185,\n",
      "                 0.6762,\n",
      "                 0.6784,\n",
      "                 0.6794,\n",
      "                 0.7607,\n",
      "                 0.7889,\n",
      "                 0.7086,\n",
      "                 0.6314,\n",
      "                 0.6456,\n",
      "                 0.7212,\n",
      "                 0.5655,\n",
      "                 0.4505,\n",
      "                 0.5683,\n",
      "                 0.6419,\n",
      "                 0.5309,\n",
      "                 0.5827,\n",
      "                 0.585,\n",
      "                 0.5112,\n",
      "                 0.6155,\n",
      "                 0.6602,\n",
      "                 0.6429],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5784352421760559,\n",
      "               0.5775484442710876,\n",
      "               0.5759924054145813,\n",
      "               0.5740283727645874,\n",
      "               0.5724844932556152,\n",
      "               0.5711098909378052,\n",
      "               0.5698261857032776,\n",
      "               0.568718433380127,\n",
      "               0.5678271055221558,\n",
      "               0.5667433738708496,\n",
      "               0.565539538860321,\n",
      "               0.5644543766975403,\n",
      "               0.5636143684387207,\n",
      "               0.5628136396408081,\n",
      "               0.5620425343513489,\n",
      "               0.5613253116607666,\n",
      "               0.5606541037559509,\n",
      "               0.5601129531860352,\n",
      "               0.559664249420166,\n",
      "               0.5591117143630981,\n",
      "               0.5586450695991516,\n",
      "               0.5582116842269897,\n",
      "               0.5578650236129761,\n",
      "               0.557528555393219,\n",
      "               0.5572671890258789,\n",
      "               0.556979775428772,\n",
      "               0.5567653775215149,\n",
      "               0.5566056370735168,\n",
      "               0.556500256061554,\n",
      "               0.5564818978309631,\n",
      "               0.5564190745353699,\n",
      "               0.5562999844551086,\n",
      "               0.5561889410018921,\n",
      "               0.5560709238052368,\n",
      "               0.5559744238853455,\n",
      "               0.5559052228927612,\n",
      "               0.5558550357818604,\n",
      "               0.5558179616928101,\n",
      "               0.5557945370674133]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.5794,\n",
      "                 0.7153,\n",
      "                 0.6459,\n",
      "                 0.5737,\n",
      "                 0.5543,\n",
      "                 0.6481,\n",
      "                 0.5427,\n",
      "                 0.5067,\n",
      "                 0.5374,\n",
      "                 0.4005,\n",
      "                 0.5081,\n",
      "                 0.4229,\n",
      "                 0.5823,\n",
      "                 0.4215,\n",
      "                 0.3442,\n",
      "                 0.3915,\n",
      "                 0.4871,\n",
      "                 0.2819,\n",
      "                 0.2768,\n",
      "                 0.3258,\n",
      "                 0.2385,\n",
      "                 0.3033,\n",
      "                 0.3924,\n",
      "                 0.2737,\n",
      "                 0.2279,\n",
      "                 0.279,\n",
      "                 0.3897,\n",
      "                 0.3064,\n",
      "                 0.2243,\n",
      "                 0.2485,\n",
      "                 0.1499,\n",
      "                 0.2688,\n",
      "                 0.3155,\n",
      "                 0.1299,\n",
      "                 0.2451,\n",
      "                 0.2026,\n",
      "                 0.3252,\n",
      "                 0.183,\n",
      "                 0.1977,\n",
      "                 0.1743],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5769845247268677,\n",
      "               0.5738494396209717,\n",
      "               0.5695074796676636,\n",
      "               0.5642703175544739,\n",
      "               0.5598158836364746,\n",
      "               0.5560208559036255,\n",
      "               0.5529075264930725,\n",
      "               0.5503559112548828,\n",
      "               0.5483397841453552,\n",
      "               0.5468184947967529,\n",
      "               0.5457097291946411,\n",
      "               0.5450308918952942,\n",
      "               0.5446909070014954,\n",
      "               0.5446426868438721,\n",
      "               0.5448622703552246,\n",
      "               0.5453435182571411,\n",
      "               0.5460290908813477,\n",
      "               0.5468777418136597,\n",
      "               0.5478724241256714,\n",
      "               0.5489851236343384,\n",
      "               0.550197958946228,\n",
      "               0.5514882802963257,\n",
      "               0.5528284311294556,\n",
      "               0.5542203187942505,\n",
      "               0.5556260943412781,\n",
      "               0.5570145845413208,\n",
      "               0.5583702325820923,\n",
      "               0.5596837401390076,\n",
      "               0.5609353184700012,\n",
      "               0.5621210932731628,\n",
      "               0.5632275938987732,\n",
      "               0.5642385482788086,\n",
      "               0.565144956111908,\n",
      "               0.565937340259552,\n",
      "               0.5666113495826721,\n",
      "               0.567160964012146,\n",
      "               0.5675755739212036,\n",
      "               0.5678541660308838,\n",
      "               0.5679937601089478]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.5069,\n",
      "                 0.5824,\n",
      "                 0.4401,\n",
      "                 0.5384,\n",
      "                 0.5339,\n",
      "                 0.5655,\n",
      "                 0.5335,\n",
      "                 0.6146,\n",
      "                 0.2668,\n",
      "                 0.3427,\n",
      "                 0.3465,\n",
      "                 0.2299,\n",
      "                 0.2054,\n",
      "                 0.3221,\n",
      "                 0.2628,\n",
      "                 0.2809,\n",
      "                 0.3508,\n",
      "                 0.301,\n",
      "                 0.2371,\n",
      "                 0.258,\n",
      "                 0.3519,\n",
      "                 0.2121,\n",
      "                 0.2552,\n",
      "                 0.1997,\n",
      "                 0.1234,\n",
      "                 0.1779,\n",
      "                 0.1478,\n",
      "                 0.245,\n",
      "                 0.1704,\n",
      "                 0.2287,\n",
      "                 0.1439,\n",
      "                 0.1104,\n",
      "                 0.1944,\n",
      "                 0.2103,\n",
      "                 0.183,\n",
      "                 0.1451,\n",
      "                 0.1555,\n",
      "                 0.175,\n",
      "                 0.2553,\n",
      "                 0.2001],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5800145864486694,\n",
      "               0.5828603506088257,\n",
      "               0.5874332189559937,\n",
      "               0.5939781069755554,\n",
      "               0.6008307337760925,\n",
      "               0.6078938245773315,\n",
      "               0.6150683760643005,\n",
      "               0.6224385499954224,\n",
      "               0.6298704147338867,\n",
      "               0.6374455094337463,\n",
      "               0.6452048420906067,\n",
      "               0.6530288457870483,\n",
      "               0.6609014272689819,\n",
      "               0.6686768531799316,\n",
      "               0.6763297915458679,\n",
      "               0.6839464902877808,\n",
      "               0.6915143728256226,\n",
      "               0.6989480257034302,\n",
      "               0.7063004374504089,\n",
      "               0.7134675979614258,\n",
      "               0.7203512191772461,\n",
      "               0.7269498705863953,\n",
      "               0.7334827780723572,\n",
      "               0.7398175001144409,\n",
      "               0.7458314299583435,\n",
      "               0.7515623569488525,\n",
      "               0.7569199800491333,\n",
      "               0.7619905471801758,\n",
      "               0.7667424082756042,\n",
      "               0.7710898518562317,\n",
      "               0.7751300930976868,\n",
      "               0.7787516713142395,\n",
      "               0.7819157838821411,\n",
      "               0.7846238017082214,\n",
      "               0.7869241237640381,\n",
      "               0.7887906432151794,\n",
      "               0.7902156114578247,\n",
      "               0.7911534905433655,\n",
      "               0.7916223406791687]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.2224,\n",
      "                 1.4478,\n",
      "                 1.4676,\n",
      "                 1.4441,\n",
      "                 1.163,\n",
      "                 0.8848,\n",
      "                 1.0591,\n",
      "                 0.8518,\n",
      "                 1.234,\n",
      "                 1.2591,\n",
      "                 0.9746,\n",
      "                 1.2376,\n",
      "                 0.9604,\n",
      "                 1.2548,\n",
      "                 1.1396,\n",
      "                 1.0842,\n",
      "                 0.9128,\n",
      "                 1.0897,\n",
      "                 0.9034,\n",
      "                 1.1852,\n",
      "                 0.9241,\n",
      "                 0.9791,\n",
      "                 1.1475,\n",
      "                 0.8935,\n",
      "                 1.2817,\n",
      "                 0.9612,\n",
      "                 0.9734,\n",
      "                 0.9973,\n",
      "                 0.9884,\n",
      "                 0.874,\n",
      "                 0.9618,\n",
      "                 1.0899,\n",
      "                 1.0143,\n",
      "                 0.9922,\n",
      "                 1.0066,\n",
      "                 1.0578,\n",
      "                 0.951,\n",
      "                 0.864,\n",
      "                 0.8403,\n",
      "                 0.9439],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.577569305896759,\n",
      "               0.5753837823867798,\n",
      "               0.5721549391746521,\n",
      "               0.5681445002555847,\n",
      "               0.5646713376045227,\n",
      "               0.5613385438919067,\n",
      "               0.5583629608154297,\n",
      "               0.5558174252510071,\n",
      "               0.5536221861839294,\n",
      "               0.5517794489860535,\n",
      "               0.5502282977104187,\n",
      "               0.5489041805267334,\n",
      "               0.5478266477584839,\n",
      "               0.5469524264335632,\n",
      "               0.546225905418396,\n",
      "               0.5456622242927551,\n",
      "               0.5452659726142883,\n",
      "               0.5449874997138977,\n",
      "               0.5447589159011841,\n",
      "               0.5445784330368042,\n",
      "               0.5444217324256897,\n",
      "               0.5443211197853088,\n",
      "               0.544257640838623,\n",
      "               0.5442264676094055,\n",
      "               0.5442485809326172,\n",
      "               0.5443121194839478,\n",
      "               0.5444250106811523,\n",
      "               0.5445584058761597,\n",
      "               0.5446906685829163,\n",
      "               0.5448068976402283,\n",
      "               0.544924259185791,\n",
      "               0.5450361967086792,\n",
      "               0.5451451539993286,\n",
      "               0.5452461242675781,\n",
      "               0.5453321933746338,\n",
      "               0.5454031825065613,\n",
      "               0.5454573035240173,\n",
      "               0.5454921126365662,\n",
      "               0.5455102920532227]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.6358,\n",
      "                 0.5231,\n",
      "                 0.6106,\n",
      "                 0.5103,\n",
      "                 0.4085,\n",
      "                 0.4487,\n",
      "                 0.4898,\n",
      "                 0.4126,\n",
      "                 0.502,\n",
      "                 0.3842,\n",
      "                 0.3796,\n",
      "                 0.4266,\n",
      "                 0.3673,\n",
      "                 0.326,\n",
      "                 0.3745,\n",
      "                 0.4579,\n",
      "                 0.3864,\n",
      "                 0.4041,\n",
      "                 0.3233,\n",
      "                 0.2465,\n",
      "                 0.3685,\n",
      "                 0.3925,\n",
      "                 0.3347,\n",
      "                 0.2409,\n",
      "                 0.3039,\n",
      "                 0.2472,\n",
      "                 0.3461,\n",
      "                 0.2456,\n",
      "                 0.2606,\n",
      "                 0.2503,\n",
      "                 0.3259,\n",
      "                 0.278,\n",
      "                 0.2806,\n",
      "                 0.2477,\n",
      "                 0.2611,\n",
      "                 0.2689,\n",
      "                 0.282,\n",
      "                 0.278,\n",
      "                 0.2853,\n",
      "                 0.2413],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5773841142654419,\n",
      "               0.5751552581787109,\n",
      "               0.5720146298408508,\n",
      "               0.5682531595230103,\n",
      "               0.5651419758796692,\n",
      "               0.5625118017196655,\n",
      "               0.5603581666946411,\n",
      "               0.5585804581642151,\n",
      "               0.5571657419204712,\n",
      "               0.556074857711792,\n",
      "               0.5552967190742493,\n",
      "               0.5547957420349121,\n",
      "               0.5545511245727539,\n",
      "               0.5545915365219116,\n",
      "               0.5548169016838074,\n",
      "               0.5551940202713013,\n",
      "               0.5557585954666138,\n",
      "               0.5564706325531006,\n",
      "               0.5572879910469055,\n",
      "               0.5582072734832764,\n",
      "               0.5591858625411987,\n",
      "               0.5602176785469055,\n",
      "               0.561281681060791,\n",
      "               0.5623401999473572,\n",
      "               0.5633953213691711,\n",
      "               0.56438809633255,\n",
      "               0.5653644800186157,\n",
      "               0.5663511753082275,\n",
      "               0.5673050880432129,\n",
      "               0.5681355595588684,\n",
      "               0.5689100027084351,\n",
      "               0.5696090459823608,\n",
      "               0.5702254772186279,\n",
      "               0.5707739591598511,\n",
      "               0.5712409615516663,\n",
      "               0.5716151595115662,\n",
      "               0.5718982219696045,\n",
      "               0.5720887184143066,\n",
      "               0.5721805691719055]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.8042,\n",
      "                 0.7852,\n",
      "                 0.6971,\n",
      "                 0.622,\n",
      "                 0.7218,\n",
      "                 0.8807,\n",
      "                 0.7829,\n",
      "                 0.501,\n",
      "                 0.5321,\n",
      "                 0.7489,\n",
      "                 0.7888,\n",
      "                 0.6617,\n",
      "                 0.7718,\n",
      "                 0.6152,\n",
      "                 0.6267,\n",
      "                 0.589,\n",
      "                 0.4766,\n",
      "                 0.6187,\n",
      "                 0.565,\n",
      "                 0.5977,\n",
      "                 0.6295,\n",
      "                 0.5882,\n",
      "                 0.4021,\n",
      "                 0.8136,\n",
      "                 0.4499,\n",
      "                 0.5123,\n",
      "                 0.4464,\n",
      "                 0.6594,\n",
      "                 0.4225,\n",
      "                 0.5333,\n",
      "                 0.814,\n",
      "                 0.7089,\n",
      "                 0.587,\n",
      "                 0.5718,\n",
      "                 0.7126,\n",
      "                 0.4443,\n",
      "                 0.5035,\n",
      "                 0.5757,\n",
      "                 0.5244,\n",
      "                 0.4868],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5777390599250793,\n",
      "               0.5761007070541382,\n",
      "               0.5734028220176697,\n",
      "               0.5697788000106812,\n",
      "               0.5665801763534546,\n",
      "               0.5636308789253235,\n",
      "               0.5610253214836121,\n",
      "               0.5587211847305298,\n",
      "               0.557073712348938,\n",
      "               0.5555174946784973,\n",
      "               0.5542246699333191,\n",
      "               0.5531597137451172,\n",
      "               0.5520978569984436,\n",
      "               0.5512951612472534,\n",
      "               0.550521731376648,\n",
      "               0.5497021675109863,\n",
      "               0.5489131808280945,\n",
      "               0.5481532216072083,\n",
      "               0.547478199005127,\n",
      "               0.546908438205719,\n",
      "               0.5463635921478271,\n",
      "               0.5458794832229614,\n",
      "               0.5454503297805786,\n",
      "               0.5450504422187805,\n",
      "               0.5446443557739258,\n",
      "               0.5442879796028137,\n",
      "               0.5439993739128113,\n",
      "               0.5437315702438354,\n",
      "               0.5435494184494019,\n",
      "               0.543379008769989,\n",
      "               0.5432256460189819,\n",
      "               0.5431105494499207,\n",
      "               0.5429884195327759,\n",
      "               0.542900562286377,\n",
      "               0.5428134202957153,\n",
      "               0.5427383780479431,\n",
      "               0.542678713798523,\n",
      "               0.5426376461982727,\n",
      "               0.5426168441772461]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.5307,\n",
      "                 0.5272,\n",
      "                 0.4937,\n",
      "                 0.6189,\n",
      "                 0.511,\n",
      "                 0.5598,\n",
      "                 0.5506,\n",
      "                 0.3264,\n",
      "                 0.4537,\n",
      "                 0.5884,\n",
      "                 0.5066,\n",
      "                 0.5453,\n",
      "                 0.3651,\n",
      "                 0.5449,\n",
      "                 0.4701,\n",
      "                 0.335,\n",
      "                 0.4129,\n",
      "                 0.4839,\n",
      "                 0.5156,\n",
      "                 0.3882,\n",
      "                 0.4146,\n",
      "                 0.444,\n",
      "                 0.3802,\n",
      "                 0.3334,\n",
      "                 0.3386,\n",
      "                 0.517,\n",
      "                 0.3007,\n",
      "                 0.3901,\n",
      "                 0.3341,\n",
      "                 0.3879,\n",
      "                 0.3348,\n",
      "                 0.3888,\n",
      "                 0.3641,\n",
      "                 0.3035,\n",
      "                 0.2741,\n",
      "                 0.3474,\n",
      "                 0.3264,\n",
      "                 0.277,\n",
      "                 0.3272,\n",
      "                 0.2725],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5776064991950989,\n",
      "               0.5755743384361267,\n",
      "               0.5728459358215332,\n",
      "               0.5693231821060181,\n",
      "               0.5662515163421631,\n",
      "               0.5635031461715698,\n",
      "               0.5609501600265503,\n",
      "               0.5586679577827454,\n",
      "               0.5566481351852417,\n",
      "               0.5548393130302429,\n",
      "               0.5533037185668945,\n",
      "               0.5519506335258484,\n",
      "               0.550713837146759,\n",
      "               0.5496796369552612,\n",
      "               0.5487216711044312,\n",
      "               0.5479110479354858,\n",
      "               0.547368049621582,\n",
      "               0.5469130277633667,\n",
      "               0.5465114712715149,\n",
      "               0.5461475849151611,\n",
      "               0.5457894802093506,\n",
      "               0.5454508066177368,\n",
      "               0.5451564192771912,\n",
      "               0.5448851585388184,\n",
      "               0.5446492433547974,\n",
      "               0.5444450378417969,\n",
      "               0.5443032383918762,\n",
      "               0.5441804528236389,\n",
      "               0.5440827012062073,\n",
      "               0.544010579586029,\n",
      "               0.5439523458480835,\n",
      "               0.5439082384109497,\n",
      "               0.5438650846481323,\n",
      "               0.5438312292098999,\n",
      "               0.5437965989112854,\n",
      "               0.5437706112861633,\n",
      "               0.5437448024749756,\n",
      "               0.5437343120574951,\n",
      "               0.5437290668487549]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7273,\n",
      "                 0.7223,\n",
      "                 0.5416,\n",
      "                 0.6047,\n",
      "                 0.7058,\n",
      "                 0.5586,\n",
      "                 0.5188,\n",
      "                 0.4959,\n",
      "                 0.5859,\n",
      "                 0.5707,\n",
      "                 0.4451,\n",
      "                 0.6015,\n",
      "                 0.3749,\n",
      "                 0.5241,\n",
      "                 0.5257,\n",
      "                 0.5627,\n",
      "                 0.4114,\n",
      "                 0.4967,\n",
      "                 0.8078,\n",
      "                 0.3905,\n",
      "                 0.4434,\n",
      "                 0.5927,\n",
      "                 0.4998,\n",
      "                 0.4521,\n",
      "                 0.4604,\n",
      "                 0.4906,\n",
      "                 0.5257,\n",
      "                 0.48,\n",
      "                 0.6442,\n",
      "                 0.4065,\n",
      "                 0.4587,\n",
      "                 0.6778,\n",
      "                 0.3925,\n",
      "                 0.6082,\n",
      "                 0.475,\n",
      "                 0.4071,\n",
      "                 0.3952,\n",
      "                 0.3448,\n",
      "                 0.3277,\n",
      "                 0.4984],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5793064832687378,\n",
      "               0.5809338688850403,\n",
      "               0.5832210779190063,\n",
      "               0.5868502259254456,\n",
      "               0.5905934572219849,\n",
      "               0.5943803787231445,\n",
      "               0.5975360870361328,\n",
      "               0.6007155179977417,\n",
      "               0.603620171546936,\n",
      "               0.6066166162490845,\n",
      "               0.6095398664474487,\n",
      "               0.6125696897506714,\n",
      "               0.6154567003250122,\n",
      "               0.6180051565170288,\n",
      "               0.6202861070632935,\n",
      "               0.6228164434432983,\n",
      "               0.6247637867927551,\n",
      "               0.6268545389175415,\n",
      "               0.6288043856620789,\n",
      "               0.6304219365119934,\n",
      "               0.6318118572235107,\n",
      "               0.6326740384101868,\n",
      "               0.6337793469429016,\n",
      "               0.6345458626747131,\n",
      "               0.6351058483123779,\n",
      "               0.6355859041213989,\n",
      "               0.6360217332839966,\n",
      "               0.6365731954574585,\n",
      "               0.6369771957397461,\n",
      "               0.6372882127761841,\n",
      "               0.6375703811645508,\n",
      "               0.6377648115158081,\n",
      "               0.6379124522209167,\n",
      "               0.6380160450935364,\n",
      "               0.6380585432052612,\n",
      "               0.6381844282150269,\n",
      "               0.6383164525032043,\n",
      "               0.6384167671203613,\n",
      "               0.638466477394104]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7196,\n",
      "                 0.9666,\n",
      "                 1.1684,\n",
      "                 0.7168,\n",
      "                 0.8783,\n",
      "                 0.8312,\n",
      "                 0.6329,\n",
      "                 1.0356,\n",
      "                 0.6081,\n",
      "                 0.8157,\n",
      "                 0.808,\n",
      "                 0.583,\n",
      "                 0.7138,\n",
      "                 0.5825,\n",
      "                 0.5579,\n",
      "                 0.6638,\n",
      "                 0.6751,\n",
      "                 0.5478,\n",
      "                 0.5021,\n",
      "                 0.5705,\n",
      "                 0.6157,\n",
      "                 0.5994,\n",
      "                 0.4268,\n",
      "                 0.5827,\n",
      "                 0.3456,\n",
      "                 0.4964,\n",
      "                 0.5026,\n",
      "                 0.4091,\n",
      "                 0.3905,\n",
      "                 0.5024,\n",
      "                 0.4849,\n",
      "                 0.4474,\n",
      "                 0.3282,\n",
      "                 0.418,\n",
      "                 0.3721,\n",
      "                 0.5287,\n",
      "                 0.4723,\n",
      "                 0.4435,\n",
      "                 0.3378,\n",
      "                 0.4475],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.580106258392334,\n",
      "               0.5832017660140991,\n",
      "               0.5879524946212769,\n",
      "               0.5947253704071045,\n",
      "               0.6018846035003662,\n",
      "               0.6093513369560242,\n",
      "               0.6170170903205872,\n",
      "               0.6246712803840637,\n",
      "               0.6323521137237549,\n",
      "               0.6400567293167114,\n",
      "               0.6477546691894531,\n",
      "               0.6553942561149597,\n",
      "               0.663148820400238,\n",
      "               0.6708930730819702,\n",
      "               0.6785968542098999,\n",
      "               0.6862348318099976,\n",
      "               0.6936647891998291,\n",
      "               0.7007880210876465,\n",
      "               0.7077010869979858,\n",
      "               0.714446485042572,\n",
      "               0.7209821939468384,\n",
      "               0.7273971438407898,\n",
      "               0.7336485981941223,\n",
      "               0.7395746111869812,\n",
      "               0.7452343106269836,\n",
      "               0.750449538230896,\n",
      "               0.7552200555801392,\n",
      "               0.7597914934158325,\n",
      "               0.764045238494873,\n",
      "               0.7680115699768066,\n",
      "               0.7715532183647156,\n",
      "               0.7746520042419434,\n",
      "               0.7773693799972534,\n",
      "               0.7796916961669922,\n",
      "               0.7816388010978699,\n",
      "               0.7831811904907227,\n",
      "               0.7843425869941711,\n",
      "               0.7851086854934692,\n",
      "               0.7854859232902527]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [1.2401,\n",
      "                 1.5679,\n",
      "                 1.5077,\n",
      "                 1.3562,\n",
      "                 1.4389,\n",
      "                 1.6838,\n",
      "                 1.4472,\n",
      "                 1.4852,\n",
      "                 1.4378,\n",
      "                 1.4222,\n",
      "                 1.2149,\n",
      "                 1.296,\n",
      "                 1.5158,\n",
      "                 1.4351,\n",
      "                 1.2444,\n",
      "                 1.5176,\n",
      "                 1.2326,\n",
      "                 1.275,\n",
      "                 1.4313,\n",
      "                 1.3538,\n",
      "                 1.2095,\n",
      "                 1.2063,\n",
      "                 1.208,\n",
      "                 1.4059,\n",
      "                 1.3113,\n",
      "                 1.2364,\n",
      "                 0.9212,\n",
      "                 1.2283,\n",
      "                 1.1532,\n",
      "                 1.4084,\n",
      "                 1.277,\n",
      "                 0.9686,\n",
      "                 1.0284,\n",
      "                 1.1361,\n",
      "                 1.2242,\n",
      "                 1.1541,\n",
      "                 1.3796,\n",
      "                 1.1438,\n",
      "                 1.0973,\n",
      "                 1.2796],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5787591338157654,\n",
      "               0.5791911482810974,\n",
      "               0.5798124670982361,\n",
      "               0.5806523561477661,\n",
      "               0.5816951990127563,\n",
      "               0.5828741788864136,\n",
      "               0.5839176774024963,\n",
      "               0.5849871039390564,\n",
      "               0.5858224630355835,\n",
      "               0.5867537260055542,\n",
      "               0.5876805186271667,\n",
      "               0.5883957147598267,\n",
      "               0.5891368985176086,\n",
      "               0.5898531079292297,\n",
      "               0.5907655954360962,\n",
      "               0.5917267799377441,\n",
      "               0.5926912426948547,\n",
      "               0.593543291091919,\n",
      "               0.5943965911865234,\n",
      "               0.5953012704849243,\n",
      "               0.5961297750473022,\n",
      "               0.5970145463943481,\n",
      "               0.5977205634117126,\n",
      "               0.5983311533927917,\n",
      "               0.5990194082260132,\n",
      "               0.5995965003967285,\n",
      "               0.6000654697418213,\n",
      "               0.6004995107650757,\n",
      "               0.6008971929550171,\n",
      "               0.6012852787971497,\n",
      "               0.6016523838043213,\n",
      "               0.6020196676254272,\n",
      "               0.602353572845459,\n",
      "               0.6026103496551514,\n",
      "               0.6027930378913879,\n",
      "               0.602933406829834,\n",
      "               0.6030368208885193,\n",
      "               0.60312420129776,\n",
      "               0.6031617522239685]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.7952,\n",
      "                 0.8267,\n",
      "                 0.8931,\n",
      "                 1.0042,\n",
      "                 0.7574,\n",
      "                 0.8874,\n",
      "                 0.8111,\n",
      "                 0.8057,\n",
      "                 0.771,\n",
      "                 0.7619,\n",
      "                 0.684,\n",
      "                 0.8331,\n",
      "                 0.7139,\n",
      "                 1.0306,\n",
      "                 1.0145,\n",
      "                 1.0359,\n",
      "                 0.7151,\n",
      "                 0.8289,\n",
      "                 0.9576,\n",
      "                 0.8511,\n",
      "                 0.8321,\n",
      "                 1.0525,\n",
      "                 0.8772,\n",
      "                 0.853,\n",
      "                 0.7931,\n",
      "                 1.0338,\n",
      "                 0.5657,\n",
      "                 0.6978,\n",
      "                 0.9262,\n",
      "                 0.8445,\n",
      "                 0.8564,\n",
      "                 0.7859,\n",
      "                 0.7023,\n",
      "                 0.9373,\n",
      "                 0.8044,\n",
      "                 0.6313,\n",
      "                 0.7114,\n",
      "                 0.7828,\n",
      "                 0.7958,\n",
      "                 0.6321],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.578738808631897,\n",
      "               0.578954815864563,\n",
      "               0.5786460041999817,\n",
      "               0.577717125415802,\n",
      "               0.5763852596282959,\n",
      "               0.575073778629303,\n",
      "               0.5742015242576599,\n",
      "               0.5734549760818481,\n",
      "               0.5724749565124512,\n",
      "               0.5713783502578735,\n",
      "               0.5704776048660278,\n",
      "               0.569978654384613,\n",
      "               0.5692331194877625,\n",
      "               0.5684889554977417,\n",
      "               0.5676758885383606,\n",
      "               0.5672733783721924,\n",
      "               0.5670343637466431,\n",
      "               0.5668057203292847,\n",
      "               0.5666317939758301,\n",
      "               0.5665901899337769,\n",
      "               0.5664038062095642,\n",
      "               0.5662752389907837,\n",
      "               0.5662830471992493,\n",
      "               0.5663180947303772,\n",
      "               0.566271185874939,\n",
      "               0.5662677884101868,\n",
      "               0.566367506980896,\n",
      "               0.5663408637046814,\n",
      "               0.566347599029541,\n",
      "               0.566320538520813,\n",
      "               0.5663117170333862,\n",
      "               0.5663343667984009,\n",
      "               0.5662947297096252,\n",
      "               0.5662624835968018,\n",
      "               0.5662651062011719,\n",
      "               0.5662685632705688,\n",
      "               0.5662791132926941,\n",
      "               0.5662822723388672,\n",
      "               0.5662869811058044]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.9061,\n",
      "                 0.9335,\n",
      "                 0.9298,\n",
      "                 0.8917,\n",
      "                 0.6709,\n",
      "                 0.674,\n",
      "                 1.021,\n",
      "                 0.7673,\n",
      "                 0.7881,\n",
      "                 0.8472,\n",
      "                 0.8009,\n",
      "                 0.8158,\n",
      "                 0.6839,\n",
      "                 0.6885,\n",
      "                 0.7116,\n",
      "                 0.6896,\n",
      "                 0.646,\n",
      "                 0.7593,\n",
      "                 0.5717,\n",
      "                 0.6713,\n",
      "                 0.5783,\n",
      "                 0.5536,\n",
      "                 0.6208,\n",
      "                 0.6093,\n",
      "                 0.4282,\n",
      "                 0.455,\n",
      "                 0.692,\n",
      "                 0.5683,\n",
      "                 0.5794,\n",
      "                 0.6997,\n",
      "                 0.3994,\n",
      "                 0.5396,\n",
      "                 0.5881,\n",
      "                 0.5195,\n",
      "                 0.541,\n",
      "                 0.5721,\n",
      "                 0.5679,\n",
      "                 0.586,\n",
      "                 0.5298,\n",
      "                 0.5206],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5797679424285889,\n",
      "               0.5822712779045105,\n",
      "               0.5861418843269348,\n",
      "               0.5917004346847534,\n",
      "               0.5974804162979126,\n",
      "               0.603601336479187,\n",
      "               0.609832763671875,\n",
      "               0.6161621809005737,\n",
      "               0.6225857138633728,\n",
      "               0.6290246844291687,\n",
      "               0.6354631781578064,\n",
      "               0.6418336629867554,\n",
      "               0.6481572985649109,\n",
      "               0.6543235778808594,\n",
      "               0.6602845788002014,\n",
      "               0.6660873889923096,\n",
      "               0.6717370748519897,\n",
      "               0.6772491335868835,\n",
      "               0.6825137138366699,\n",
      "               0.687589168548584,\n",
      "               0.6925347447395325,\n",
      "               0.6972496509552002,\n",
      "               0.7017489075660706,\n",
      "               0.7057775855064392,\n",
      "               0.7095783948898315,\n",
      "               0.7131621837615967,\n",
      "               0.7164639234542847,\n",
      "               0.7196216583251953,\n",
      "               0.7225377559661865,\n",
      "               0.7249773144721985,\n",
      "               0.7271065711975098,\n",
      "               0.7289696931838989,\n",
      "               0.7306138873100281,\n",
      "               0.7319285273551941,\n",
      "               0.73296058177948,\n",
      "               0.7337441444396973,\n",
      "               0.7343194484710693,\n",
      "               0.7347014546394348,\n",
      "               0.7348926663398743]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.3008,\n",
      "                 0.2242,\n",
      "                 0.2885,\n",
      "                 0.2506,\n",
      "                 0.2045,\n",
      "                 0.306,\n",
      "                 0.2487,\n",
      "                 0.2467,\n",
      "                 0.2245,\n",
      "                 0.3027,\n",
      "                 0.1593,\n",
      "                 0.2386,\n",
      "                 0.1447,\n",
      "                 0.1846,\n",
      "                 0.1443,\n",
      "                 0.114,\n",
      "                 0.1551,\n",
      "                 0.228,\n",
      "                 0.1827,\n",
      "                 0.1866,\n",
      "                 0.1648,\n",
      "                 0.1597,\n",
      "                 0.1456,\n",
      "                 0.1356,\n",
      "                 0.1028,\n",
      "                 0.1479,\n",
      "                 0.0827,\n",
      "                 0.1663,\n",
      "                 0.1547,\n",
      "                 0.1025,\n",
      "                 0.1222,\n",
      "                 0.0965,\n",
      "                 0.1187,\n",
      "                 0.1706,\n",
      "                 0.1114,\n",
      "                 0.0863,\n",
      "                 0.1225,\n",
      "                 0.1267,\n",
      "                 0.1056,\n",
      "                 0.1555],\n",
      "  'val_loss': [0.5786162614822388,\n",
      "               0.5799700021743774,\n",
      "               0.5827633142471313,\n",
      "               0.5872474908828735,\n",
      "               0.5935617685317993,\n",
      "               0.6001425981521606,\n",
      "               0.6068403124809265,\n",
      "               0.6136730909347534,\n",
      "               0.6205418705940247,\n",
      "               0.6275255084037781,\n",
      "               0.6343858242034912,\n",
      "               0.6413482427597046,\n",
      "               0.6477474570274353,\n",
      "               0.6541920304298401,\n",
      "               0.6606631278991699,\n",
      "               0.6668144464492798,\n",
      "               0.6727160811424255,\n",
      "               0.6786801218986511,\n",
      "               0.6843123435974121,\n",
      "               0.6898894906044006,\n",
      "               0.6951904892921448,\n",
      "               0.700084388256073,\n",
      "               0.7047890424728394,\n",
      "               0.7092595100402832,\n",
      "               0.7136228084564209,\n",
      "               0.7177428007125854,\n",
      "               0.7211702466011047,\n",
      "               0.7244209051132202,\n",
      "               0.7274619340896606,\n",
      "               0.7299951314926147,\n",
      "               0.7323480248451233,\n",
      "               0.7341288328170776,\n",
      "               0.7357891201972961,\n",
      "               0.737131655216217,\n",
      "               0.7381026148796082,\n",
      "               0.7387844920158386,\n",
      "               0.739316463470459,\n",
      "               0.7397368550300598,\n",
      "               0.7400078773498535,\n",
      "               0.7401362657546997]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0801,\n",
      "                 0.8471,\n",
      "                 0.9416,\n",
      "                 0.7848,\n",
      "                 0.7436,\n",
      "                 1.009,\n",
      "                 0.7163,\n",
      "                 1.0185,\n",
      "                 0.5255,\n",
      "                 1.1028,\n",
      "                 0.7969,\n",
      "                 0.5798,\n",
      "                 0.9464,\n",
      "                 0.7022,\n",
      "                 0.8509,\n",
      "                 1.0642,\n",
      "                 0.7872,\n",
      "                 0.8609,\n",
      "                 0.9885,\n",
      "                 0.551,\n",
      "                 0.8014,\n",
      "                 0.8308,\n",
      "                 0.5916,\n",
      "                 0.9933,\n",
      "                 0.7971,\n",
      "                 0.6417,\n",
      "                 0.6796,\n",
      "                 0.7522,\n",
      "                 0.7722,\n",
      "                 0.6408,\n",
      "                 0.5108,\n",
      "                 0.8932,\n",
      "                 0.6292,\n",
      "                 0.7334,\n",
      "                 0.9145,\n",
      "                 0.5449,\n",
      "                 0.686,\n",
      "                 0.5679,\n",
      "                 0.9474,\n",
      "                 0.5956,\n",
      "                 0.559,\n",
      "                 0.9689,\n",
      "                 0.701,\n",
      "                 0.5424,\n",
      "                 0.5017,\n",
      "                 0.7934,\n",
      "                 0.9558,\n",
      "                 0.6161,\n",
      "                 0.7765,\n",
      "                 0.4509,\n",
      "                 0.7201,\n",
      "                 0.6087,\n",
      "                 0.6058,\n",
      "                 1.029,\n",
      "                 0.398,\n",
      "                 0.6416,\n",
      "                 0.6572,\n",
      "                 0.5809,\n",
      "                 0.6678,\n",
      "                 0.6365,\n",
      "                 0.6654,\n",
      "                 0.6407,\n",
      "                 0.6099,\n",
      "                 0.6139,\n",
      "                 0.759,\n",
      "                 0.6973,\n",
      "                 0.5485,\n",
      "                 0.6878,\n",
      "                 0.768,\n",
      "                 0.5047,\n",
      "                 0.8195,\n",
      "                 0.6061,\n",
      "                 0.8725,\n",
      "                 0.6884,\n",
      "                 0.6538,\n",
      "                 0.7252,\n",
      "                 0.6778,\n",
      "                 0.5212,\n",
      "                 0.548,\n",
      "                 0.6865],\n",
      "  'val_loss': [0.5783883333206177,\n",
      "               0.5770462155342102,\n",
      "               0.5750454068183899,\n",
      "               0.5728395581245422,\n",
      "               0.5693337917327881,\n",
      "               0.5657175779342651,\n",
      "               0.5633261203765869,\n",
      "               0.5605819225311279,\n",
      "               0.5588098168373108,\n",
      "               0.5565719604492188,\n",
      "               0.5545123815536499,\n",
      "               0.5527269840240479,\n",
      "               0.5510339736938477,\n",
      "               0.5498376488685608,\n",
      "               0.5485124588012695,\n",
      "               0.5472029447555542,\n",
      "               0.5459386706352234,\n",
      "               0.5448631048202515,\n",
      "               0.5440273284912109,\n",
      "               0.5431865453720093,\n",
      "               0.5424472689628601,\n",
      "               0.5418812036514282,\n",
      "               0.5414100885391235,\n",
      "               0.5409694910049438,\n",
      "               0.5405411720275879,\n",
      "               0.5402163863182068,\n",
      "               0.5399340391159058,\n",
      "               0.5395981073379517,\n",
      "               0.5392872095108032,\n",
      "               0.5390143394470215,\n",
      "               0.5388098955154419,\n",
      "               0.5386325120925903,\n",
      "               0.5384336113929749,\n",
      "               0.5382612943649292,\n",
      "               0.5381449460983276,\n",
      "               0.5380547642707825,\n",
      "               0.5379809141159058,\n",
      "               0.5379256010055542,\n",
      "               0.5379015207290649,\n",
      "               0.5378883481025696]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.7904,\n",
      "                 0.2797,\n",
      "                 0.8208,\n",
      "                 0.5996,\n",
      "                 0.8005,\n",
      "                 0.8473,\n",
      "                 0.6198,\n",
      "                 1.1396,\n",
      "                 0.2078,\n",
      "                 1.3826,\n",
      "                 1.0166,\n",
      "                 0.5932,\n",
      "                 0.4509,\n",
      "                 1.1815,\n",
      "                 1.1855,\n",
      "                 0.6517,\n",
      "                 0.6608,\n",
      "                 0.6326,\n",
      "                 0.7997,\n",
      "                 0.6941,\n",
      "                 0.8237,\n",
      "                 0.4221,\n",
      "                 0.9805,\n",
      "                 0.669,\n",
      "                 1.3427,\n",
      "                 0.5378,\n",
      "                 0.4551,\n",
      "                 1.1443,\n",
      "                 1.1309,\n",
      "                 0.5611,\n",
      "                 1.0434,\n",
      "                 0.4452,\n",
      "                 0.7661,\n",
      "                 0.9758,\n",
      "                 0.7382,\n",
      "                 0.8569,\n",
      "                 0.4931,\n",
      "                 0.8625,\n",
      "                 0.6968,\n",
      "                 0.5512,\n",
      "                 0.6498,\n",
      "                 0.5682,\n",
      "                 0.506,\n",
      "                 0.8684,\n",
      "                 0.2343,\n",
      "                 1.0568,\n",
      "                 1.1632,\n",
      "                 0.557,\n",
      "                 0.9087,\n",
      "                 0.3971,\n",
      "                 0.5711,\n",
      "                 0.9193,\n",
      "                 0.3424,\n",
      "                 0.8748,\n",
      "                 0.2188,\n",
      "                 1.1828,\n",
      "                 0.9605,\n",
      "                 0.2374,\n",
      "                 0.4496,\n",
      "                 0.6583,\n",
      "                 0.8908,\n",
      "                 0.3645,\n",
      "                 0.9646,\n",
      "                 0.4229,\n",
      "                 0.5501,\n",
      "                 0.6303,\n",
      "                 0.5447,\n",
      "                 0.5524,\n",
      "                 0.5545,\n",
      "                 0.6468,\n",
      "                 1.0532,\n",
      "                 0.2395,\n",
      "                 0.9785,\n",
      "                 0.3041,\n",
      "                 1.0314,\n",
      "                 0.1543,\n",
      "                 0.9586,\n",
      "                 0.4971,\n",
      "                 0.7354,\n",
      "                 0.4319],\n",
      "  'val_loss': [0.5787137746810913,\n",
      "               0.5787172317504883,\n",
      "               0.5778549313545227,\n",
      "               0.5776116251945496,\n",
      "               0.5774935483932495,\n",
      "               0.5764116048812866,\n",
      "               0.5768274664878845,\n",
      "               0.5763238072395325,\n",
      "               0.575250506401062,\n",
      "               0.5747629404067993,\n",
      "               0.574202835559845,\n",
      "               0.5736957788467407,\n",
      "               0.5726876258850098,\n",
      "               0.5724717378616333,\n",
      "               0.5717223882675171,\n",
      "               0.5716118812561035,\n",
      "               0.5714484453201294,\n",
      "               0.5712157487869263,\n",
      "               0.57085782289505,\n",
      "               0.5707944631576538,\n",
      "               0.5703862905502319,\n",
      "               0.5697869658470154,\n",
      "               0.56963050365448,\n",
      "               0.5694482922554016,\n",
      "               0.5693435668945312,\n",
      "               0.5692683458328247,\n",
      "               0.5693880915641785,\n",
      "               0.5693005323410034,\n",
      "               0.5690656900405884,\n",
      "               0.5689005851745605,\n",
      "               0.568759560585022,\n",
      "               0.5686525106430054,\n",
      "               0.5685478448867798,\n",
      "               0.5685067176818848,\n",
      "               0.5683801770210266,\n",
      "               0.5682851076126099,\n",
      "               0.5682223439216614,\n",
      "               0.5681888461112976,\n",
      "               0.5681723356246948,\n",
      "               0.5681737661361694]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.2111,\n",
      "                 1.0487,\n",
      "                 0.5666,\n",
      "                 0.555,\n",
      "                 0.5587,\n",
      "                 0.5119,\n",
      "                 0.7055,\n",
      "                 0.5815,\n",
      "                 0.9531,\n",
      "                 0.3047,\n",
      "                 0.8877,\n",
      "                 0.279,\n",
      "                 0.6067,\n",
      "                 0.4928,\n",
      "                 0.5542,\n",
      "                 0.515,\n",
      "                 0.5177,\n",
      "                 0.6855,\n",
      "                 0.5596,\n",
      "                 0.7486,\n",
      "                 0.5314,\n",
      "                 0.6221,\n",
      "                 0.4983,\n",
      "                 0.5321,\n",
      "                 0.5625,\n",
      "                 0.3717,\n",
      "                 0.4288,\n",
      "                 0.3902,\n",
      "                 0.2606,\n",
      "                 0.674,\n",
      "                 0.4707,\n",
      "                 0.355,\n",
      "                 0.7312,\n",
      "                 0.2878,\n",
      "                 0.2025,\n",
      "                 0.7718,\n",
      "                 0.5695,\n",
      "                 0.3719,\n",
      "                 0.5539,\n",
      "                 0.4308,\n",
      "                 0.7133,\n",
      "                 0.2402,\n",
      "                 0.3123,\n",
      "                 0.6801,\n",
      "                 0.651,\n",
      "                 0.275,\n",
      "                 0.3876,\n",
      "                 0.4128,\n",
      "                 0.4123,\n",
      "                 0.4267,\n",
      "                 0.1444,\n",
      "                 1.0573,\n",
      "                 0.5094,\n",
      "                 0.3324,\n",
      "                 0.5713,\n",
      "                 0.2208,\n",
      "                 0.2466,\n",
      "                 0.7331,\n",
      "                 0.497,\n",
      "                 0.2702,\n",
      "                 0.6156,\n",
      "                 0.4065,\n",
      "                 0.5392,\n",
      "                 0.4608,\n",
      "                 0.8002,\n",
      "                 0.3159,\n",
      "                 0.6276,\n",
      "                 0.1339,\n",
      "                 0.6804,\n",
      "                 0.1578,\n",
      "                 0.4562,\n",
      "                 0.3829,\n",
      "                 0.226,\n",
      "                 0.5884,\n",
      "                 0.1652,\n",
      "                 0.826,\n",
      "                 0.2258,\n",
      "                 0.5523,\n",
      "                 0.2864,\n",
      "                 0.4692],\n",
      "  'val_loss': [0.5785096287727356,\n",
      "               0.5774437785148621,\n",
      "               0.5749713778495789,\n",
      "               0.572462260723114,\n",
      "               0.5687850117683411,\n",
      "               0.5660665035247803,\n",
      "               0.5632068514823914,\n",
      "               0.5606988072395325,\n",
      "               0.558564305305481,\n",
      "               0.5566977262496948,\n",
      "               0.5552513599395752,\n",
      "               0.5544031262397766,\n",
      "               0.5535899996757507,\n",
      "               0.5532512664794922,\n",
      "               0.5527620315551758,\n",
      "               0.552424430847168,\n",
      "               0.5521558523178101,\n",
      "               0.5519608855247498,\n",
      "               0.5517479181289673,\n",
      "               0.5514118075370789,\n",
      "               0.5511879920959473,\n",
      "               0.5508326292037964,\n",
      "               0.5507178902626038,\n",
      "               0.5506576895713806,\n",
      "               0.550698459148407,\n",
      "               0.5507410764694214,\n",
      "               0.5507915019989014,\n",
      "               0.550659716129303,\n",
      "               0.5507076978683472,\n",
      "               0.5507979393005371,\n",
      "               0.5509368777275085,\n",
      "               0.5510531663894653,\n",
      "               0.5510574579238892,\n",
      "               0.5510658025741577,\n",
      "               0.5510357022285461,\n",
      "               0.5510414838790894,\n",
      "               0.5510430335998535,\n",
      "               0.5510540008544922,\n",
      "               0.5510408282279968,\n",
      "               0.5510409474372864]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.1216,\n",
      "                 0.6479,\n",
      "                 1.042,\n",
      "                 0.7361,\n",
      "                 0.8576,\n",
      "                 0.6509,\n",
      "                 0.3798,\n",
      "                 1.1896,\n",
      "                 0.7696,\n",
      "                 0.6152,\n",
      "                 0.6268,\n",
      "                 0.6341,\n",
      "                 0.6245,\n",
      "                 0.6114,\n",
      "                 0.9778,\n",
      "                 0.6609,\n",
      "                 0.4362,\n",
      "                 0.8884,\n",
      "                 0.6734,\n",
      "                 0.6142,\n",
      "                 0.5839,\n",
      "                 0.6608,\n",
      "                 0.6397,\n",
      "                 0.4246,\n",
      "                 0.8443,\n",
      "                 0.4267,\n",
      "                 0.1822,\n",
      "                 0.7745,\n",
      "                 0.9558,\n",
      "                 0.2415,\n",
      "                 0.4961,\n",
      "                 0.6803,\n",
      "                 0.5619,\n",
      "                 0.6244,\n",
      "                 0.4638,\n",
      "                 0.7205,\n",
      "                 0.3264,\n",
      "                 0.683,\n",
      "                 0.3296,\n",
      "                 0.5756,\n",
      "                 0.4569,\n",
      "                 0.2778,\n",
      "                 0.3609,\n",
      "                 0.4309,\n",
      "                 0.2377,\n",
      "                 0.4959,\n",
      "                 0.7376,\n",
      "                 0.3469,\n",
      "                 0.7245,\n",
      "                 0.1297,\n",
      "                 0.4001,\n",
      "                 0.7646,\n",
      "                 0.224,\n",
      "                 0.5414,\n",
      "                 0.1551,\n",
      "                 0.5516,\n",
      "                 0.6169,\n",
      "                 0.1893,\n",
      "                 0.3419,\n",
      "                 0.4453,\n",
      "                 0.5999,\n",
      "                 0.1612,\n",
      "                 0.5872,\n",
      "                 0.1478,\n",
      "                 0.2278,\n",
      "                 0.6858,\n",
      "                 0.4124,\n",
      "                 0.34,\n",
      "                 0.2491,\n",
      "                 0.6432,\n",
      "                 0.632,\n",
      "                 0.1885,\n",
      "                 0.7312,\n",
      "                 0.1977,\n",
      "                 0.5497,\n",
      "                 0.3554,\n",
      "                 0.5722,\n",
      "                 0.1532,\n",
      "                 0.2458,\n",
      "                 0.6545],\n",
      "  'val_loss': [0.5793054699897766,\n",
      "               0.5826418995857239,\n",
      "               0.5892692804336548,\n",
      "               0.6002715229988098,\n",
      "               0.6152063608169556,\n",
      "               0.6308093070983887,\n",
      "               0.6477961540222168,\n",
      "               0.6645044088363647,\n",
      "               0.6824002265930176,\n",
      "               0.7000877261161804,\n",
      "               0.7161005735397339,\n",
      "               0.7314386367797852,\n",
      "               0.7469552755355835,\n",
      "               0.7637687921524048,\n",
      "               0.7800359725952148,\n",
      "               0.7943663597106934,\n",
      "               0.8086406588554382,\n",
      "               0.8214396238327026,\n",
      "               0.8332405090332031,\n",
      "               0.844325840473175,\n",
      "               0.8540140986442566,\n",
      "               0.8648513555526733,\n",
      "               0.876078724861145,\n",
      "               0.8864768147468567,\n",
      "               0.8971912264823914,\n",
      "               0.9079378247261047,\n",
      "               0.9176069498062134,\n",
      "               0.926439642906189,\n",
      "               0.9342538118362427,\n",
      "               0.9417799115180969,\n",
      "               0.9476833343505859,\n",
      "               0.9535294771194458,\n",
      "               0.9589496850967407,\n",
      "               0.9627043604850769,\n",
      "               0.9663143157958984,\n",
      "               0.9691034555435181,\n",
      "               0.9714586138725281,\n",
      "               0.973068356513977,\n",
      "               0.974215030670166,\n",
      "               0.9747591018676758]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.9467,\n",
      "                 0.6664,\n",
      "                 0.8249,\n",
      "                 0.945,\n",
      "                 0.6035,\n",
      "                 1.2697,\n",
      "                 0.6753,\n",
      "                 0.9659,\n",
      "                 0.7804,\n",
      "                 1.2855,\n",
      "                 0.8739,\n",
      "                 0.6289,\n",
      "                 0.7671,\n",
      "                 0.8752,\n",
      "                 0.8095,\n",
      "                 0.8805,\n",
      "                 1.0979,\n",
      "                 0.8452,\n",
      "                 0.8026,\n",
      "                 0.8599,\n",
      "                 0.559,\n",
      "                 0.7445,\n",
      "                 0.8251,\n",
      "                 0.7017,\n",
      "                 1.0583,\n",
      "                 0.5564,\n",
      "                 0.6921,\n",
      "                 0.8435,\n",
      "                 0.7704,\n",
      "                 0.7912,\n",
      "                 0.7728,\n",
      "                 0.7177,\n",
      "                 0.8352,\n",
      "                 0.6366,\n",
      "                 0.7207,\n",
      "                 0.7135,\n",
      "                 0.5671,\n",
      "                 0.7392,\n",
      "                 0.7308,\n",
      "                 0.7154,\n",
      "                 0.806,\n",
      "                 0.7143,\n",
      "                 0.5816,\n",
      "                 0.5401,\n",
      "                 0.5942,\n",
      "                 0.6904,\n",
      "                 0.6896,\n",
      "                 0.7514,\n",
      "                 0.6595,\n",
      "                 0.4768,\n",
      "                 0.4884,\n",
      "                 0.9013,\n",
      "                 0.926,\n",
      "                 0.6032,\n",
      "                 0.484,\n",
      "                 0.6152,\n",
      "                 0.6877,\n",
      "                 0.5034,\n",
      "                 0.7167,\n",
      "                 0.6119,\n",
      "                 0.832,\n",
      "                 0.6664,\n",
      "                 0.6371,\n",
      "                 0.664,\n",
      "                 0.8205,\n",
      "                 0.4968,\n",
      "                 0.6567,\n",
      "                 0.5154,\n",
      "                 0.6918,\n",
      "                 0.6482,\n",
      "                 0.5154,\n",
      "                 0.5343,\n",
      "                 0.7355,\n",
      "                 0.5829,\n",
      "                 0.7655,\n",
      "                 0.4793,\n",
      "                 0.5465,\n",
      "                 0.7221,\n",
      "                 0.73,\n",
      "                 0.4966],\n",
      "  'val_loss': [0.5791244506835938,\n",
      "               0.5805330872535706,\n",
      "               0.5826693177223206,\n",
      "               0.5862412452697754,\n",
      "               0.5894670486450195,\n",
      "               0.5933355093002319,\n",
      "               0.5950673222541809,\n",
      "               0.5976178050041199,\n",
      "               0.6009097099304199,\n",
      "               0.6028248071670532,\n",
      "               0.6048263907432556,\n",
      "               0.608027458190918,\n",
      "               0.6117216944694519,\n",
      "               0.6151341199874878,\n",
      "               0.6193622350692749,\n",
      "               0.6234857439994812,\n",
      "               0.6281384229660034,\n",
      "               0.6328392028808594,\n",
      "               0.6375553011894226,\n",
      "               0.6415260434150696,\n",
      "               0.6456994414329529,\n",
      "               0.649679958820343,\n",
      "               0.6523626446723938,\n",
      "               0.6553232073783875,\n",
      "               0.6571677327156067,\n",
      "               0.6591503024101257,\n",
      "               0.6606415510177612,\n",
      "               0.6619156002998352,\n",
      "               0.663190484046936,\n",
      "               0.6642781496047974,\n",
      "               0.6653875708580017,\n",
      "               0.6663068532943726,\n",
      "               0.66680508852005,\n",
      "               0.667236328125,\n",
      "               0.66766756772995,\n",
      "               0.6679442524909973,\n",
      "               0.6681863069534302,\n",
      "               0.6683721542358398,\n",
      "               0.6685755252838135,\n",
      "               0.6686495542526245]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.3117,\n",
      "                 1.0857,\n",
      "                 0.5532,\n",
      "                 0.6514,\n",
      "                 0.6515,\n",
      "                 0.8039,\n",
      "                 0.847,\n",
      "                 0.5811,\n",
      "                 0.7381,\n",
      "                 0.8013,\n",
      "                 0.6507,\n",
      "                 0.6917,\n",
      "                 0.838,\n",
      "                 0.3864,\n",
      "                 0.6603,\n",
      "                 0.7163,\n",
      "                 0.8344,\n",
      "                 0.5664,\n",
      "                 0.3735,\n",
      "                 0.7241,\n",
      "                 0.4086,\n",
      "                 0.8307,\n",
      "                 0.2994,\n",
      "                 0.5775,\n",
      "                 0.6998,\n",
      "                 0.4293,\n",
      "                 0.7365,\n",
      "                 0.3502,\n",
      "                 0.368,\n",
      "                 0.7439,\n",
      "                 0.3224,\n",
      "                 0.6168,\n",
      "                 0.5942,\n",
      "                 0.5186,\n",
      "                 0.6572,\n",
      "                 0.3902,\n",
      "                 0.6167,\n",
      "                 0.3118,\n",
      "                 0.5132,\n",
      "                 0.4506,\n",
      "                 0.3777,\n",
      "                 0.6025,\n",
      "                 0.5493,\n",
      "                 0.3708,\n",
      "                 0.4086,\n",
      "                 0.4529,\n",
      "                 0.5192,\n",
      "                 0.389,\n",
      "                 0.4875,\n",
      "                 0.399,\n",
      "                 0.5808,\n",
      "                 0.4143,\n",
      "                 0.4944,\n",
      "                 0.4011,\n",
      "                 0.3842,\n",
      "                 0.3344,\n",
      "                 0.4116,\n",
      "                 0.5274,\n",
      "                 0.397,\n",
      "                 0.4918,\n",
      "                 0.4091,\n",
      "                 0.4945,\n",
      "                 0.3513,\n",
      "                 0.5564,\n",
      "                 0.3587,\n",
      "                 0.4325,\n",
      "                 0.3411,\n",
      "                 0.4674,\n",
      "                 0.4063,\n",
      "                 0.3301,\n",
      "                 0.3964,\n",
      "                 0.3963,\n",
      "                 0.3849,\n",
      "                 0.4179,\n",
      "                 0.4017,\n",
      "                 0.5566,\n",
      "                 0.4881,\n",
      "                 0.3154,\n",
      "                 0.4259,\n",
      "                 0.3234],\n",
      "  'val_loss': [0.5784996151924133,\n",
      "               0.5769017338752747,\n",
      "               0.5733379125595093,\n",
      "               0.5678485035896301,\n",
      "               0.5620083808898926,\n",
      "               0.557237982749939,\n",
      "               0.5538392663002014,\n",
      "               0.5511223077774048,\n",
      "               0.5488883256912231,\n",
      "               0.5475606322288513,\n",
      "               0.5466731786727905,\n",
      "               0.5462222695350647,\n",
      "               0.5461148023605347,\n",
      "               0.546237587928772,\n",
      "               0.5465388894081116,\n",
      "               0.5467397570610046,\n",
      "               0.5470194816589355,\n",
      "               0.5474444627761841,\n",
      "               0.5479879975318909,\n",
      "               0.5486757159233093,\n",
      "               0.5493601560592651,\n",
      "               0.5499369502067566,\n",
      "               0.55042964220047,\n",
      "               0.5510320663452148,\n",
      "               0.551445484161377,\n",
      "               0.5517142415046692,\n",
      "               0.5519464015960693,\n",
      "               0.552127480506897,\n",
      "               0.552039384841919,\n",
      "               0.5519803762435913,\n",
      "               0.5519084930419922,\n",
      "               0.5519031286239624,\n",
      "               0.5518544316291809,\n",
      "               0.5518239736557007,\n",
      "               0.5517838597297668,\n",
      "               0.5517242550849915,\n",
      "               0.5516539812088013,\n",
      "               0.5515996217727661,\n",
      "               0.5515998601913452,\n",
      "               0.55158531665802]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [1.0543,\n",
      "                 0.4941,\n",
      "                 1.0485,\n",
      "                 0.7587,\n",
      "                 0.8629,\n",
      "                 0.8942,\n",
      "                 1.2001,\n",
      "                 0.6835,\n",
      "                 0.755,\n",
      "                 0.982,\n",
      "                 0.441,\n",
      "                 1.1392,\n",
      "                 0.9215,\n",
      "                 0.9304,\n",
      "                 1.0439,\n",
      "                 0.7985,\n",
      "                 1.2056,\n",
      "                 0.5569,\n",
      "                 1.0002,\n",
      "                 0.579,\n",
      "                 0.7057,\n",
      "                 0.886,\n",
      "                 0.4041,\n",
      "                 0.9112,\n",
      "                 0.6689,\n",
      "                 0.7653,\n",
      "                 0.7691,\n",
      "                 0.6883,\n",
      "                 0.8498,\n",
      "                 0.8838,\n",
      "                 0.8221,\n",
      "                 0.6606,\n",
      "                 0.544,\n",
      "                 0.9697,\n",
      "                 0.7424,\n",
      "                 0.6124,\n",
      "                 0.5781,\n",
      "                 0.7986,\n",
      "                 0.7627,\n",
      "                 0.5468,\n",
      "                 0.5577,\n",
      "                 0.6431,\n",
      "                 0.8062,\n",
      "                 0.549,\n",
      "                 0.6905,\n",
      "                 0.6893,\n",
      "                 0.6699,\n",
      "                 0.7278,\n",
      "                 0.3753,\n",
      "                 0.8327,\n",
      "                 0.779,\n",
      "                 0.5141,\n",
      "                 0.6074,\n",
      "                 0.5639,\n",
      "                 0.5381,\n",
      "                 0.7436,\n",
      "                 0.6782,\n",
      "                 0.5727,\n",
      "                 0.825,\n",
      "                 0.3633,\n",
      "                 0.3935,\n",
      "                 0.6669,\n",
      "                 0.4652,\n",
      "                 0.6863,\n",
      "                 0.6232,\n",
      "                 0.5775,\n",
      "                 0.5101,\n",
      "                 0.6575,\n",
      "                 0.5867,\n",
      "                 0.6397,\n",
      "                 0.5144,\n",
      "                 0.5112,\n",
      "                 0.559,\n",
      "                 0.5892,\n",
      "                 0.5722,\n",
      "                 0.6262,\n",
      "                 0.6394,\n",
      "                 0.6374,\n",
      "                 0.4928,\n",
      "                 0.5077],\n",
      "  'val_loss': [0.5782836675643921,\n",
      "               0.576705813407898,\n",
      "               0.5743061900138855,\n",
      "               0.5705444812774658,\n",
      "               0.567268967628479,\n",
      "               0.5648439526557922,\n",
      "               0.5619513392448425,\n",
      "               0.5592223405838013,\n",
      "               0.5571550130844116,\n",
      "               0.5550898909568787,\n",
      "               0.5529980063438416,\n",
      "               0.5513125061988831,\n",
      "               0.5495955348014832,\n",
      "               0.5480769872665405,\n",
      "               0.5468581318855286,\n",
      "               0.5455594062805176,\n",
      "               0.5446735620498657,\n",
      "               0.5438297986984253,\n",
      "               0.5432451963424683,\n",
      "               0.5427279472351074,\n",
      "               0.5422325730323792,\n",
      "               0.541899561882019,\n",
      "               0.5417254567146301,\n",
      "               0.5415740609169006,\n",
      "               0.5414237976074219,\n",
      "               0.5411828756332397,\n",
      "               0.5409782528877258,\n",
      "               0.5407362580299377,\n",
      "               0.5404835343360901,\n",
      "               0.5402385592460632,\n",
      "               0.5400265455245972,\n",
      "               0.5398011207580566,\n",
      "               0.5396102666854858,\n",
      "               0.5394682288169861,\n",
      "               0.5393749475479126,\n",
      "               0.5393258929252625,\n",
      "               0.5393036603927612,\n",
      "               0.5392935872077942,\n",
      "               0.539271354675293,\n",
      "               0.5392600893974304]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.9161,\n",
      "                 0.5768,\n",
      "                 1.3496,\n",
      "                 0.1111,\n",
      "                 0.9321,\n",
      "                 0.4178,\n",
      "                 0.7113,\n",
      "                 0.92,\n",
      "                 0.5914,\n",
      "                 0.8194,\n",
      "                 0.6592,\n",
      "                 0.5961,\n",
      "                 0.7935,\n",
      "                 0.4305,\n",
      "                 1.0001,\n",
      "                 0.2065,\n",
      "                 0.2435,\n",
      "                 0.8401,\n",
      "                 0.6154,\n",
      "                 0.3123,\n",
      "                 0.8705,\n",
      "                 0.2578,\n",
      "                 0.5098,\n",
      "                 0.4755,\n",
      "                 0.5987,\n",
      "                 0.317,\n",
      "                 0.3285,\n",
      "                 0.5206,\n",
      "                 0.4083,\n",
      "                 0.4772,\n",
      "                 0.4267,\n",
      "                 0.481,\n",
      "                 0.5637,\n",
      "                 0.6158,\n",
      "                 0.3953,\n",
      "                 0.4203,\n",
      "                 0.2746,\n",
      "                 0.6449,\n",
      "                 0.4764,\n",
      "                 0.4034,\n",
      "                 0.5155,\n",
      "                 0.4321,\n",
      "                 0.3752,\n",
      "                 0.4721,\n",
      "                 0.3505,\n",
      "                 0.2715,\n",
      "                 0.3974,\n",
      "                 0.3367,\n",
      "                 0.4891,\n",
      "                 0.2716,\n",
      "                 0.3245,\n",
      "                 0.5374,\n",
      "                 0.3806,\n",
      "                 0.3944,\n",
      "                 0.2766,\n",
      "                 0.5088,\n",
      "                 0.343,\n",
      "                 0.203,\n",
      "                 0.3308,\n",
      "                 0.3767,\n",
      "                 0.387,\n",
      "                 0.3671,\n",
      "                 0.2278,\n",
      "                 0.3536,\n",
      "                 0.2859,\n",
      "                 0.2457,\n",
      "                 0.3618,\n",
      "                 0.225,\n",
      "                 0.2664,\n",
      "                 0.2608,\n",
      "                 0.4571,\n",
      "                 0.1797,\n",
      "                 0.3849,\n",
      "                 0.4032,\n",
      "                 0.2952,\n",
      "                 0.2583,\n",
      "                 0.3478,\n",
      "                 0.3062,\n",
      "                 0.258,\n",
      "                 0.2601],\n",
      "  'val_loss': [0.5779376029968262,\n",
      "               0.5756717324256897,\n",
      "               0.5723026394844055,\n",
      "               0.5672307014465332,\n",
      "               0.5613620281219482,\n",
      "               0.5560632944107056,\n",
      "               0.5518220663070679,\n",
      "               0.549026370048523,\n",
      "               0.5470854043960571,\n",
      "               0.5456595420837402,\n",
      "               0.5449053049087524,\n",
      "               0.5443347096443176,\n",
      "               0.5444072484970093,\n",
      "               0.5446910262107849,\n",
      "               0.5449047088623047,\n",
      "               0.5453112125396729,\n",
      "               0.5458964109420776,\n",
      "               0.5466569066047668,\n",
      "               0.5473805069923401,\n",
      "               0.548524022102356,\n",
      "               0.5498546361923218,\n",
      "               0.5511453747749329,\n",
      "               0.5526058077812195,\n",
      "               0.5541540384292603,\n",
      "               0.5554930567741394,\n",
      "               0.5565279126167297,\n",
      "               0.5574636459350586,\n",
      "               0.5585756301879883,\n",
      "               0.5595743060112,\n",
      "               0.5605905652046204,\n",
      "               0.5613376498222351,\n",
      "               0.5619470477104187,\n",
      "               0.5625702142715454,\n",
      "               0.563052773475647,\n",
      "               0.5633876323699951,\n",
      "               0.5637367963790894,\n",
      "               0.5639753341674805,\n",
      "               0.5642217397689819,\n",
      "               0.5643370747566223,\n",
      "               0.5643805265426636]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.8689,\n",
      "                 0.7273,\n",
      "                 0.6969,\n",
      "                 1.1246,\n",
      "                 0.9118,\n",
      "                 0.8605,\n",
      "                 0.643,\n",
      "                 0.7272,\n",
      "                 0.6173,\n",
      "                 1.0646,\n",
      "                 0.509,\n",
      "                 0.9274,\n",
      "                 1.272,\n",
      "                 0.4471,\n",
      "                 0.7901,\n",
      "                 0.9147,\n",
      "                 0.6045,\n",
      "                 0.9644,\n",
      "                 0.9292,\n",
      "                 0.6733,\n",
      "                 0.5553,\n",
      "                 0.9012,\n",
      "                 0.8151,\n",
      "                 0.7172,\n",
      "                 0.8297,\n",
      "                 0.7397,\n",
      "                 0.8224,\n",
      "                 0.4003,\n",
      "                 0.7274,\n",
      "                 0.9305,\n",
      "                 0.748,\n",
      "                 0.882,\n",
      "                 0.5408,\n",
      "                 0.7233,\n",
      "                 0.8972,\n",
      "                 0.3866,\n",
      "                 0.7809,\n",
      "                 0.7957,\n",
      "                 0.9343,\n",
      "                 0.4707,\n",
      "                 0.2872,\n",
      "                 0.9141,\n",
      "                 0.6101,\n",
      "                 0.6676,\n",
      "                 0.4871,\n",
      "                 1.0001,\n",
      "                 0.5933,\n",
      "                 0.7343,\n",
      "                 0.5965,\n",
      "                 0.5578,\n",
      "                 0.6511,\n",
      "                 0.8766,\n",
      "                 0.9341,\n",
      "                 0.4616,\n",
      "                 0.4164,\n",
      "                 0.6319,\n",
      "                 1.059,\n",
      "                 0.4996,\n",
      "                 0.3947,\n",
      "                 0.8532,\n",
      "                 0.5605,\n",
      "                 0.714,\n",
      "                 0.5564,\n",
      "                 0.6426,\n",
      "                 0.4606,\n",
      "                 0.7244,\n",
      "                 0.7154,\n",
      "                 0.572,\n",
      "                 0.4581,\n",
      "                 0.7498,\n",
      "                 0.6717,\n",
      "                 0.583,\n",
      "                 0.8369,\n",
      "                 0.5375,\n",
      "                 0.7412,\n",
      "                 0.7018,\n",
      "                 0.5339,\n",
      "                 0.5993,\n",
      "                 0.7299,\n",
      "                 0.4157],\n",
      "  'val_loss': [0.5787720680236816,\n",
      "               0.5793924331665039,\n",
      "               0.5807485580444336,\n",
      "               0.5805489420890808,\n",
      "               0.5816988945007324,\n",
      "               0.5824995040893555,\n",
      "               0.5828043818473816,\n",
      "               0.5835694074630737,\n",
      "               0.585654616355896,\n",
      "               0.5877941846847534,\n",
      "               0.5898948907852173,\n",
      "               0.5924933552742004,\n",
      "               0.5952752828598022,\n",
      "               0.5975232124328613,\n",
      "               0.6003926992416382,\n",
      "               0.6020575761795044,\n",
      "               0.604408860206604,\n",
      "               0.6055701971054077,\n",
      "               0.6074093580245972,\n",
      "               0.6082856059074402,\n",
      "               0.6090485453605652,\n",
      "               0.6096583604812622,\n",
      "               0.6102770566940308,\n",
      "               0.6103123426437378,\n",
      "               0.6107471585273743,\n",
      "               0.6110824942588806,\n",
      "               0.6108903884887695,\n",
      "               0.6114917397499084,\n",
      "               0.6119049191474915,\n",
      "               0.6124753355979919,\n",
      "               0.6128823161125183,\n",
      "               0.6132192611694336,\n",
      "               0.6135061383247375,\n",
      "               0.6134389042854309,\n",
      "               0.6136244535446167,\n",
      "               0.613634467124939,\n",
      "               0.6136257648468018,\n",
      "               0.6136183142662048,\n",
      "               0.6136186718940735,\n",
      "               0.6136420369148254]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 8,\n",
      "  'train_loss': [0.4051,\n",
      "                 0.8056,\n",
      "                 0.5854,\n",
      "                 0.6314,\n",
      "                 0.6659,\n",
      "                 0.2996,\n",
      "                 0.2868,\n",
      "                 0.8864,\n",
      "                 0.6019,\n",
      "                 0.2175,\n",
      "                 0.4646,\n",
      "                 0.3758,\n",
      "                 0.4172,\n",
      "                 0.3826,\n",
      "                 0.3822,\n",
      "                 0.3791,\n",
      "                 0.3015,\n",
      "                 0.4519,\n",
      "                 0.3068,\n",
      "                 0.3108,\n",
      "                 0.3408,\n",
      "                 0.2803,\n",
      "                 0.4497,\n",
      "                 0.2646,\n",
      "                 0.2469,\n",
      "                 0.2111,\n",
      "                 0.2691,\n",
      "                 0.3791,\n",
      "                 0.3158,\n",
      "                 0.3414,\n",
      "                 0.2061,\n",
      "                 0.3027,\n",
      "                 0.3483,\n",
      "                 0.2007,\n",
      "                 0.1897,\n",
      "                 0.3666,\n",
      "                 0.2103,\n",
      "                 0.3386,\n",
      "                 0.2127,\n",
      "                 0.408,\n",
      "                 0.2708,\n",
      "                 0.2221,\n",
      "                 0.2076,\n",
      "                 0.2926,\n",
      "                 0.2125,\n",
      "                 0.1813,\n",
      "                 0.2026,\n",
      "                 0.1994,\n",
      "                 0.2722,\n",
      "                 0.1325,\n",
      "                 0.1868,\n",
      "                 0.2923,\n",
      "                 0.2077,\n",
      "                 0.2319,\n",
      "                 0.2393,\n",
      "                 0.2849,\n",
      "                 0.2186,\n",
      "                 0.2742,\n",
      "                 0.2945,\n",
      "                 0.1695,\n",
      "                 0.2987,\n",
      "                 0.166,\n",
      "                 0.3429,\n",
      "                 0.1759,\n",
      "                 0.2134,\n",
      "                 0.2066,\n",
      "                 0.3275,\n",
      "                 0.1127,\n",
      "                 0.1826,\n",
      "                 0.2748,\n",
      "                 0.1896,\n",
      "                 0.2453,\n",
      "                 0.2296,\n",
      "                 0.148,\n",
      "                 0.1575,\n",
      "                 0.2561,\n",
      "                 0.257,\n",
      "                 0.2659,\n",
      "                 0.1646,\n",
      "                 0.2216],\n",
      "  'val_loss': [0.5780311822891235,\n",
      "               0.5752614736557007,\n",
      "               0.5705880522727966,\n",
      "               0.5644168853759766,\n",
      "               0.5583264231681824,\n",
      "               0.5540834069252014,\n",
      "               0.550629734992981,\n",
      "               0.5481280088424683,\n",
      "               0.5466073155403137,\n",
      "               0.5456522703170776,\n",
      "               0.5451794862747192,\n",
      "               0.5451600551605225,\n",
      "               0.5455259084701538,\n",
      "               0.545969545841217,\n",
      "               0.5466097593307495,\n",
      "               0.5472065210342407,\n",
      "               0.5478866696357727,\n",
      "               0.5486540198326111,\n",
      "               0.549595296382904,\n",
      "               0.5505213737487793,\n",
      "               0.551247775554657,\n",
      "               0.5521230101585388,\n",
      "               0.5527281761169434,\n",
      "               0.5531514883041382,\n",
      "               0.5535850524902344,\n",
      "               0.553988516330719,\n",
      "               0.5541784763336182,\n",
      "               0.554519534111023,\n",
      "               0.5548943877220154,\n",
      "               0.5553098917007446,\n",
      "               0.555453360080719,\n",
      "               0.5555708408355713,\n",
      "               0.5556402206420898,\n",
      "               0.5555750131607056,\n",
      "               0.5556483268737793,\n",
      "               0.5557114481925964,\n",
      "               0.5557661056518555,\n",
      "               0.5558422207832336,\n",
      "               0.5558959245681763,\n",
      "               0.5559195280075073]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.6644,\n",
      "                 0.6753,\n",
      "                 1.1453,\n",
      "                 0.53,\n",
      "                 1.3425,\n",
      "                 0.5516,\n",
      "                 0.3486,\n",
      "                 1.5213,\n",
      "                 0.6568,\n",
      "                 0.818,\n",
      "                 0.4727,\n",
      "                 0.7533,\n",
      "                 2.1807,\n",
      "                 0.6722,\n",
      "                 1.3624,\n",
      "                 0.6889,\n",
      "                 0.8963,\n",
      "                 0.7825,\n",
      "                 0.5514,\n",
      "                 1.6817,\n",
      "                 0.7975,\n",
      "                 1.8742,\n",
      "                 0.588,\n",
      "                 0.6017,\n",
      "                 0.9169,\n",
      "                 0.6246,\n",
      "                 1.4478,\n",
      "                 1.0469,\n",
      "                 0.3084,\n",
      "                 0.759,\n",
      "                 1.0087,\n",
      "                 1.1599,\n",
      "                 0.4781,\n",
      "                 1.0318,\n",
      "                 0.6522,\n",
      "                 1.971,\n",
      "                 1.6524,\n",
      "                 0.5981,\n",
      "                 1.4554,\n",
      "                 0.4086,\n",
      "                 1.3861,\n",
      "                 0.9276,\n",
      "                 1.4016,\n",
      "                 0.5012,\n",
      "                 0.8839,\n",
      "                 0.5847,\n",
      "                 0.5938,\n",
      "                 2.4629,\n",
      "                 1.1239,\n",
      "                 1.1176,\n",
      "                 1.3098,\n",
      "                 0.5166,\n",
      "                 0.8261,\n",
      "                 0.4805,\n",
      "                 1.701,\n",
      "                 0.6377,\n",
      "                 0.9984,\n",
      "                 0.7547,\n",
      "                 1.4009,\n",
      "                 0.7085,\n",
      "                 0.8495,\n",
      "                 0.2589,\n",
      "                 1.4436,\n",
      "                 0.9412,\n",
      "                 0.7118,\n",
      "                 0.5365,\n",
      "                 0.615,\n",
      "                 1.8415,\n",
      "                 0.8293,\n",
      "                 0.7981,\n",
      "                 0.9046,\n",
      "                 0.7244,\n",
      "                 0.2618,\n",
      "                 0.4758,\n",
      "                 0.8126,\n",
      "                 1.1473,\n",
      "                 0.7178,\n",
      "                 0.9618,\n",
      "                 1.859,\n",
      "                 0.7803,\n",
      "                 1.1883,\n",
      "                 0.2181,\n",
      "                 1.2315,\n",
      "                 1.6982,\n",
      "                 0.6572,\n",
      "                 0.9859,\n",
      "                 0.5798,\n",
      "                 1.0126,\n",
      "                 0.6034,\n",
      "                 0.9389,\n",
      "                 1.0719,\n",
      "                 0.7503,\n",
      "                 0.4118,\n",
      "                 1.116,\n",
      "                 0.8317,\n",
      "                 1.4923,\n",
      "                 0.5564,\n",
      "                 0.5193,\n",
      "                 0.8552,\n",
      "                 0.983,\n",
      "                 0.9062,\n",
      "                 1.0507,\n",
      "                 1.3929,\n",
      "                 0.6452,\n",
      "                 1.0137,\n",
      "                 0.5839,\n",
      "                 1.7654,\n",
      "                 0.5627,\n",
      "                 0.3693,\n",
      "                 1.9394,\n",
      "                 0.6183,\n",
      "                 0.9161,\n",
      "                 0.5815,\n",
      "                 0.4906,\n",
      "                 0.5781,\n",
      "                 1.1648,\n",
      "                 1.6441,\n",
      "                 0.6778,\n",
      "                 1.2049,\n",
      "                 0.4403,\n",
      "                 0.8477,\n",
      "                 0.9033,\n",
      "                 1.7995,\n",
      "                 0.5223,\n",
      "                 0.9502,\n",
      "                 1.0549,\n",
      "                 0.4218,\n",
      "                 0.7645,\n",
      "                 0.9655,\n",
      "                 0.8312,\n",
      "                 0.6757,\n",
      "                 0.5766,\n",
      "                 1.415,\n",
      "                 1.2218,\n",
      "                 0.7253,\n",
      "                 0.3715,\n",
      "                 0.2074,\n",
      "                 0.756,\n",
      "                 0.7299,\n",
      "                 0.5795,\n",
      "                 0.704,\n",
      "                 1.4542,\n",
      "                 0.7952,\n",
      "                 1.3315,\n",
      "                 0.9581,\n",
      "                 0.4866,\n",
      "                 0.6219,\n",
      "                 1.1068,\n",
      "                 0.8363,\n",
      "                 0.8509,\n",
      "                 0.5444,\n",
      "                 1.3423,\n",
      "                 0.7608,\n",
      "                 0.6808,\n",
      "                 0.7859,\n",
      "                 0.8558,\n",
      "                 1.0204,\n",
      "                 0.5482,\n",
      "                 0.9471,\n",
      "                 0.5281,\n",
      "                 0.5843,\n",
      "                 1.2789,\n",
      "                 0.755,\n",
      "                 0.559,\n",
      "                 0.3769,\n",
      "                 0.8795,\n",
      "                 0.6746,\n",
      "                 0.7057,\n",
      "                 0.5301,\n",
      "                 0.8357,\n",
      "                 0.3707,\n",
      "                 0.9616,\n",
      "                 0.6426,\n",
      "                 0.5555,\n",
      "                 0.6021,\n",
      "                 1.1846,\n",
      "                 0.4826,\n",
      "                 1.2246,\n",
      "                 0.5247,\n",
      "                 0.6933,\n",
      "                 0.6049,\n",
      "                 1.1054,\n",
      "                 0.9951,\n",
      "                 0.6282,\n",
      "                 0.5778,\n",
      "                 0.7059,\n",
      "                 0.5463,\n",
      "                 1.0026,\n",
      "                 0.4661,\n",
      "                 0.6641,\n",
      "                 0.5259,\n",
      "                 1.6675,\n",
      "                 1.0385,\n",
      "                 0.4494,\n",
      "                 0.714,\n",
      "                 0.597,\n",
      "                 0.916,\n",
      "                 0.2271,\n",
      "                 0.7144,\n",
      "                 1.1792,\n",
      "                 1.2061,\n",
      "                 0.4798,\n",
      "                 1.2642,\n",
      "                 0.396,\n",
      "                 0.5408,\n",
      "                 0.2812,\n",
      "                 0.5098,\n",
      "                 0.8639,\n",
      "                 1.0878,\n",
      "                 0.3618,\n",
      "                 0.4403,\n",
      "                 0.3781,\n",
      "                 1.0133,\n",
      "                 0.6728,\n",
      "                 1.1841,\n",
      "                 0.8075,\n",
      "                 0.7895,\n",
      "                 0.5804,\n",
      "                 0.7463,\n",
      "                 1.0004,\n",
      "                 0.2854,\n",
      "                 1.1185,\n",
      "                 0.8081,\n",
      "                 0.3433,\n",
      "                 0.5996,\n",
      "                 0.6304,\n",
      "                 0.8204,\n",
      "                 0.3742,\n",
      "                 0.665,\n",
      "                 0.4601,\n",
      "                 1.5041,\n",
      "                 0.4007,\n",
      "                 0.304,\n",
      "                 0.5399,\n",
      "                 1.0135,\n",
      "                 0.9148,\n",
      "                 1.0194,\n",
      "                 0.3381,\n",
      "                 0.6559,\n",
      "                 0.9655,\n",
      "                 0.7143,\n",
      "                 0.8572,\n",
      "                 0.4019,\n",
      "                 0.902,\n",
      "                 1.0032,\n",
      "                 0.7733,\n",
      "                 0.2938,\n",
      "                 0.3914,\n",
      "                 0.399,\n",
      "                 0.7218,\n",
      "                 1.0074,\n",
      "                 0.2699,\n",
      "                 0.4666,\n",
      "                 0.3761,\n",
      "                 1.2303,\n",
      "                 0.5816,\n",
      "                 0.4896,\n",
      "                 0.3266,\n",
      "                 0.3867,\n",
      "                 1.8659,\n",
      "                 0.4427,\n",
      "                 1.5963,\n",
      "                 0.3654,\n",
      "                 0.6809,\n",
      "                 1.4317,\n",
      "                 0.1119,\n",
      "                 0.3251,\n",
      "                 1.1202,\n",
      "                 0.739,\n",
      "                 0.4035,\n",
      "                 0.3977,\n",
      "                 1.0553,\n",
      "                 0.689,\n",
      "                 0.4713,\n",
      "                 0.5227,\n",
      "                 1.0111,\n",
      "                 0.7519,\n",
      "                 0.1501,\n",
      "                 0.5513,\n",
      "                 0.7786,\n",
      "                 0.5399,\n",
      "                 0.4927,\n",
      "                 1.6003,\n",
      "                 0.6386,\n",
      "                 0.55,\n",
      "                 0.3831,\n",
      "                 0.2936,\n",
      "                 0.7139,\n",
      "                 0.9807,\n",
      "                 0.9598,\n",
      "                 0.7921,\n",
      "                 0.8217,\n",
      "                 0.3322,\n",
      "                 0.3977,\n",
      "                 0.5753,\n",
      "                 0.504,\n",
      "                 0.3562,\n",
      "                 1.2235,\n",
      "                 0.3935,\n",
      "                 0.5632,\n",
      "                 0.7754,\n",
      "                 0.8314,\n",
      "                 0.7148,\n",
      "                 0.7333,\n",
      "                 0.7178,\n",
      "                 0.4455,\n",
      "                 0.6355,\n",
      "                 0.4102,\n",
      "                 1.3595,\n",
      "                 0.3185,\n",
      "                 0.4123,\n",
      "                 1.7067,\n",
      "                 0.8333,\n",
      "                 1.0983,\n",
      "                 0.9288,\n",
      "                 0.11,\n",
      "                 1.0044,\n",
      "                 0.3472,\n",
      "                 0.6548,\n",
      "                 0.5506],\n",
      "  'val_loss': [0.5773907899856567,\n",
      "               0.5759792923927307,\n",
      "               0.5765266418457031,\n",
      "               0.5732094049453735,\n",
      "               0.5700737833976746,\n",
      "               0.5707347989082336,\n",
      "               0.5717836618423462,\n",
      "               0.5762222409248352,\n",
      "               0.5800786018371582,\n",
      "               0.5837193727493286,\n",
      "               0.588976263999939,\n",
      "               0.588912844657898,\n",
      "               0.5892685055732727,\n",
      "               0.5896893739700317,\n",
      "               0.5929669141769409,\n",
      "               0.5960311889648438,\n",
      "               0.5986014604568481,\n",
      "               0.597817063331604,\n",
      "               0.5977103114128113,\n",
      "               0.5985149145126343,\n",
      "               0.5977484583854675,\n",
      "               0.5975317358970642,\n",
      "               0.5966793298721313,\n",
      "               0.5965462923049927,\n",
      "               0.598028838634491,\n",
      "               0.5996463894844055,\n",
      "               0.6014692783355713,\n",
      "               0.6028232574462891,\n",
      "               0.6050899624824524,\n",
      "               0.6053369641304016,\n",
      "               0.6062740087509155,\n",
      "               0.6066389083862305,\n",
      "               0.6064481735229492,\n",
      "               0.6064944267272949,\n",
      "               0.6063154339790344,\n",
      "               0.6065616607666016,\n",
      "               0.6068034172058105,\n",
      "               0.6071243286132812,\n",
      "               0.6069523096084595,\n",
      "               0.6069357991218567]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6367,\n",
      "                 0.5372,\n",
      "                 1.3319,\n",
      "                 0.6529,\n",
      "                 0.9443,\n",
      "                 0.2484,\n",
      "                 0.471,\n",
      "                 0.6705,\n",
      "                 0.5236,\n",
      "                 0.6669,\n",
      "                 0.7455,\n",
      "                 0.3216,\n",
      "                 0.467,\n",
      "                 1.2027,\n",
      "                 0.6088,\n",
      "                 1.2359,\n",
      "                 0.3731,\n",
      "                 0.884,\n",
      "                 0.5907,\n",
      "                 0.9775,\n",
      "                 0.885,\n",
      "                 0.4417,\n",
      "                 0.3978,\n",
      "                 0.6378,\n",
      "                 0.5149,\n",
      "                 1.1457,\n",
      "                 0.4095,\n",
      "                 0.7519,\n",
      "                 0.4522,\n",
      "                 1.171,\n",
      "                 0.8352,\n",
      "                 0.4294,\n",
      "                 0.5074,\n",
      "                 0.8605,\n",
      "                 0.6864,\n",
      "                 0.5679,\n",
      "                 0.5507,\n",
      "                 0.6932,\n",
      "                 0.7411,\n",
      "                 0.6377,\n",
      "                 0.3777,\n",
      "                 0.2855,\n",
      "                 0.7913,\n",
      "                 0.7664,\n",
      "                 0.6623,\n",
      "                 0.5861,\n",
      "                 0.6051,\n",
      "                 0.6503,\n",
      "                 0.3927,\n",
      "                 0.368,\n",
      "                 0.8219,\n",
      "                 0.8378,\n",
      "                 0.5155,\n",
      "                 0.8115,\n",
      "                 0.3585,\n",
      "                 0.647,\n",
      "                 0.3673,\n",
      "                 0.3436,\n",
      "                 0.6733,\n",
      "                 0.9673,\n",
      "                 0.3965,\n",
      "                 0.6167,\n",
      "                 0.3769,\n",
      "                 0.6519,\n",
      "                 0.84,\n",
      "                 0.4563,\n",
      "                 1.1172,\n",
      "                 0.3194,\n",
      "                 0.5965,\n",
      "                 0.4006,\n",
      "                 0.354,\n",
      "                 0.3355,\n",
      "                 0.5778,\n",
      "                 0.5531,\n",
      "                 0.7984,\n",
      "                 1.0175,\n",
      "                 0.4712,\n",
      "                 0.4749,\n",
      "                 0.5073,\n",
      "                 0.4522,\n",
      "                 0.6193,\n",
      "                 0.3443,\n",
      "                 0.277,\n",
      "                 0.2699,\n",
      "                 0.9567,\n",
      "                 0.8474,\n",
      "                 0.6108,\n",
      "                 0.4169,\n",
      "                 0.9986,\n",
      "                 0.4195,\n",
      "                 0.3103,\n",
      "                 0.5137,\n",
      "                 0.4465,\n",
      "                 1.1068,\n",
      "                 0.8232,\n",
      "                 0.4722,\n",
      "                 1.1397,\n",
      "                 0.6427,\n",
      "                 0.1938,\n",
      "                 0.4733,\n",
      "                 0.6248,\n",
      "                 0.178,\n",
      "                 0.3091,\n",
      "                 0.7699,\n",
      "                 0.3518,\n",
      "                 0.3402,\n",
      "                 0.6591,\n",
      "                 1.0722,\n",
      "                 0.5984,\n",
      "                 0.4123,\n",
      "                 0.4078,\n",
      "                 0.3781,\n",
      "                 0.6515,\n",
      "                 0.7631,\n",
      "                 0.7257,\n",
      "                 0.3276,\n",
      "                 0.3896,\n",
      "                 0.2817,\n",
      "                 0.234,\n",
      "                 0.6188,\n",
      "                 1.1537,\n",
      "                 0.5922,\n",
      "                 0.3002,\n",
      "                 0.615,\n",
      "                 0.5297,\n",
      "                 0.3391,\n",
      "                 0.4045,\n",
      "                 0.6217,\n",
      "                 0.568,\n",
      "                 0.4662,\n",
      "                 0.3209,\n",
      "                 0.6356,\n",
      "                 0.6933,\n",
      "                 0.5289,\n",
      "                 0.2411,\n",
      "                 0.2468,\n",
      "                 0.3183,\n",
      "                 0.6647,\n",
      "                 0.239,\n",
      "                 0.7553,\n",
      "                 0.7661,\n",
      "                 0.4595,\n",
      "                 0.4507,\n",
      "                 0.2387,\n",
      "                 0.795,\n",
      "                 0.5909,\n",
      "                 0.5159,\n",
      "                 0.3341,\n",
      "                 0.1392,\n",
      "                 0.229,\n",
      "                 0.531,\n",
      "                 0.4177,\n",
      "                 0.2427,\n",
      "                 0.6312,\n",
      "                 0.2344,\n",
      "                 0.6911,\n",
      "                 0.256,\n",
      "                 0.6555,\n",
      "                 0.9711,\n",
      "                 0.2115,\n",
      "                 0.522,\n",
      "                 0.4034,\n",
      "                 0.9459,\n",
      "                 0.227,\n",
      "                 0.5361,\n",
      "                 0.2087,\n",
      "                 0.4035,\n",
      "                 0.4363,\n",
      "                 0.541,\n",
      "                 0.2067,\n",
      "                 0.2885,\n",
      "                 0.3209,\n",
      "                 0.5106,\n",
      "                 0.5896,\n",
      "                 0.4093,\n",
      "                 0.7675,\n",
      "                 0.1602,\n",
      "                 0.3594,\n",
      "                 0.6496,\n",
      "                 0.7438,\n",
      "                 0.974,\n",
      "                 0.3562,\n",
      "                 0.2278,\n",
      "                 0.1907,\n",
      "                 0.3032,\n",
      "                 0.7159,\n",
      "                 0.6577,\n",
      "                 0.6444,\n",
      "                 0.3625,\n",
      "                 0.4007,\n",
      "                 0.2303,\n",
      "                 0.2426,\n",
      "                 0.2541,\n",
      "                 0.137,\n",
      "                 0.7174,\n",
      "                 0.284,\n",
      "                 0.3952,\n",
      "                 0.8325,\n",
      "                 0.3883,\n",
      "                 0.4357,\n",
      "                 0.7243,\n",
      "                 0.464,\n",
      "                 0.4041,\n",
      "                 0.5835,\n",
      "                 0.4805,\n",
      "                 0.2608,\n",
      "                 0.2134,\n",
      "                 0.4387,\n",
      "                 0.3053,\n",
      "                 1.0292,\n",
      "                 0.5513,\n",
      "                 0.3507,\n",
      "                 0.2222,\n",
      "                 0.2341,\n",
      "                 0.5384,\n",
      "                 0.3381,\n",
      "                 0.6634,\n",
      "                 0.7787,\n",
      "                 0.8676,\n",
      "                 0.5783,\n",
      "                 0.234,\n",
      "                 0.189,\n",
      "                 0.3908,\n",
      "                 0.3103,\n",
      "                 0.6248,\n",
      "                 0.2933,\n",
      "                 1.0552,\n",
      "                 0.2503,\n",
      "                 0.4025,\n",
      "                 0.5018,\n",
      "                 0.3909,\n",
      "                 0.4388,\n",
      "                 0.2443,\n",
      "                 1.0213,\n",
      "                 0.3544,\n",
      "                 0.5714,\n",
      "                 0.1554,\n",
      "                 0.3837,\n",
      "                 0.2223,\n",
      "                 0.3227,\n",
      "                 0.7572,\n",
      "                 0.1574,\n",
      "                 0.6123,\n",
      "                 0.2047,\n",
      "                 0.6716,\n",
      "                 0.2054,\n",
      "                 0.6231,\n",
      "                 0.4755,\n",
      "                 0.2157,\n",
      "                 0.9077,\n",
      "                 0.201,\n",
      "                 0.2525,\n",
      "                 0.7295,\n",
      "                 0.2284,\n",
      "                 0.1537,\n",
      "                 1.0,\n",
      "                 0.3512,\n",
      "                 0.3257,\n",
      "                 0.9591,\n",
      "                 0.2399,\n",
      "                 0.6117,\n",
      "                 0.2608,\n",
      "                 0.5527,\n",
      "                 0.3039,\n",
      "                 0.2961,\n",
      "                 0.2215,\n",
      "                 0.385,\n",
      "                 0.2643,\n",
      "                 0.4606,\n",
      "                 0.3614,\n",
      "                 0.9016,\n",
      "                 0.1588,\n",
      "                 0.4676,\n",
      "                 0.2814,\n",
      "                 0.3091,\n",
      "                 0.2554,\n",
      "                 0.7016,\n",
      "                 0.1628,\n",
      "                 0.521,\n",
      "                 0.9231,\n",
      "                 0.6061,\n",
      "                 0.5935,\n",
      "                 0.2179,\n",
      "                 0.2413,\n",
      "                 1.1179,\n",
      "                 0.2498,\n",
      "                 0.2662,\n",
      "                 0.4937,\n",
      "                 0.3775,\n",
      "                 0.5913,\n",
      "                 0.2125,\n",
      "                 0.2862,\n",
      "                 0.4611,\n",
      "                 0.1437,\n",
      "                 0.6456,\n",
      "                 0.3269,\n",
      "                 0.6589,\n",
      "                 0.2317,\n",
      "                 0.5783,\n",
      "                 0.3042,\n",
      "                 0.606,\n",
      "                 0.1795,\n",
      "                 0.2956,\n",
      "                 0.5532,\n",
      "                 0.8076,\n",
      "                 0.483,\n",
      "                 0.4212,\n",
      "                 0.168,\n",
      "                 0.208,\n",
      "                 0.5655,\n",
      "                 0.5188,\n",
      "                 0.3512,\n",
      "                 0.6355,\n",
      "                 0.4754,\n",
      "                 0.3416,\n",
      "                 0.2145,\n",
      "                 0.4046,\n",
      "                 0.5297,\n",
      "                 0.1885,\n",
      "                 0.7148],\n",
      "  'val_loss': [0.5773840546607971,\n",
      "               0.5741069912910461,\n",
      "               0.568513035774231,\n",
      "               0.5597367286682129,\n",
      "               0.5531467199325562,\n",
      "               0.5463667511940002,\n",
      "               0.542961597442627,\n",
      "               0.5405920147895813,\n",
      "               0.539291262626648,\n",
      "               0.5391716957092285,\n",
      "               0.5366836786270142,\n",
      "               0.5340573191642761,\n",
      "               0.5329028367996216,\n",
      "               0.5322391390800476,\n",
      "               0.5312119722366333,\n",
      "               0.5304247736930847,\n",
      "               0.5299919247627258,\n",
      "               0.529384434223175,\n",
      "               0.5280134081840515,\n",
      "               0.5266825556755066,\n",
      "               0.5261019468307495,\n",
      "               0.5257253050804138,\n",
      "               0.5253941416740417,\n",
      "               0.5249655842781067,\n",
      "               0.5247083902359009,\n",
      "               0.5246488451957703,\n",
      "               0.5243455767631531,\n",
      "               0.5238109230995178,\n",
      "               0.5229429006576538,\n",
      "               0.5220149755477905,\n",
      "               0.5209976434707642,\n",
      "               0.5204043388366699,\n",
      "               0.5203536152839661,\n",
      "               0.5201342701911926,\n",
      "               0.5199995636940002,\n",
      "               0.5197911858558655,\n",
      "               0.5196855664253235,\n",
      "               0.5196347236633301,\n",
      "               0.519577145576477,\n",
      "               0.5195798873901367]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.4563,\n",
      "                 0.4913,\n",
      "                 1.0311,\n",
      "                 0.3001,\n",
      "                 1.0058,\n",
      "                 0.8598,\n",
      "                 0.6049,\n",
      "                 1.6,\n",
      "                 1.0708,\n",
      "                 0.7845,\n",
      "                 0.3076,\n",
      "                 1.0653,\n",
      "                 0.9853,\n",
      "                 0.3575,\n",
      "                 0.6706,\n",
      "                 0.6773,\n",
      "                 0.8296,\n",
      "                 0.4416,\n",
      "                 0.4384,\n",
      "                 1.8802,\n",
      "                 0.3195,\n",
      "                 1.5664,\n",
      "                 0.5839,\n",
      "                 0.3162,\n",
      "                 0.8366,\n",
      "                 0.6324,\n",
      "                 1.3078,\n",
      "                 0.6055,\n",
      "                 0.6981,\n",
      "                 0.2987,\n",
      "                 0.5575,\n",
      "                 0.8236,\n",
      "                 0.2446,\n",
      "                 0.5878,\n",
      "                 0.4133,\n",
      "                 1.212,\n",
      "                 0.705,\n",
      "                 1.0489,\n",
      "                 0.6027,\n",
      "                 0.5537,\n",
      "                 0.5023,\n",
      "                 0.5871,\n",
      "                 0.5981,\n",
      "                 0.2949,\n",
      "                 0.6811,\n",
      "                 0.2642,\n",
      "                 0.2979,\n",
      "                 1.1275,\n",
      "                 0.7256,\n",
      "                 0.7602,\n",
      "                 0.5116,\n",
      "                 0.2532,\n",
      "                 1.29,\n",
      "                 0.4522,\n",
      "                 1.2139,\n",
      "                 0.6393,\n",
      "                 0.802,\n",
      "                 0.4932,\n",
      "                 0.6861,\n",
      "                 0.4692,\n",
      "                 0.7463,\n",
      "                 0.4772,\n",
      "                 0.8301,\n",
      "                 1.1308,\n",
      "                 1.2649,\n",
      "                 0.2718,\n",
      "                 0.3033,\n",
      "                 0.8202,\n",
      "                 0.2649,\n",
      "                 0.4377,\n",
      "                 0.4997,\n",
      "                 0.818,\n",
      "                 0.7266,\n",
      "                 0.6219,\n",
      "                 0.7929,\n",
      "                 0.2657,\n",
      "                 0.4146,\n",
      "                 0.7385,\n",
      "                 1.4198,\n",
      "                 0.97,\n",
      "                 0.4146,\n",
      "                 0.4463,\n",
      "                 0.454,\n",
      "                 0.5463,\n",
      "                 0.6724,\n",
      "                 0.3384,\n",
      "                 0.6644,\n",
      "                 0.7871,\n",
      "                 0.4288,\n",
      "                 0.8438,\n",
      "                 0.4405,\n",
      "                 0.492,\n",
      "                 0.4628,\n",
      "                 0.5653,\n",
      "                 1.0974,\n",
      "                 0.6582,\n",
      "                 0.2569,\n",
      "                 0.4003,\n",
      "                 0.6425,\n",
      "                 1.0985,\n",
      "                 0.6035,\n",
      "                 0.9227,\n",
      "                 0.6311,\n",
      "                 0.5748,\n",
      "                 0.5235,\n",
      "                 0.4387,\n",
      "                 0.7488,\n",
      "                 0.3641,\n",
      "                 0.3624,\n",
      "                 0.7557,\n",
      "                 0.4767,\n",
      "                 0.3313,\n",
      "                 0.4001,\n",
      "                 0.4139,\n",
      "                 0.6324,\n",
      "                 0.6484,\n",
      "                 0.6384,\n",
      "                 0.4904,\n",
      "                 0.7278,\n",
      "                 0.3636,\n",
      "                 0.4311,\n",
      "                 0.4904,\n",
      "                 0.4617,\n",
      "                 0.4445,\n",
      "                 0.9167,\n",
      "                 1.1762,\n",
      "                 0.2851,\n",
      "                 0.2632,\n",
      "                 0.6082,\n",
      "                 0.5538,\n",
      "                 0.4825,\n",
      "                 0.3913,\n",
      "                 0.3592,\n",
      "                 0.9236,\n",
      "                 0.9737,\n",
      "                 0.3379,\n",
      "                 0.3778,\n",
      "                 0.1933,\n",
      "                 0.243,\n",
      "                 0.6596,\n",
      "                 0.6005,\n",
      "                 0.7197,\n",
      "                 0.9949,\n",
      "                 0.4846,\n",
      "                 0.341,\n",
      "                 0.251,\n",
      "                 0.2642,\n",
      "                 0.8734,\n",
      "                 0.52,\n",
      "                 0.5466,\n",
      "                 0.3524,\n",
      "                 0.3513,\n",
      "                 0.6318,\n",
      "                 0.4593,\n",
      "                 0.422,\n",
      "                 0.4151,\n",
      "                 0.7004,\n",
      "                 0.6417,\n",
      "                 0.4415,\n",
      "                 0.1471,\n",
      "                 0.4494,\n",
      "                 0.8527,\n",
      "                 0.2801,\n",
      "                 0.7,\n",
      "                 0.3292,\n",
      "                 0.3189,\n",
      "                 0.2429,\n",
      "                 0.753,\n",
      "                 0.114,\n",
      "                 0.8861,\n",
      "                 0.4848,\n",
      "                 0.5947,\n",
      "                 0.3258,\n",
      "                 0.4023,\n",
      "                 0.3599,\n",
      "                 0.9673,\n",
      "                 0.1262,\n",
      "                 1.0485,\n",
      "                 0.2527,\n",
      "                 0.5157,\n",
      "                 0.6608,\n",
      "                 0.9347,\n",
      "                 0.5874,\n",
      "                 0.4266,\n",
      "                 0.4695,\n",
      "                 0.229,\n",
      "                 0.6317,\n",
      "                 0.6463,\n",
      "                 0.4102,\n",
      "                 1.1236,\n",
      "                 0.1531,\n",
      "                 0.7546,\n",
      "                 0.7211,\n",
      "                 0.7299,\n",
      "                 0.1779,\n",
      "                 0.3712,\n",
      "                 0.7189,\n",
      "                 0.3553,\n",
      "                 0.4678,\n",
      "                 0.7977,\n",
      "                 0.3793,\n",
      "                 0.2476,\n",
      "                 0.553,\n",
      "                 0.3762,\n",
      "                 0.4343,\n",
      "                 0.15,\n",
      "                 0.728,\n",
      "                 0.7612,\n",
      "                 0.8292,\n",
      "                 0.1935,\n",
      "                 0.4047,\n",
      "                 0.5297,\n",
      "                 0.4498,\n",
      "                 0.875,\n",
      "                 0.4475,\n",
      "                 0.3904,\n",
      "                 0.9867,\n",
      "                 0.4534,\n",
      "                 0.1483,\n",
      "                 0.5851,\n",
      "                 0.172,\n",
      "                 0.5265,\n",
      "                 0.4972,\n",
      "                 0.224,\n",
      "                 0.2652,\n",
      "                 0.6586,\n",
      "                 0.3632,\n",
      "                 0.4516,\n",
      "                 0.5612,\n",
      "                 0.353,\n",
      "                 1.1989,\n",
      "                 0.2889,\n",
      "                 0.2294,\n",
      "                 0.2626,\n",
      "                 0.588,\n",
      "                 0.5921,\n",
      "                 0.7749,\n",
      "                 0.5252,\n",
      "                 0.4946,\n",
      "                 0.3809,\n",
      "                 0.1837,\n",
      "                 0.3376,\n",
      "                 0.5883,\n",
      "                 0.5256,\n",
      "                 0.7819,\n",
      "                 0.7089,\n",
      "                 0.2066,\n",
      "                 0.5023,\n",
      "                 0.1414,\n",
      "                 0.308,\n",
      "                 0.649,\n",
      "                 0.394,\n",
      "                 0.4575,\n",
      "                 0.2817,\n",
      "                 1.0138,\n",
      "                 0.4188,\n",
      "                 0.3348,\n",
      "                 0.2897,\n",
      "                 0.3181,\n",
      "                 0.8438,\n",
      "                 0.1662,\n",
      "                 0.6034,\n",
      "                 0.5626,\n",
      "                 0.2742,\n",
      "                 0.4773,\n",
      "                 0.3193,\n",
      "                 0.3002,\n",
      "                 0.6431,\n",
      "                 1.0084,\n",
      "                 0.1393,\n",
      "                 0.4649,\n",
      "                 0.6641,\n",
      "                 0.6099,\n",
      "                 0.2432,\n",
      "                 0.6728,\n",
      "                 0.3076,\n",
      "                 0.4942,\n",
      "                 0.192,\n",
      "                 0.3366,\n",
      "                 0.5514,\n",
      "                 0.4608,\n",
      "                 0.512,\n",
      "                 0.5754,\n",
      "                 0.2166,\n",
      "                 0.2835,\n",
      "                 0.6429,\n",
      "                 0.2393,\n",
      "                 0.3423,\n",
      "                 0.5506,\n",
      "                 0.4915,\n",
      "                 0.6533,\n",
      "                 0.484,\n",
      "                 0.119,\n",
      "                 0.2489,\n",
      "                 0.4781,\n",
      "                 0.1766,\n",
      "                 0.3513,\n",
      "                 0.5917,\n",
      "                 0.4026,\n",
      "                 0.3087,\n",
      "                 0.5692,\n",
      "                 0.3632,\n",
      "                 0.1582,\n",
      "                 0.9169,\n",
      "                 0.5514,\n",
      "                 0.4016,\n",
      "                 0.3554,\n",
      "                 0.1453,\n",
      "                 0.4533,\n",
      "                 0.3703,\n",
      "                 0.2219,\n",
      "                 0.6966,\n",
      "                 1.0812,\n",
      "                 0.6775,\n",
      "                 0.6749,\n",
      "                 0.2141,\n",
      "                 0.4356,\n",
      "                 0.3701,\n",
      "                 0.2243,\n",
      "                 0.2353],\n",
      "  'val_loss': [0.5792247653007507,\n",
      "               0.5759296417236328,\n",
      "               0.5709227323532104,\n",
      "               0.56279456615448,\n",
      "               0.5544620752334595,\n",
      "               0.5507764220237732,\n",
      "               0.5463311076164246,\n",
      "               0.5432448387145996,\n",
      "               0.541226863861084,\n",
      "               0.5384894013404846,\n",
      "               0.5370777249336243,\n",
      "               0.5364392995834351,\n",
      "               0.5374646186828613,\n",
      "               0.5377092361450195,\n",
      "               0.5379027128219604,\n",
      "               0.5385321974754333,\n",
      "               0.5387624502182007,\n",
      "               0.5383849143981934,\n",
      "               0.5381990671157837,\n",
      "               0.5392999053001404,\n",
      "               0.5396111607551575,\n",
      "               0.5412499308586121,\n",
      "               0.5422899127006531,\n",
      "               0.5432469248771667,\n",
      "               0.544080376625061,\n",
      "               0.544904351234436,\n",
      "               0.5435836315155029,\n",
      "               0.5436628460884094,\n",
      "               0.5439102053642273,\n",
      "               0.5438041687011719,\n",
      "               0.5435351133346558,\n",
      "               0.5430570840835571,\n",
      "               0.5428775548934937,\n",
      "               0.5429456830024719,\n",
      "               0.5430189371109009,\n",
      "               0.5429342985153198,\n",
      "               0.5430781841278076,\n",
      "               0.5432862043380737,\n",
      "               0.5433356761932373,\n",
      "               0.5433435440063477]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.4284,\n",
      "                 0.7111,\n",
      "                 1.2287,\n",
      "                 0.7858,\n",
      "                 1.0426,\n",
      "                 0.783,\n",
      "                 0.3589,\n",
      "                 1.1914,\n",
      "                 0.4593,\n",
      "                 0.6939,\n",
      "                 1.0118,\n",
      "                 1.3665,\n",
      "                 1.0192,\n",
      "                 0.2825,\n",
      "                 0.5194,\n",
      "                 0.7479,\n",
      "                 0.8356,\n",
      "                 0.3433,\n",
      "                 0.7152,\n",
      "                 0.8432,\n",
      "                 0.3081,\n",
      "                 1.3497,\n",
      "                 0.4706,\n",
      "                 1.047,\n",
      "                 0.2733,\n",
      "                 0.9979,\n",
      "                 0.657,\n",
      "                 0.7502,\n",
      "                 1.1485,\n",
      "                 0.3153,\n",
      "                 1.2749,\n",
      "                 0.2409,\n",
      "                 0.4726,\n",
      "                 0.0836,\n",
      "                 0.462,\n",
      "                 1.8304,\n",
      "                 0.5176,\n",
      "                 0.7272,\n",
      "                 0.1267,\n",
      "                 0.8602,\n",
      "                 0.2382,\n",
      "                 1.3321,\n",
      "                 0.3806,\n",
      "                 1.091,\n",
      "                 0.9258,\n",
      "                 0.326,\n",
      "                 0.5407,\n",
      "                 0.3907,\n",
      "                 0.2848,\n",
      "                 0.4581,\n",
      "                 1.3686,\n",
      "                 0.4698,\n",
      "                 0.3698,\n",
      "                 0.443,\n",
      "                 0.5873,\n",
      "                 0.9901,\n",
      "                 0.5588,\n",
      "                 0.2548,\n",
      "                 0.4583,\n",
      "                 0.704,\n",
      "                 1.3604,\n",
      "                 0.7218,\n",
      "                 0.7079,\n",
      "                 0.5543,\n",
      "                 0.4969,\n",
      "                 0.204,\n",
      "                 0.9342,\n",
      "                 0.5005,\n",
      "                 0.4302,\n",
      "                 0.2947,\n",
      "                 1.4314,\n",
      "                 0.7277,\n",
      "                 0.5672,\n",
      "                 0.2007,\n",
      "                 0.5159,\n",
      "                 0.3713,\n",
      "                 0.9177,\n",
      "                 1.6438,\n",
      "                 0.2864,\n",
      "                 0.2666,\n",
      "                 1.0227,\n",
      "                 0.3654,\n",
      "                 0.1992,\n",
      "                 0.5093,\n",
      "                 0.5697,\n",
      "                 0.3976,\n",
      "                 0.9149,\n",
      "                 0.3351,\n",
      "                 0.2407,\n",
      "                 0.0895,\n",
      "                 1.193,\n",
      "                 0.081,\n",
      "                 0.885,\n",
      "                 0.5816,\n",
      "                 0.6814,\n",
      "                 0.4189,\n",
      "                 0.4158,\n",
      "                 0.3209,\n",
      "                 1.4747,\n",
      "                 0.3546,\n",
      "                 0.4706,\n",
      "                 0.1123,\n",
      "                 0.4189,\n",
      "                 0.7939,\n",
      "                 0.5999,\n",
      "                 0.208,\n",
      "                 0.6734,\n",
      "                 1.2548,\n",
      "                 0.1142,\n",
      "                 1.3717,\n",
      "                 0.2911,\n",
      "                 0.2863,\n",
      "                 0.0534,\n",
      "                 0.2981,\n",
      "                 1.1847,\n",
      "                 1.2796,\n",
      "                 0.4299,\n",
      "                 0.0797,\n",
      "                 0.5865,\n",
      "                 0.7826,\n",
      "                 0.3493,\n",
      "                 1.3466,\n",
      "                 0.1602,\n",
      "                 0.153,\n",
      "                 0.8435,\n",
      "                 0.2344,\n",
      "                 0.2179,\n",
      "                 0.3764,\n",
      "                 1.1936,\n",
      "                 0.1711,\n",
      "                 0.2867,\n",
      "                 0.2926,\n",
      "                 0.4095,\n",
      "                 0.7873,\n",
      "                 0.678,\n",
      "                 0.2559,\n",
      "                 0.5677,\n",
      "                 0.295,\n",
      "                 1.0887,\n",
      "                 0.5925,\n",
      "                 0.5319,\n",
      "                 0.2597,\n",
      "                 0.2472,\n",
      "                 0.2284,\n",
      "                 0.4102,\n",
      "                 0.0977,\n",
      "                 0.1261,\n",
      "                 0.4724,\n",
      "                 0.2373,\n",
      "                 1.3937,\n",
      "                 0.6269,\n",
      "                 0.4587,\n",
      "                 0.414,\n",
      "                 0.366,\n",
      "                 1.3402,\n",
      "                 0.2324,\n",
      "                 0.1747,\n",
      "                 0.9463,\n",
      "                 0.68,\n",
      "                 0.078,\n",
      "                 0.7781,\n",
      "                 1.3322,\n",
      "                 0.6137,\n",
      "                 0.1633,\n",
      "                 0.3019,\n",
      "                 0.2518,\n",
      "                 0.3342,\n",
      "                 0.0547,\n",
      "                 0.3227,\n",
      "                 1.3673,\n",
      "                 0.2692,\n",
      "                 0.1469,\n",
      "                 0.2156,\n",
      "                 0.6542,\n",
      "                 0.1837,\n",
      "                 0.2189,\n",
      "                 0.1042,\n",
      "                 1.1269,\n",
      "                 0.6099,\n",
      "                 0.6713,\n",
      "                 0.1801,\n",
      "                 0.1875,\n",
      "                 0.4736,\n",
      "                 0.3585,\n",
      "                 1.4341,\n",
      "                 0.3619,\n",
      "                 0.8964,\n",
      "                 0.4245,\n",
      "                 0.1891,\n",
      "                 0.3009,\n",
      "                 0.0886,\n",
      "                 0.299,\n",
      "                 0.2303,\n",
      "                 0.4096,\n",
      "                 0.6175,\n",
      "                 0.3626,\n",
      "                 1.8232,\n",
      "                 0.2975,\n",
      "                 0.0721,\n",
      "                 0.1372,\n",
      "                 1.5258,\n",
      "                 0.6449,\n",
      "                 0.4408,\n",
      "                 0.3472,\n",
      "                 0.1052,\n",
      "                 0.4081,\n",
      "                 0.3121,\n",
      "                 0.0431,\n",
      "                 0.2432,\n",
      "                 0.5243,\n",
      "                 0.1162,\n",
      "                 0.3039,\n",
      "                 0.2697,\n",
      "                 0.2198,\n",
      "                 1.6447,\n",
      "                 0.6963,\n",
      "                 0.8306,\n",
      "                 0.3283,\n",
      "                 0.5222,\n",
      "                 0.0585,\n",
      "                 0.2176,\n",
      "                 0.2637,\n",
      "                 1.2793,\n",
      "                 0.0811,\n",
      "                 0.1879,\n",
      "                 0.0535,\n",
      "                 2.0326,\n",
      "                 0.2247,\n",
      "                 0.6354,\n",
      "                 0.0523,\n",
      "                 0.4332,\n",
      "                 0.1531,\n",
      "                 0.2162,\n",
      "                 0.5411,\n",
      "                 0.1294,\n",
      "                 1.7086,\n",
      "                 0.2633,\n",
      "                 0.1556,\n",
      "                 0.1013,\n",
      "                 0.4674,\n",
      "                 0.6591,\n",
      "                 1.26,\n",
      "                 0.3132,\n",
      "                 0.2313,\n",
      "                 0.1214,\n",
      "                 0.0431,\n",
      "                 0.0945,\n",
      "                 0.8027,\n",
      "                 0.1013,\n",
      "                 0.5065,\n",
      "                 1.3141,\n",
      "                 0.2764,\n",
      "                 0.888,\n",
      "                 0.444,\n",
      "                 0.165,\n",
      "                 0.2043,\n",
      "                 0.0423,\n",
      "                 0.3362,\n",
      "                 0.6779,\n",
      "                 1.2201,\n",
      "                 0.975,\n",
      "                 0.1266,\n",
      "                 0.1736,\n",
      "                 0.2257,\n",
      "                 0.2504,\n",
      "                 0.1676,\n",
      "                 0.0413,\n",
      "                 1.6152,\n",
      "                 0.5804,\n",
      "                 0.3496,\n",
      "                 0.0837,\n",
      "                 0.0629,\n",
      "                 1.4442,\n",
      "                 0.0383,\n",
      "                 0.2495,\n",
      "                 0.1718,\n",
      "                 0.3313,\n",
      "                 0.1873,\n",
      "                 1.3363,\n",
      "                 0.2171,\n",
      "                 0.2569,\n",
      "                 0.137,\n",
      "                 0.1063,\n",
      "                 1.1442,\n",
      "                 0.4342,\n",
      "                 0.2791,\n",
      "                 0.0598,\n",
      "                 0.8561,\n",
      "                 0.5244,\n",
      "                 1.2342,\n",
      "                 0.2015,\n",
      "                 0.0378,\n",
      "                 0.3794,\n",
      "                 0.2127,\n",
      "                 0.1498,\n",
      "                 0.1634,\n",
      "                 0.1557,\n",
      "                 0.1672,\n",
      "                 0.4174,\n",
      "                 0.0343,\n",
      "                 0.4389,\n",
      "                 1.2525,\n",
      "                 0.5318,\n",
      "                 0.0526,\n",
      "                 0.1951,\n",
      "                 0.1728,\n",
      "                 0.294,\n",
      "                 0.038,\n",
      "                 1.8984,\n",
      "                 0.8731,\n",
      "                 0.3771,\n",
      "                 0.0502,\n",
      "                 0.4136,\n",
      "                 0.2794,\n",
      "                 1.2089,\n",
      "                 0.217,\n",
      "                 0.117,\n",
      "                 0.8087,\n",
      "                 0.1421,\n",
      "                 0.4633],\n",
      "  'val_loss': [0.5795891284942627,\n",
      "               0.5864213705062866,\n",
      "               0.5952324867248535,\n",
      "               0.6110905408859253,\n",
      "               0.6226202845573425,\n",
      "               0.6334880590438843,\n",
      "               0.6563827395439148,\n",
      "               0.6640914082527161,\n",
      "               0.678905725479126,\n",
      "               0.6944554448127747,\n",
      "               0.7029497027397156,\n",
      "               0.7156745791435242,\n",
      "               0.7194629907608032,\n",
      "               0.7252444624900818,\n",
      "               0.7366815805435181,\n",
      "               0.7420104742050171,\n",
      "               0.7369962930679321,\n",
      "               0.7311080694198608,\n",
      "               0.7365973591804504,\n",
      "               0.734221875667572,\n",
      "               0.7299143671989441,\n",
      "               0.7254944443702698,\n",
      "               0.7232208251953125,\n",
      "               0.7213309407234192,\n",
      "               0.7213150262832642,\n",
      "               0.7279753684997559,\n",
      "               0.7335953712463379,\n",
      "               0.7349262833595276,\n",
      "               0.7397759556770325,\n",
      "               0.746430516242981,\n",
      "               0.7536023259162903,\n",
      "               0.7587839961051941,\n",
      "               0.7621960639953613,\n",
      "               0.7618139982223511,\n",
      "               0.7634775042533875,\n",
      "               0.7654033899307251,\n",
      "               0.7656534314155579,\n",
      "               0.7656794786453247,\n",
      "               0.7654464244842529,\n",
      "               0.7654906511306763]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6938,\n",
      "                 0.6228,\n",
      "                 1.4939,\n",
      "                 0.7716,\n",
      "                 0.9175,\n",
      "                 1.6864,\n",
      "                 0.9549,\n",
      "                 1.4666,\n",
      "                 1.3084,\n",
      "                 0.9508,\n",
      "                 0.4544,\n",
      "                 0.9093,\n",
      "                 1.5259,\n",
      "                 1.088,\n",
      "                 0.717,\n",
      "                 0.9391,\n",
      "                 1.0112,\n",
      "                 1.4392,\n",
      "                 0.6105,\n",
      "                 1.0275,\n",
      "                 1.1769,\n",
      "                 1.0011,\n",
      "                 1.4438,\n",
      "                 0.2073,\n",
      "                 0.6407,\n",
      "                 0.9926,\n",
      "                 0.9744,\n",
      "                 0.9947,\n",
      "                 0.9716,\n",
      "                 0.4072,\n",
      "                 0.6839,\n",
      "                 1.4769,\n",
      "                 0.9859,\n",
      "                 0.9315,\n",
      "                 0.5964,\n",
      "                 0.3963,\n",
      "                 1.6602,\n",
      "                 1.2921,\n",
      "                 0.551,\n",
      "                 0.3916,\n",
      "                 1.3152,\n",
      "                 0.3873,\n",
      "                 1.2151,\n",
      "                 0.441,\n",
      "                 1.3908,\n",
      "                 0.4915,\n",
      "                 0.9351,\n",
      "                 1.1775,\n",
      "                 0.4241,\n",
      "                 1.2363,\n",
      "                 0.4369,\n",
      "                 1.1362,\n",
      "                 1.0493,\n",
      "                 0.5108,\n",
      "                 1.1999,\n",
      "                 0.5293,\n",
      "                 1.023,\n",
      "                 1.0898,\n",
      "                 0.5218,\n",
      "                 1.0524,\n",
      "                 0.1936,\n",
      "                 1.216,\n",
      "                 0.7136,\n",
      "                 1.1192,\n",
      "                 1.3267,\n",
      "                 1.2684,\n",
      "                 0.5923,\n",
      "                 1.5247,\n",
      "                 0.4952,\n",
      "                 0.4991,\n",
      "                 0.4892,\n",
      "                 1.4528,\n",
      "                 1.2514,\n",
      "                 1.3103,\n",
      "                 1.0184,\n",
      "                 1.259,\n",
      "                 0.5405,\n",
      "                 0.1874,\n",
      "                 0.9329,\n",
      "                 0.6048,\n",
      "                 0.4444,\n",
      "                 0.7543,\n",
      "                 0.5211,\n",
      "                 0.4601,\n",
      "                 0.8226,\n",
      "                 1.088,\n",
      "                 0.7816,\n",
      "                 1.216,\n",
      "                 0.6718,\n",
      "                 0.476,\n",
      "                 0.927,\n",
      "                 1.1175,\n",
      "                 0.5103,\n",
      "                 0.7345,\n",
      "                 1.5,\n",
      "                 0.6576,\n",
      "                 0.3868,\n",
      "                 1.0417,\n",
      "                 0.2299,\n",
      "                 1.218,\n",
      "                 1.3987,\n",
      "                 0.431,\n",
      "                 0.8577,\n",
      "                 0.6771,\n",
      "                 1.5186,\n",
      "                 1.1716,\n",
      "                 0.8828,\n",
      "                 0.5872,\n",
      "                 0.8922,\n",
      "                 0.5791,\n",
      "                 0.6116,\n",
      "                 0.9076,\n",
      "                 0.5585,\n",
      "                 0.3717,\n",
      "                 0.9517,\n",
      "                 0.4955,\n",
      "                 1.6136,\n",
      "                 0.6476,\n",
      "                 1.4089,\n",
      "                 0.4808,\n",
      "                 1.008,\n",
      "                 0.4951,\n",
      "                 0.5077,\n",
      "                 1.2627,\n",
      "                 1.1221,\n",
      "                 0.7399,\n",
      "                 0.8159,\n",
      "                 0.5916,\n",
      "                 0.6042,\n",
      "                 1.468,\n",
      "                 0.417,\n",
      "                 0.5097,\n",
      "                 0.7607,\n",
      "                 0.545,\n",
      "                 1.2722,\n",
      "                 0.2833,\n",
      "                 1.0047,\n",
      "                 0.5352,\n",
      "                 0.4066,\n",
      "                 0.4796,\n",
      "                 1.0191,\n",
      "                 1.1997,\n",
      "                 0.7572,\n",
      "                 1.0275,\n",
      "                 0.8271,\n",
      "                 1.2156,\n",
      "                 0.5027,\n",
      "                 0.8518,\n",
      "                 0.6004,\n",
      "                 0.2857,\n",
      "                 0.8501,\n",
      "                 0.7047,\n",
      "                 0.6749,\n",
      "                 0.5755,\n",
      "                 0.3407,\n",
      "                 0.914,\n",
      "                 1.0862,\n",
      "                 0.6137,\n",
      "                 0.7885,\n",
      "                 0.4627,\n",
      "                 0.6015,\n",
      "                 0.7149,\n",
      "                 0.3891,\n",
      "                 0.6485,\n",
      "                 1.0359,\n",
      "                 0.8056,\n",
      "                 0.7173,\n",
      "                 0.4124,\n",
      "                 1.0645,\n",
      "                 0.521,\n",
      "                 0.27,\n",
      "                 0.5773,\n",
      "                 0.8709,\n",
      "                 0.9952,\n",
      "                 0.6136,\n",
      "                 0.6316,\n",
      "                 0.6735,\n",
      "                 0.6009,\n",
      "                 0.5142,\n",
      "                 0.6369,\n",
      "                 0.6953,\n",
      "                 1.1345,\n",
      "                 1.2464,\n",
      "                 0.3206,\n",
      "                 0.5139,\n",
      "                 0.5838,\n",
      "                 0.6514,\n",
      "                 0.8807,\n",
      "                 0.4371,\n",
      "                 0.6637,\n",
      "                 0.3423,\n",
      "                 1.1021,\n",
      "                 0.4963,\n",
      "                 0.6338,\n",
      "                 1.1384,\n",
      "                 0.2483,\n",
      "                 0.5319,\n",
      "                 0.8831,\n",
      "                 0.6356,\n",
      "                 0.8496,\n",
      "                 0.3665,\n",
      "                 0.4276,\n",
      "                 0.7016,\n",
      "                 0.3308,\n",
      "                 0.3587,\n",
      "                 1.4316,\n",
      "                 0.7909,\n",
      "                 0.8979,\n",
      "                 0.9227,\n",
      "                 0.8092,\n",
      "                 0.2254,\n",
      "                 0.32,\n",
      "                 1.4879,\n",
      "                 0.7257,\n",
      "                 0.2686,\n",
      "                 0.2824,\n",
      "                 1.0077,\n",
      "                 0.4368,\n",
      "                 1.1581,\n",
      "                 0.487,\n",
      "                 0.9044,\n",
      "                 0.5328,\n",
      "                 0.4429,\n",
      "                 0.4984,\n",
      "                 0.3952,\n",
      "                 0.7401,\n",
      "                 0.555,\n",
      "                 0.3378,\n",
      "                 1.1541,\n",
      "                 0.2901,\n",
      "                 0.8789,\n",
      "                 0.5954,\n",
      "                 0.3735,\n",
      "                 0.4731,\n",
      "                 0.917,\n",
      "                 0.4443,\n",
      "                 0.578,\n",
      "                 0.9912,\n",
      "                 0.4797,\n",
      "                 0.6243,\n",
      "                 0.9354,\n",
      "                 0.347,\n",
      "                 0.2463,\n",
      "                 0.6775,\n",
      "                 0.8968,\n",
      "                 0.5664,\n",
      "                 0.6352,\n",
      "                 0.5445,\n",
      "                 0.5654,\n",
      "                 0.4231,\n",
      "                 0.7736,\n",
      "                 0.2955,\n",
      "                 0.536,\n",
      "                 1.1952,\n",
      "                 0.5242,\n",
      "                 0.3179,\n",
      "                 0.3289,\n",
      "                 0.9573,\n",
      "                 0.5651,\n",
      "                 0.407,\n",
      "                 0.4217,\n",
      "                 0.9668,\n",
      "                 0.3538,\n",
      "                 0.7646,\n",
      "                 0.8859,\n",
      "                 0.8427,\n",
      "                 0.8286,\n",
      "                 0.2943,\n",
      "                 0.6341,\n",
      "                 0.3837,\n",
      "                 0.3499,\n",
      "                 0.7438,\n",
      "                 0.3934,\n",
      "                 0.4974,\n",
      "                 0.3407,\n",
      "                 0.842,\n",
      "                 0.8206,\n",
      "                 0.6107,\n",
      "                 0.7839,\n",
      "                 0.3891,\n",
      "                 0.4043,\n",
      "                 0.3886,\n",
      "                 0.982,\n",
      "                 0.3718,\n",
      "                 0.3571,\n",
      "                 1.0589,\n",
      "                 0.3246,\n",
      "                 0.9164,\n",
      "                 0.914,\n",
      "                 0.2801,\n",
      "                 0.7194,\n",
      "                 0.7538,\n",
      "                 0.9853,\n",
      "                 0.1125,\n",
      "                 0.3233,\n",
      "                 0.5866,\n",
      "                 0.3297,\n",
      "                 0.908,\n",
      "                 0.2867,\n",
      "                 0.3852,\n",
      "                 0.5905,\n",
      "                 0.5949,\n",
      "                 0.5263,\n",
      "                 0.7029,\n",
      "                 0.5837,\n",
      "                 0.3647,\n",
      "                 0.8522,\n",
      "                 0.299,\n",
      "                 0.6826,\n",
      "                 1.1565,\n",
      "                 0.5137,\n",
      "                 0.691,\n",
      "                 0.5866,\n",
      "                 0.8177,\n",
      "                 0.6277,\n",
      "                 0.6651,\n",
      "                 0.8348,\n",
      "                 0.4095,\n",
      "                 0.6725,\n",
      "                 0.6467],\n",
      "  'val_loss': [0.5779986381530762,\n",
      "               0.5726189613342285,\n",
      "               0.5672434568405151,\n",
      "               0.5611957311630249,\n",
      "               0.5572670698165894,\n",
      "               0.5576747059822083,\n",
      "               0.5592087507247925,\n",
      "               0.5606632232666016,\n",
      "               0.5621997117996216,\n",
      "               0.5624957084655762,\n",
      "               0.5637924075126648,\n",
      "               0.56509929895401,\n",
      "               0.5667134523391724,\n",
      "               0.5668965578079224,\n",
      "               0.5690419673919678,\n",
      "               0.5720330476760864,\n",
      "               0.574988067150116,\n",
      "               0.5762372612953186,\n",
      "               0.5789700746536255,\n",
      "               0.5814751386642456,\n",
      "               0.5840965509414673,\n",
      "               0.5855680704116821,\n",
      "               0.5877582430839539,\n",
      "               0.5895400047302246,\n",
      "               0.591866135597229,\n",
      "               0.592967689037323,\n",
      "               0.5947430729866028,\n",
      "               0.596260666847229,\n",
      "               0.5973766446113586,\n",
      "               0.5978350639343262,\n",
      "               0.5986273288726807,\n",
      "               0.5987110137939453,\n",
      "               0.5988172888755798,\n",
      "               0.599635660648346,\n",
      "               0.6004294157028198,\n",
      "               0.6010777354240417,\n",
      "               0.6010838747024536,\n",
      "               0.6013306975364685,\n",
      "               0.6015653014183044,\n",
      "               0.6015810966491699]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.8991,\n",
      "                 1.1271,\n",
      "                 0.4166,\n",
      "                 0.7887,\n",
      "                 0.7142,\n",
      "                 0.8257,\n",
      "                 0.0912,\n",
      "                 0.658,\n",
      "                 0.0812,\n",
      "                 0.2413,\n",
      "                 1.3795,\n",
      "                 1.2098,\n",
      "                 0.5739,\n",
      "                 0.3828,\n",
      "                 1.0631,\n",
      "                 0.8185,\n",
      "                 0.8957,\n",
      "                 0.6942,\n",
      "                 0.9609,\n",
      "                 0.7283,\n",
      "                 0.1467,\n",
      "                 1.0626,\n",
      "                 0.1614,\n",
      "                 1.0773,\n",
      "                 0.6838,\n",
      "                 1.1285,\n",
      "                 0.3379,\n",
      "                 0.4637,\n",
      "                 1.1361,\n",
      "                 0.5489,\n",
      "                 0.8435,\n",
      "                 0.5998,\n",
      "                 0.5161,\n",
      "                 0.2193,\n",
      "                 1.268,\n",
      "                 1.0742,\n",
      "                 0.38,\n",
      "                 0.8782,\n",
      "                 0.5234,\n",
      "                 1.1155,\n",
      "                 0.5473,\n",
      "                 1.3551,\n",
      "                 0.3041,\n",
      "                 1.009,\n",
      "                 0.6334,\n",
      "                 0.4411,\n",
      "                 0.8794,\n",
      "                 0.2483,\n",
      "                 0.5106,\n",
      "                 0.2799,\n",
      "                 0.9722,\n",
      "                 0.3472,\n",
      "                 0.5114,\n",
      "                 0.9135,\n",
      "                 0.5534,\n",
      "                 0.695,\n",
      "                 0.1295,\n",
      "                 0.4576,\n",
      "                 0.6541,\n",
      "                 0.5586,\n",
      "                 1.0428,\n",
      "                 1.5863,\n",
      "                 0.464,\n",
      "                 0.3546,\n",
      "                 0.1584,\n",
      "                 0.1678,\n",
      "                 1.4762,\n",
      "                 0.6067,\n",
      "                 0.4402,\n",
      "                 0.8799,\n",
      "                 1.1004,\n",
      "                 0.6538,\n",
      "                 1.1758,\n",
      "                 0.1019,\n",
      "                 0.3812,\n",
      "                 0.7077,\n",
      "                 0.987,\n",
      "                 0.9669,\n",
      "                 1.0457,\n",
      "                 0.6861,\n",
      "                 0.8519,\n",
      "                 0.7922,\n",
      "                 0.4958,\n",
      "                 0.2019,\n",
      "                 0.9591,\n",
      "                 0.806,\n",
      "                 0.6454,\n",
      "                 0.141,\n",
      "                 0.8695,\n",
      "                 0.3486,\n",
      "                 0.8178,\n",
      "                 0.1148,\n",
      "                 0.8887,\n",
      "                 0.5157,\n",
      "                 0.4541,\n",
      "                 0.3725,\n",
      "                 0.5465,\n",
      "                 0.3561,\n",
      "                 0.7275,\n",
      "                 0.3376,\n",
      "                 0.3926,\n",
      "                 0.5073,\n",
      "                 0.2914,\n",
      "                 1.1714,\n",
      "                 0.4439,\n",
      "                 0.3767,\n",
      "                 0.8597,\n",
      "                 0.6291,\n",
      "                 0.0709,\n",
      "                 0.9074,\n",
      "                 0.3252,\n",
      "                 0.5986,\n",
      "                 0.1971,\n",
      "                 0.6608,\n",
      "                 0.827,\n",
      "                 0.4708,\n",
      "                 0.2478,\n",
      "                 0.2804,\n",
      "                 0.9345,\n",
      "                 0.7135,\n",
      "                 0.5169,\n",
      "                 0.5293,\n",
      "                 0.462,\n",
      "                 0.5221,\n",
      "                 0.4226,\n",
      "                 0.4426,\n",
      "                 0.3616,\n",
      "                 0.22,\n",
      "                 0.3644,\n",
      "                 0.2279,\n",
      "                 0.2919,\n",
      "                 0.6931,\n",
      "                 0.6041,\n",
      "                 0.9457,\n",
      "                 0.6075,\n",
      "                 0.6027,\n",
      "                 0.6291,\n",
      "                 0.3248,\n",
      "                 0.3899,\n",
      "                 0.8217,\n",
      "                 0.5351,\n",
      "                 0.2263,\n",
      "                 0.2198,\n",
      "                 0.9376,\n",
      "                 1.0142,\n",
      "                 0.4124,\n",
      "                 0.1485,\n",
      "                 0.2556,\n",
      "                 0.5794,\n",
      "                 0.7615,\n",
      "                 0.4918,\n",
      "                 0.4455,\n",
      "                 0.362,\n",
      "                 0.2999,\n",
      "                 0.7221,\n",
      "                 0.2214,\n",
      "                 1.0177,\n",
      "                 0.7475,\n",
      "                 0.2554,\n",
      "                 0.1242,\n",
      "                 0.7049,\n",
      "                 0.7447,\n",
      "                 0.4735,\n",
      "                 0.5689,\n",
      "                 0.553,\n",
      "                 0.2562,\n",
      "                 0.4254,\n",
      "                 0.1328,\n",
      "                 0.8459,\n",
      "                 0.5748,\n",
      "                 0.475,\n",
      "                 0.2898,\n",
      "                 0.2031,\n",
      "                 0.585,\n",
      "                 0.2118,\n",
      "                 0.7376,\n",
      "                 0.2079,\n",
      "                 0.6935,\n",
      "                 0.2879,\n",
      "                 0.5327,\n",
      "                 0.3638,\n",
      "                 0.5131,\n",
      "                 0.5242,\n",
      "                 0.4299,\n",
      "                 1.0242,\n",
      "                 0.3561,\n",
      "                 0.3137,\n",
      "                 0.358,\n",
      "                 0.3273,\n",
      "                 0.3962,\n",
      "                 0.163,\n",
      "                 0.4194,\n",
      "                 0.2093,\n",
      "                 0.1277,\n",
      "                 0.2149,\n",
      "                 0.247,\n",
      "                 1.1935,\n",
      "                 0.864,\n",
      "                 0.1785,\n",
      "                 0.3141,\n",
      "                 0.6393,\n",
      "                 0.3558,\n",
      "                 0.3425,\n",
      "                 0.5711,\n",
      "                 0.1799,\n",
      "                 0.2955,\n",
      "                 0.3014,\n",
      "                 0.2224,\n",
      "                 0.3661,\n",
      "                 0.0822,\n",
      "                 0.4271,\n",
      "                 0.3479,\n",
      "                 0.5179,\n",
      "                 0.1108,\n",
      "                 0.6485,\n",
      "                 0.4794,\n",
      "                 0.5163,\n",
      "                 0.6826,\n",
      "                 0.3567,\n",
      "                 0.4165,\n",
      "                 0.3911,\n",
      "                 0.468,\n",
      "                 0.543,\n",
      "                 0.2408,\n",
      "                 0.4029,\n",
      "                 0.4085,\n",
      "                 0.5383,\n",
      "                 0.3726,\n",
      "                 0.3908,\n",
      "                 0.3189,\n",
      "                 0.404,\n",
      "                 0.3788,\n",
      "                 0.1184,\n",
      "                 0.4364,\n",
      "                 0.1826,\n",
      "                 0.915,\n",
      "                 0.3852,\n",
      "                 0.2763,\n",
      "                 0.3526,\n",
      "                 0.2338,\n",
      "                 0.1677,\n",
      "                 0.5094,\n",
      "                 0.3337,\n",
      "                 0.3416,\n",
      "                 0.113,\n",
      "                 0.3629,\n",
      "                 0.2801,\n",
      "                 0.4778,\n",
      "                 0.1276,\n",
      "                 0.3044,\n",
      "                 0.5909,\n",
      "                 0.3271,\n",
      "                 0.3397,\n",
      "                 0.3967,\n",
      "                 0.5132,\n",
      "                 0.3554,\n",
      "                 0.1604,\n",
      "                 0.5781,\n",
      "                 0.4293,\n",
      "                 0.9178,\n",
      "                 0.354,\n",
      "                 0.4808,\n",
      "                 0.1684,\n",
      "                 0.2874,\n",
      "                 0.3197,\n",
      "                 0.5765,\n",
      "                 0.0678,\n",
      "                 0.5663,\n",
      "                 0.3063,\n",
      "                 0.1576,\n",
      "                 0.3934,\n",
      "                 0.5119,\n",
      "                 0.7908,\n",
      "                 0.0783,\n",
      "                 0.1801,\n",
      "                 0.3607,\n",
      "                 0.388,\n",
      "                 0.1954,\n",
      "                 0.5318,\n",
      "                 0.4493,\n",
      "                 0.2481,\n",
      "                 0.1759,\n",
      "                 0.3186,\n",
      "                 0.6044,\n",
      "                 0.3611,\n",
      "                 0.4519,\n",
      "                 0.2912,\n",
      "                 0.4603,\n",
      "                 0.7052,\n",
      "                 0.3952,\n",
      "                 0.3398,\n",
      "                 0.3332,\n",
      "                 0.3028,\n",
      "                 0.2364,\n",
      "                 0.3899,\n",
      "                 0.1381,\n",
      "                 0.2578,\n",
      "                 0.3567,\n",
      "                 0.3975,\n",
      "                 0.132,\n",
      "                 0.2308,\n",
      "                 0.8252,\n",
      "                 0.4832,\n",
      "                 0.4483,\n",
      "                 0.5855,\n",
      "                 0.2209,\n",
      "                 0.36,\n",
      "                 0.2006,\n",
      "                 0.6083,\n",
      "                 0.5687,\n",
      "                 0.3048,\n",
      "                 0.4512,\n",
      "                 0.3565,\n",
      "                 0.4439,\n",
      "                 0.5983,\n",
      "                 0.285,\n",
      "                 0.1741,\n",
      "                 0.4871,\n",
      "                 0.164,\n",
      "                 0.2117],\n",
      "  'val_loss': [0.5779100656509399,\n",
      "               0.5759962797164917,\n",
      "               0.5722674131393433,\n",
      "               0.5640902519226074,\n",
      "               0.5573773980140686,\n",
      "               0.5535929799079895,\n",
      "               0.549949049949646,\n",
      "               0.5486936569213867,\n",
      "               0.5479177236557007,\n",
      "               0.5458911657333374,\n",
      "               0.5442951917648315,\n",
      "               0.5429588556289673,\n",
      "               0.5415700078010559,\n",
      "               0.5405259132385254,\n",
      "               0.5398462414741516,\n",
      "               0.5384230613708496,\n",
      "               0.5372956395149231,\n",
      "               0.5346681475639343,\n",
      "               0.5325101017951965,\n",
      "               0.530144453048706,\n",
      "               0.5280891060829163,\n",
      "               0.5261996984481812,\n",
      "               0.5246917605400085,\n",
      "               0.5230596661567688,\n",
      "               0.5211900472640991,\n",
      "               0.5201350450515747,\n",
      "               0.519230306148529,\n",
      "               0.5186260342597961,\n",
      "               0.5179481506347656,\n",
      "               0.5175355076789856,\n",
      "               0.5169385671615601,\n",
      "               0.5164985656738281,\n",
      "               0.5162174105644226,\n",
      "               0.5159298181533813,\n",
      "               0.5156415104866028,\n",
      "               0.5153260231018066,\n",
      "               0.5151647329330444,\n",
      "               0.5148182511329651,\n",
      "               0.5146533250808716,\n",
      "               0.5146048665046692]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.6556,\n",
      "                 0.5749,\n",
      "                 0.9674,\n",
      "                 0.5481,\n",
      "                 0.8822,\n",
      "                 0.8343,\n",
      "                 0.6635,\n",
      "                 0.8348,\n",
      "                 0.913,\n",
      "                 0.9666,\n",
      "                 0.3354,\n",
      "                 0.9816,\n",
      "                 0.619,\n",
      "                 1.1765,\n",
      "                 0.4843,\n",
      "                 0.3628,\n",
      "                 0.9414,\n",
      "                 0.8753,\n",
      "                 0.4461,\n",
      "                 0.3866,\n",
      "                 0.5609,\n",
      "                 0.7392,\n",
      "                 0.8865,\n",
      "                 0.4062,\n",
      "                 0.9274,\n",
      "                 0.468,\n",
      "                 0.5455,\n",
      "                 0.8554,\n",
      "                 0.8561,\n",
      "                 0.3509,\n",
      "                 0.6906,\n",
      "                 0.9319,\n",
      "                 0.6024,\n",
      "                 0.7702,\n",
      "                 0.545,\n",
      "                 0.352,\n",
      "                 1.1239,\n",
      "                 1.1451,\n",
      "                 0.564,\n",
      "                 0.4015,\n",
      "                 1.121,\n",
      "                 0.332,\n",
      "                 0.8625,\n",
      "                 0.6747,\n",
      "                 0.8063,\n",
      "                 0.3148,\n",
      "                 0.6874,\n",
      "                 0.495,\n",
      "                 0.6072,\n",
      "                 0.8721,\n",
      "                 0.3202,\n",
      "                 1.0922,\n",
      "                 0.5652,\n",
      "                 0.4089,\n",
      "                 0.8107,\n",
      "                 0.2046,\n",
      "                 1.2669,\n",
      "                 0.5995,\n",
      "                 0.7353,\n",
      "                 0.4066,\n",
      "                 0.548,\n",
      "                 0.7596,\n",
      "                 0.5412,\n",
      "                 0.6812,\n",
      "                 0.8592,\n",
      "                 1.0242,\n",
      "                 0.2453,\n",
      "                 0.7406,\n",
      "                 0.3006,\n",
      "                 0.8574,\n",
      "                 0.5412,\n",
      "                 0.7066,\n",
      "                 0.6028,\n",
      "                 0.8025,\n",
      "                 0.6342,\n",
      "                 0.9249,\n",
      "                 0.4419,\n",
      "                 0.3057,\n",
      "                 0.4889,\n",
      "                 0.8411,\n",
      "                 0.6186,\n",
      "                 0.8926,\n",
      "                 0.9881,\n",
      "                 0.3093,\n",
      "                 0.3153,\n",
      "                 0.682,\n",
      "                 0.7697,\n",
      "                 0.9563,\n",
      "                 0.5274,\n",
      "                 0.5455,\n",
      "                 0.6419,\n",
      "                 0.6675,\n",
      "                 0.5354,\n",
      "                 0.4228,\n",
      "                 0.9908,\n",
      "                 0.5439,\n",
      "                 0.5917,\n",
      "                 1.0971,\n",
      "                 0.2294,\n",
      "                 0.5668,\n",
      "                 0.6728,\n",
      "                 0.6962,\n",
      "                 0.6211,\n",
      "                 0.1588,\n",
      "                 1.3175,\n",
      "                 0.7712,\n",
      "                 0.302,\n",
      "                 0.4215,\n",
      "                 0.9425,\n",
      "                 0.585,\n",
      "                 0.2302,\n",
      "                 1.2272,\n",
      "                 0.4826,\n",
      "                 0.4646,\n",
      "                 0.2063,\n",
      "                 0.4792,\n",
      "                 0.7183,\n",
      "                 0.7366,\n",
      "                 0.6786,\n",
      "                 0.4138,\n",
      "                 0.6618,\n",
      "                 0.5285,\n",
      "                 0.3696,\n",
      "                 0.8508,\n",
      "                 0.6613,\n",
      "                 0.9377,\n",
      "                 0.5578,\n",
      "                 0.2659,\n",
      "                 0.653,\n",
      "                 0.9357,\n",
      "                 0.2473,\n",
      "                 0.5971,\n",
      "                 0.5748,\n",
      "                 0.1728,\n",
      "                 0.8376,\n",
      "                 0.416,\n",
      "                 0.9343,\n",
      "                 0.3283,\n",
      "                 0.34,\n",
      "                 0.1813,\n",
      "                 0.3819,\n",
      "                 0.5068,\n",
      "                 0.6413,\n",
      "                 0.6999,\n",
      "                 0.8505,\n",
      "                 0.8117,\n",
      "                 0.4684,\n",
      "                 0.6842,\n",
      "                 0.6218,\n",
      "                 0.3949,\n",
      "                 0.4234,\n",
      "                 0.3996,\n",
      "                 0.4419,\n",
      "                 0.444,\n",
      "                 0.3706,\n",
      "                 0.9922,\n",
      "                 0.7605,\n",
      "                 0.2059,\n",
      "                 0.5519,\n",
      "                 0.3657,\n",
      "                 0.3013,\n",
      "                 0.6346,\n",
      "                 0.2799,\n",
      "                 0.4842,\n",
      "                 0.6534,\n",
      "                 0.4248,\n",
      "                 0.6622,\n",
      "                 0.3483,\n",
      "                 0.5285,\n",
      "                 0.6397,\n",
      "                 0.4359,\n",
      "                 0.2622,\n",
      "                 0.895,\n",
      "                 0.663,\n",
      "                 0.4928,\n",
      "                 0.4389,\n",
      "                 0.3254,\n",
      "                 0.3453,\n",
      "                 0.355,\n",
      "                 0.3734,\n",
      "                 0.3421,\n",
      "                 0.7786,\n",
      "                 0.4213,\n",
      "                 0.4755,\n",
      "                 0.5494,\n",
      "                 0.5661,\n",
      "                 0.3491,\n",
      "                 0.1922,\n",
      "                 0.5772,\n",
      "                 0.518,\n",
      "                 0.4821,\n",
      "                 1.0165,\n",
      "                 0.6674,\n",
      "                 0.8969,\n",
      "                 0.832,\n",
      "                 0.6336,\n",
      "                 0.1909,\n",
      "                 0.6586,\n",
      "                 0.4736,\n",
      "                 0.4183,\n",
      "                 0.255,\n",
      "                 0.5557,\n",
      "                 0.2671,\n",
      "                 0.3301,\n",
      "                 0.506,\n",
      "                 0.9408,\n",
      "                 0.8334,\n",
      "                 0.759,\n",
      "                 0.8303,\n",
      "                 0.4342,\n",
      "                 0.4774,\n",
      "                 0.8752,\n",
      "                 0.4929,\n",
      "                 0.7244,\n",
      "                 0.2811,\n",
      "                 0.141,\n",
      "                 0.6612,\n",
      "                 0.234,\n",
      "                 0.6398,\n",
      "                 1.0409,\n",
      "                 0.4039,\n",
      "                 0.4455,\n",
      "                 0.5299,\n",
      "                 0.8958,\n",
      "                 0.1387,\n",
      "                 0.5381,\n",
      "                 0.3457,\n",
      "                 0.4692,\n",
      "                 0.6579,\n",
      "                 0.9836,\n",
      "                 0.5606,\n",
      "                 0.7336,\n",
      "                 0.5611,\n",
      "                 0.204,\n",
      "                 0.4505,\n",
      "                 0.2167,\n",
      "                 0.6929,\n",
      "                 1.0147,\n",
      "                 0.1801,\n",
      "                 0.6582,\n",
      "                 0.5414,\n",
      "                 0.7212,\n",
      "                 0.4413,\n",
      "                 0.3529,\n",
      "                 0.6102,\n",
      "                 0.2776,\n",
      "                 0.7831,\n",
      "                 0.2342,\n",
      "                 0.4513,\n",
      "                 0.2664,\n",
      "                 0.2465,\n",
      "                 0.4413,\n",
      "                 0.4184,\n",
      "                 0.7881,\n",
      "                 0.4849,\n",
      "                 0.3425,\n",
      "                 0.2015,\n",
      "                 0.4925,\n",
      "                 0.3966,\n",
      "                 0.4674,\n",
      "                 0.2269,\n",
      "                 0.3652,\n",
      "                 0.6633,\n",
      "                 1.0002,\n",
      "                 0.5187,\n",
      "                 0.5411,\n",
      "                 0.4845,\n",
      "                 0.3869,\n",
      "                 0.5725,\n",
      "                 0.436,\n",
      "                 0.3892,\n",
      "                 0.2847,\n",
      "                 0.2972,\n",
      "                 0.4861,\n",
      "                 0.5061,\n",
      "                 0.1756,\n",
      "                 0.4811,\n",
      "                 0.9756,\n",
      "                 0.6911,\n",
      "                 0.3651,\n",
      "                 0.2851,\n",
      "                 0.5805,\n",
      "                 0.3585,\n",
      "                 0.3943,\n",
      "                 0.2712,\n",
      "                 0.5693,\n",
      "                 0.256,\n",
      "                 0.6669,\n",
      "                 0.1796,\n",
      "                 0.2274,\n",
      "                 0.631,\n",
      "                 0.5372,\n",
      "                 0.5118,\n",
      "                 0.1154,\n",
      "                 0.3861,\n",
      "                 0.6334,\n",
      "                 0.4827,\n",
      "                 0.5566,\n",
      "                 0.2853,\n",
      "                 0.4828,\n",
      "                 0.5627,\n",
      "                 0.6123,\n",
      "                 0.2672,\n",
      "                 0.8928,\n",
      "                 0.404,\n",
      "                 0.4283,\n",
      "                 0.6142,\n",
      "                 0.3313,\n",
      "                 0.1901,\n",
      "                 0.4312,\n",
      "                 0.3136,\n",
      "                 0.5271,\n",
      "                 0.3481,\n",
      "                 0.2709,\n",
      "                 0.4199,\n",
      "                 0.6471,\n",
      "                 0.5177,\n",
      "                 0.1157,\n",
      "                 1.0454,\n",
      "                 0.4089],\n",
      "  'val_loss': [0.5781622529029846,\n",
      "               0.5755650997161865,\n",
      "               0.570477306842804,\n",
      "               0.5666488409042358,\n",
      "               0.5652552843093872,\n",
      "               0.5682371854782104,\n",
      "               0.5741523504257202,\n",
      "               0.573784589767456,\n",
      "               0.576994776725769,\n",
      "               0.5810468792915344,\n",
      "               0.5792295336723328,\n",
      "               0.5754822492599487,\n",
      "               0.5763672590255737,\n",
      "               0.5791569948196411,\n",
      "               0.5775710940361023,\n",
      "               0.5773320198059082,\n",
      "               0.574817955493927,\n",
      "               0.5773640871047974,\n",
      "               0.5771891474723816,\n",
      "               0.5796284675598145,\n",
      "               0.5791186094284058,\n",
      "               0.5804052352905273,\n",
      "               0.5790531039237976,\n",
      "               0.5799471139907837,\n",
      "               0.5788903832435608,\n",
      "               0.5795086622238159,\n",
      "               0.579933762550354,\n",
      "               0.5790453553199768,\n",
      "               0.5790569186210632,\n",
      "               0.5796419978141785,\n",
      "               0.5787555575370789,\n",
      "               0.5779547691345215,\n",
      "               0.5779174566268921,\n",
      "               0.5770056843757629,\n",
      "               0.5765862464904785,\n",
      "               0.5764504075050354,\n",
      "               0.5769127011299133,\n",
      "               0.5770668983459473,\n",
      "               0.5769267678260803,\n",
      "               0.5769262313842773]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.1987,\n",
      "                 1.6899,\n",
      "                 1.2359,\n",
      "                 1.344,\n",
      "                 1.2749,\n",
      "                 1.1517,\n",
      "                 0.3393,\n",
      "                 0.2489,\n",
      "                 0.2334,\n",
      "                 0.6325,\n",
      "                 1.1528,\n",
      "                 1.0976,\n",
      "                 0.2849,\n",
      "                 1.697,\n",
      "                 1.3866,\n",
      "                 0.5666,\n",
      "                 1.0577,\n",
      "                 0.1501,\n",
      "                 1.2083,\n",
      "                 0.8204,\n",
      "                 1.031,\n",
      "                 0.9538,\n",
      "                 0.3254,\n",
      "                 1.4519,\n",
      "                 0.9526,\n",
      "                 1.3171,\n",
      "                 0.4556,\n",
      "                 1.1236,\n",
      "                 1.6053,\n",
      "                 0.1421,\n",
      "                 1.3935,\n",
      "                 0.1866,\n",
      "                 0.1967,\n",
      "                 0.8104,\n",
      "                 1.2158,\n",
      "                 0.7378,\n",
      "                 0.7199,\n",
      "                 1.0516,\n",
      "                 0.2961,\n",
      "                 1.839,\n",
      "                 0.1771,\n",
      "                 0.9966,\n",
      "                 1.4368,\n",
      "                 1.3725,\n",
      "                 1.0006,\n",
      "                 0.0729,\n",
      "                 0.7047,\n",
      "                 0.3208,\n",
      "                 0.8198,\n",
      "                 0.7687,\n",
      "                 0.617,\n",
      "                 1.3971,\n",
      "                 0.4936,\n",
      "                 1.1377,\n",
      "                 0.2522,\n",
      "                 0.9134,\n",
      "                 0.4551,\n",
      "                 0.1853,\n",
      "                 0.1766,\n",
      "                 1.5181,\n",
      "                 1.2478,\n",
      "                 1.6957,\n",
      "                 0.8413,\n",
      "                 0.6182,\n",
      "                 0.8281,\n",
      "                 1.3605,\n",
      "                 1.3168,\n",
      "                 0.2065,\n",
      "                 0.0475,\n",
      "                 0.927,\n",
      "                 1.4089,\n",
      "                 0.8149,\n",
      "                 1.0307,\n",
      "                 0.3751,\n",
      "                 1.6509,\n",
      "                 0.0933,\n",
      "                 1.6776,\n",
      "                 0.771,\n",
      "                 0.34,\n",
      "                 0.7566,\n",
      "                 1.7919,\n",
      "                 1.0329,\n",
      "                 1.4634,\n",
      "                 0.1382,\n",
      "                 0.6834,\n",
      "                 0.1187,\n",
      "                 1.2102,\n",
      "                 0.5585,\n",
      "                 1.0869,\n",
      "                 0.2118,\n",
      "                 1.0673,\n",
      "                 0.2946,\n",
      "                 1.3287,\n",
      "                 0.3742,\n",
      "                 0.6551,\n",
      "                 0.8713,\n",
      "                 0.7581,\n",
      "                 0.6126,\n",
      "                 0.4916,\n",
      "                 0.9688,\n",
      "                 1.0585,\n",
      "                 0.6259,\n",
      "                 0.2806,\n",
      "                 0.8113,\n",
      "                 0.9277,\n",
      "                 0.7613,\n",
      "                 0.5231,\n",
      "                 0.9095,\n",
      "                 0.9641,\n",
      "                 0.9316,\n",
      "                 0.3049,\n",
      "                 0.4089,\n",
      "                 0.8103,\n",
      "                 0.8288,\n",
      "                 0.9712,\n",
      "                 0.9074,\n",
      "                 0.7019,\n",
      "                 0.1863,\n",
      "                 0.8301,\n",
      "                 0.8391,\n",
      "                 0.5304,\n",
      "                 1.3406,\n",
      "                 0.622,\n",
      "                 0.6101,\n",
      "                 1.106,\n",
      "                 1.0962,\n",
      "                 0.3766,\n",
      "                 0.0609,\n",
      "                 1.6887,\n",
      "                 0.2749,\n",
      "                 0.1921,\n",
      "                 0.5422,\n",
      "                 0.1472,\n",
      "                 0.5159,\n",
      "                 0.6865,\n",
      "                 1.2421,\n",
      "                 1.439,\n",
      "                 0.0619,\n",
      "                 0.8798,\n",
      "                 0.6847,\n",
      "                 0.6233,\n",
      "                 1.1423,\n",
      "                 0.9022,\n",
      "                 0.2908,\n",
      "                 0.6716,\n",
      "                 1.8057,\n",
      "                 0.2559,\n",
      "                 0.883,\n",
      "                 0.8581,\n",
      "                 1.6418,\n",
      "                 0.4822,\n",
      "                 0.1204,\n",
      "                 0.8934,\n",
      "                 1.5836,\n",
      "                 1.9654,\n",
      "                 0.2802,\n",
      "                 0.3344,\n",
      "                 1.3001,\n",
      "                 0.2813,\n",
      "                 0.0635,\n",
      "                 0.9312,\n",
      "                 1.0039,\n",
      "                 0.3635,\n",
      "                 1.0147,\n",
      "                 1.4644,\n",
      "                 0.2029,\n",
      "                 0.9242,\n",
      "                 0.1745,\n",
      "                 0.3846,\n",
      "                 0.8077,\n",
      "                 1.6325,\n",
      "                 0.0857,\n",
      "                 1.0279,\n",
      "                 0.9237,\n",
      "                 0.4074,\n",
      "                 0.5041,\n",
      "                 0.1063,\n",
      "                 0.996,\n",
      "                 0.8874,\n",
      "                 0.9724,\n",
      "                 1.0591,\n",
      "                 0.2085,\n",
      "                 0.5477,\n",
      "                 1.0467,\n",
      "                 1.0801,\n",
      "                 1.0574,\n",
      "                 0.7543,\n",
      "                 0.4094,\n",
      "                 0.7831,\n",
      "                 0.9892,\n",
      "                 0.104,\n",
      "                 0.1298,\n",
      "                 0.7321,\n",
      "                 0.3087,\n",
      "                 0.1368,\n",
      "                 0.7973,\n",
      "                 1.5075,\n",
      "                 0.7181,\n",
      "                 0.1371,\n",
      "                 0.9345,\n",
      "                 0.7284,\n",
      "                 0.4068,\n",
      "                 0.4706,\n",
      "                 1.0452,\n",
      "                 0.9218,\n",
      "                 0.4656,\n",
      "                 0.6864,\n",
      "                 0.2415,\n",
      "                 0.1339,\n",
      "                 0.1592,\n",
      "                 1.0844,\n",
      "                 1.5717,\n",
      "                 0.4033,\n",
      "                 0.3187,\n",
      "                 0.825,\n",
      "                 0.4641,\n",
      "                 0.6836,\n",
      "                 0.5017,\n",
      "                 0.085,\n",
      "                 0.9505,\n",
      "                 0.3234,\n",
      "                 0.7028,\n",
      "                 0.8757,\n",
      "                 0.4383,\n",
      "                 0.266,\n",
      "                 0.1348,\n",
      "                 0.6945,\n",
      "                 1.02,\n",
      "                 0.3417,\n",
      "                 1.4162,\n",
      "                 0.2677,\n",
      "                 0.813,\n",
      "                 0.6246,\n",
      "                 0.2416,\n",
      "                 0.2161,\n",
      "                 1.0227,\n",
      "                 0.619,\n",
      "                 1.3903,\n",
      "                 0.1801,\n",
      "                 0.3059,\n",
      "                 0.1159,\n",
      "                 0.689,\n",
      "                 1.3815,\n",
      "                 0.5982,\n",
      "                 0.2703,\n",
      "                 0.1295,\n",
      "                 1.6646,\n",
      "                 0.9769,\n",
      "                 0.1839,\n",
      "                 0.3443,\n",
      "                 0.826,\n",
      "                 1.3678,\n",
      "                 1.7612,\n",
      "                 0.3949,\n",
      "                 0.2179,\n",
      "                 0.3496,\n",
      "                 0.1341,\n",
      "                 0.4691,\n",
      "                 0.1733,\n",
      "                 0.7371,\n",
      "                 0.3222,\n",
      "                 0.2742,\n",
      "                 1.6221,\n",
      "                 0.4939,\n",
      "                 0.1173,\n",
      "                 0.8008,\n",
      "                 0.1554,\n",
      "                 0.8855,\n",
      "                 0.7618,\n",
      "                 0.6724,\n",
      "                 1.1828,\n",
      "                 0.1447,\n",
      "                 1.2575,\n",
      "                 0.2337,\n",
      "                 0.8033,\n",
      "                 0.1865,\n",
      "                 0.0625,\n",
      "                 0.7377,\n",
      "                 0.5322,\n",
      "                 0.4645,\n",
      "                 0.4211,\n",
      "                 1.75,\n",
      "                 0.1546,\n",
      "                 0.8652,\n",
      "                 0.3028,\n",
      "                 0.496,\n",
      "                 0.3719,\n",
      "                 0.6658,\n",
      "                 0.6786,\n",
      "                 1.1459,\n",
      "                 0.6925,\n",
      "                 0.2315,\n",
      "                 0.5011,\n",
      "                 0.5674,\n",
      "                 0.8838,\n",
      "                 0.2085,\n",
      "                 0.5912,\n",
      "                 0.1462,\n",
      "                 0.8888,\n",
      "                 0.0677,\n",
      "                 0.2588,\n",
      "                 0.8715,\n",
      "                 0.4313,\n",
      "                 0.8584,\n",
      "                 0.5081,\n",
      "                 1.1994,\n",
      "                 0.3321,\n",
      "                 0.1182,\n",
      "                 0.775,\n",
      "                 1.0599,\n",
      "                 0.5911,\n",
      "                 0.2084,\n",
      "                 0.646,\n",
      "                 0.4111,\n",
      "                 0.8542,\n",
      "                 0.8483,\n",
      "                 0.9095,\n",
      "                 0.5609,\n",
      "                 0.1545,\n",
      "                 0.6096],\n",
      "  'val_loss': [0.5769524574279785,\n",
      "               0.571523904800415,\n",
      "               0.5654837489128113,\n",
      "               0.5601164102554321,\n",
      "               0.5549647212028503,\n",
      "               0.5524051785469055,\n",
      "               0.554253876209259,\n",
      "               0.5581508278846741,\n",
      "               0.5617882013320923,\n",
      "               0.5645330548286438,\n",
      "               0.5664270520210266,\n",
      "               0.5703614354133606,\n",
      "               0.5722862482070923,\n",
      "               0.5744714736938477,\n",
      "               0.574924647808075,\n",
      "               0.5769888162612915,\n",
      "               0.5806692838668823,\n",
      "               0.5845947265625,\n",
      "               0.587591826915741,\n",
      "               0.5884376764297485,\n",
      "               0.5907518267631531,\n",
      "               0.5906890630722046,\n",
      "               0.5922492146492004,\n",
      "               0.594488263130188,\n",
      "               0.5958887338638306,\n",
      "               0.5960021018981934,\n",
      "               0.5948814153671265,\n",
      "               0.5953174233436584,\n",
      "               0.5949594378471375,\n",
      "               0.5949690937995911,\n",
      "               0.594192624092102,\n",
      "               0.5948413610458374,\n",
      "               0.5959823131561279,\n",
      "               0.5958853960037231,\n",
      "               0.5957350134849548,\n",
      "               0.5963733792304993,\n",
      "               0.5968917012214661,\n",
      "               0.5969058871269226,\n",
      "               0.5969979166984558,\n",
      "               0.5970695614814758]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [0.659,\n",
      "                 1.1929,\n",
      "                 1.0536,\n",
      "                 1.5913,\n",
      "                 2.2156,\n",
      "                 0.9219,\n",
      "                 0.9931,\n",
      "                 1.2457,\n",
      "                 0.7819,\n",
      "                 1.905,\n",
      "                 1.166,\n",
      "                 1.2131,\n",
      "                 1.1189,\n",
      "                 2.4542,\n",
      "                 1.1825,\n",
      "                 0.4302,\n",
      "                 0.8368,\n",
      "                 0.7151,\n",
      "                 1.7273,\n",
      "                 0.9969,\n",
      "                 2.2439,\n",
      "                 1.4457,\n",
      "                 0.9064,\n",
      "                 0.9553,\n",
      "                 0.9284,\n",
      "                 0.48,\n",
      "                 0.914,\n",
      "                 1.5913,\n",
      "                 1.0614,\n",
      "                 0.8297,\n",
      "                 1.8552,\n",
      "                 1.2072,\n",
      "                 0.4791,\n",
      "                 1.3332,\n",
      "                 1.1599,\n",
      "                 1.295,\n",
      "                 1.4576,\n",
      "                 0.7251,\n",
      "                 1.486,\n",
      "                 1.1606,\n",
      "                 1.0171,\n",
      "                 1.4675,\n",
      "                 1.7966,\n",
      "                 1.0948,\n",
      "                 0.554,\n",
      "                 1.0638,\n",
      "                 0.6869,\n",
      "                 1.0303,\n",
      "                 1.5206,\n",
      "                 0.9702,\n",
      "                 0.7125,\n",
      "                 1.1812,\n",
      "                 0.5894,\n",
      "                 1.4223,\n",
      "                 0.8186,\n",
      "                 1.5516,\n",
      "                 0.9171,\n",
      "                 1.174,\n",
      "                 0.736,\n",
      "                 1.7653,\n",
      "                 1.3317,\n",
      "                 0.8371,\n",
      "                 1.5721,\n",
      "                 0.7547,\n",
      "                 0.981,\n",
      "                 1.5434,\n",
      "                 1.1861,\n",
      "                 0.7789,\n",
      "                 1.1579,\n",
      "                 1.273,\n",
      "                 1.1516,\n",
      "                 0.7745,\n",
      "                 0.6688,\n",
      "                 0.4647,\n",
      "                 1.2931,\n",
      "                 0.8996,\n",
      "                 1.3994,\n",
      "                 1.2228,\n",
      "                 1.0205,\n",
      "                 1.2324,\n",
      "                 1.808,\n",
      "                 1.093,\n",
      "                 1.1792,\n",
      "                 1.396,\n",
      "                 0.6779,\n",
      "                 0.7655,\n",
      "                 1.1299,\n",
      "                 0.9332,\n",
      "                 1.0378,\n",
      "                 1.3243,\n",
      "                 0.8613,\n",
      "                 0.5214,\n",
      "                 1.1933,\n",
      "                 0.4211,\n",
      "                 1.1843,\n",
      "                 1.4375,\n",
      "                 0.7819,\n",
      "                 0.6751,\n",
      "                 1.4212,\n",
      "                 0.8557,\n",
      "                 1.0121,\n",
      "                 0.9015,\n",
      "                 0.4094,\n",
      "                 1.0274,\n",
      "                 0.9965,\n",
      "                 1.2285,\n",
      "                 0.4634,\n",
      "                 0.9347,\n",
      "                 1.3887,\n",
      "                 0.958,\n",
      "                 1.1713,\n",
      "                 0.9813,\n",
      "                 1.8017,\n",
      "                 1.1006,\n",
      "                 0.8851,\n",
      "                 0.7144,\n",
      "                 1.315,\n",
      "                 0.8996,\n",
      "                 0.628,\n",
      "                 0.765,\n",
      "                 0.5114,\n",
      "                 1.4613,\n",
      "                 0.9197,\n",
      "                 0.4533,\n",
      "                 1.2934,\n",
      "                 0.8065,\n",
      "                 0.5154,\n",
      "                 1.1415,\n",
      "                 1.4113,\n",
      "                 0.8982,\n",
      "                 1.1017,\n",
      "                 0.4183,\n",
      "                 0.5239,\n",
      "                 0.8574,\n",
      "                 1.153,\n",
      "                 0.9535,\n",
      "                 0.8351,\n",
      "                 0.9037,\n",
      "                 0.6942,\n",
      "                 0.475,\n",
      "                 0.9587,\n",
      "                 1.1111,\n",
      "                 1.434,\n",
      "                 0.7363,\n",
      "                 0.7716,\n",
      "                 0.972,\n",
      "                 1.1366,\n",
      "                 0.8156,\n",
      "                 0.7839,\n",
      "                 1.1256,\n",
      "                 0.6522,\n",
      "                 0.5083,\n",
      "                 0.7606,\n",
      "                 1.3527,\n",
      "                 0.9908,\n",
      "                 0.8745,\n",
      "                 0.5226,\n",
      "                 0.8406,\n",
      "                 0.9333,\n",
      "                 0.8159,\n",
      "                 0.8941,\n",
      "                 0.9919,\n",
      "                 0.2751,\n",
      "                 0.9498,\n",
      "                 1.3217,\n",
      "                 0.6838,\n",
      "                 0.823,\n",
      "                 1.1074,\n",
      "                 0.2871,\n",
      "                 1.0429,\n",
      "                 0.823,\n",
      "                 1.1666,\n",
      "                 1.1253,\n",
      "                 0.8795,\n",
      "                 0.636,\n",
      "                 0.5376,\n",
      "                 0.9214,\n",
      "                 1.2703,\n",
      "                 0.5466,\n",
      "                 0.7983,\n",
      "                 1.21,\n",
      "                 0.7923,\n",
      "                 0.608,\n",
      "                 0.7328,\n",
      "                 0.5601,\n",
      "                 0.8875,\n",
      "                 0.896,\n",
      "                 0.4885,\n",
      "                 0.9963,\n",
      "                 1.3236,\n",
      "                 0.8844,\n",
      "                 0.816,\n",
      "                 0.778,\n",
      "                 0.6479,\n",
      "                 0.5834,\n",
      "                 0.4385,\n",
      "                 0.9178,\n",
      "                 0.3967,\n",
      "                 0.9619,\n",
      "                 0.7646,\n",
      "                 0.4872,\n",
      "                 0.6334,\n",
      "                 0.5424,\n",
      "                 0.9693,\n",
      "                 1.4352,\n",
      "                 0.5722,\n",
      "                 0.8809,\n",
      "                 0.9019,\n",
      "                 0.8261,\n",
      "                 0.8089,\n",
      "                 0.6098,\n",
      "                 1.1013,\n",
      "                 0.3837,\n",
      "                 0.8489,\n",
      "                 0.552,\n",
      "                 0.9436,\n",
      "                 1.4185,\n",
      "                 0.3671,\n",
      "                 0.4971,\n",
      "                 1.0311,\n",
      "                 0.828,\n",
      "                 0.8989,\n",
      "                 1.1921,\n",
      "                 0.5067,\n",
      "                 1.1283,\n",
      "                 0.5162,\n",
      "                 0.7008,\n",
      "                 0.7502,\n",
      "                 1.0253,\n",
      "                 1.0584,\n",
      "                 0.919,\n",
      "                 0.5825,\n",
      "                 0.7508,\n",
      "                 0.2614,\n",
      "                 0.396,\n",
      "                 0.6995,\n",
      "                 0.8503,\n",
      "                 0.9366,\n",
      "                 1.1415,\n",
      "                 0.63,\n",
      "                 0.4194,\n",
      "                 0.492,\n",
      "                 0.6081,\n",
      "                 0.8424,\n",
      "                 0.9339,\n",
      "                 0.8342,\n",
      "                 0.8275,\n",
      "                 0.8633,\n",
      "                 0.7811,\n",
      "                 0.4234,\n",
      "                 0.711,\n",
      "                 0.9075,\n",
      "                 1.2845,\n",
      "                 0.5421,\n",
      "                 0.9681,\n",
      "                 0.5577,\n",
      "                 0.7291,\n",
      "                 0.5001,\n",
      "                 0.4754,\n",
      "                 0.6582,\n",
      "                 0.485,\n",
      "                 0.6159,\n",
      "                 0.9805,\n",
      "                 0.6704,\n",
      "                 0.5051,\n",
      "                 0.7523,\n",
      "                 0.5462,\n",
      "                 0.4969,\n",
      "                 1.0893,\n",
      "                 0.5488,\n",
      "                 1.305,\n",
      "                 0.8952,\n",
      "                 1.1809,\n",
      "                 0.8678,\n",
      "                 0.671,\n",
      "                 1.1902,\n",
      "                 0.5953,\n",
      "                 0.6492,\n",
      "                 0.8049,\n",
      "                 0.8967,\n",
      "                 0.5749,\n",
      "                 0.9845,\n",
      "                 0.8205,\n",
      "                 0.6061,\n",
      "                 0.2594,\n",
      "                 0.7496,\n",
      "                 0.8889,\n",
      "                 0.8783,\n",
      "                 1.1103,\n",
      "                 0.501,\n",
      "                 1.0438,\n",
      "                 0.7528,\n",
      "                 0.2751,\n",
      "                 0.8201,\n",
      "                 0.9892,\n",
      "                 0.4909,\n",
      "                 0.5682,\n",
      "                 0.4638,\n",
      "                 0.6615,\n",
      "                 0.8002,\n",
      "                 0.6387,\n",
      "                 0.3811,\n",
      "                 0.643,\n",
      "                 1.0277,\n",
      "                 0.6908,\n",
      "                 1.0988,\n",
      "                 0.5146,\n",
      "                 0.8408,\n",
      "                 0.6025,\n",
      "                 0.6788,\n",
      "                 0.489,\n",
      "                 0.573,\n",
      "                 0.4116,\n",
      "                 0.6745,\n",
      "                 0.7278,\n",
      "                 0.6541,\n",
      "                 0.9552,\n",
      "                 0.9046,\n",
      "                 0.4966,\n",
      "                 0.616],\n",
      "  'val_loss': [0.5788252353668213,\n",
      "               0.5811716318130493,\n",
      "               0.5825923681259155,\n",
      "               0.5805476903915405,\n",
      "               0.5817404985427856,\n",
      "               0.5807759165763855,\n",
      "               0.5814650058746338,\n",
      "               0.5851989388465881,\n",
      "               0.5847878456115723,\n",
      "               0.5811498761177063,\n",
      "               0.5795871019363403,\n",
      "               0.5848042368888855,\n",
      "               0.5862478613853455,\n",
      "               0.5838801264762878,\n",
      "               0.5844146609306335,\n",
      "               0.5821942090988159,\n",
      "               0.5890134572982788,\n",
      "               0.5918096303939819,\n",
      "               0.5977479219436646,\n",
      "               0.5972703695297241,\n",
      "               0.5966426134109497,\n",
      "               0.5948887467384338,\n",
      "               0.5970975160598755,\n",
      "               0.5930511951446533,\n",
      "               0.596218466758728,\n",
      "               0.5964746475219727,\n",
      "               0.6003320813179016,\n",
      "               0.6040111780166626,\n",
      "               0.6090005040168762,\n",
      "               0.6102169156074524,\n",
      "               0.613667368888855,\n",
      "               0.615081250667572,\n",
      "               0.617088794708252,\n",
      "               0.6178765296936035,\n",
      "               0.6185828447341919,\n",
      "               0.619225800037384,\n",
      "               0.6193019151687622,\n",
      "               0.6195178627967834,\n",
      "               0.6198326945304871,\n",
      "               0.6200647354125977]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 16,\n",
      "  'train_loss': [1.5208,\n",
      "                 1.2238,\n",
      "                 0.8949,\n",
      "                 0.8002,\n",
      "                 0.3429,\n",
      "                 1.9946,\n",
      "                 0.9858,\n",
      "                 1.915,\n",
      "                 1.6351,\n",
      "                 2.151,\n",
      "                 2.0867,\n",
      "                 0.7422,\n",
      "                 1.5228,\n",
      "                 0.2941,\n",
      "                 1.0697,\n",
      "                 0.838,\n",
      "                 1.3036,\n",
      "                 1.9965,\n",
      "                 0.7202,\n",
      "                 0.5975,\n",
      "                 1.0026,\n",
      "                 0.8469,\n",
      "                 1.7119,\n",
      "                 1.0038,\n",
      "                 2.0627,\n",
      "                 0.8719,\n",
      "                 0.3675,\n",
      "                 1.0462,\n",
      "                 0.7726,\n",
      "                 1.7711,\n",
      "                 0.3986,\n",
      "                 2.2436,\n",
      "                 0.9132,\n",
      "                 1.2709,\n",
      "                 0.8741,\n",
      "                 0.7353,\n",
      "                 1.5555,\n",
      "                 0.5692,\n",
      "                 2.0691,\n",
      "                 1.1803,\n",
      "                 1.8836,\n",
      "                 0.2821,\n",
      "                 0.5821,\n",
      "                 1.2137,\n",
      "                 0.5983,\n",
      "                 1.5942,\n",
      "                 0.697,\n",
      "                 1.0241,\n",
      "                 1.9089,\n",
      "                 0.5446,\n",
      "                 1.3352,\n",
      "                 0.6236,\n",
      "                 1.1359,\n",
      "                 0.6174,\n",
      "                 1.4209,\n",
      "                 0.6767,\n",
      "                 0.8921,\n",
      "                 1.7102,\n",
      "                 1.5205,\n",
      "                 0.2086,\n",
      "                 1.1056,\n",
      "                 1.056,\n",
      "                 0.455,\n",
      "                 0.9681,\n",
      "                 1.4285,\n",
      "                 0.1326,\n",
      "                 0.8575,\n",
      "                 1.819,\n",
      "                 1.7419,\n",
      "                 1.3813,\n",
      "                 0.219,\n",
      "                 0.5897,\n",
      "                 1.0818,\n",
      "                 1.0105,\n",
      "                 0.1783,\n",
      "                 1.7947,\n",
      "                 0.0973,\n",
      "                 0.5959,\n",
      "                 1.3047,\n",
      "                 0.9068,\n",
      "                 0.1771,\n",
      "                 1.1691,\n",
      "                 1.0624,\n",
      "                 1.2588,\n",
      "                 0.5231,\n",
      "                 2.2396,\n",
      "                 0.7152,\n",
      "                 0.508,\n",
      "                 0.4825,\n",
      "                 1.5443,\n",
      "                 0.6188,\n",
      "                 0.4446,\n",
      "                 0.841,\n",
      "                 1.0443,\n",
      "                 1.6073,\n",
      "                 0.8106,\n",
      "                 0.6199,\n",
      "                 1.2057,\n",
      "                 0.851,\n",
      "                 0.3976,\n",
      "                 1.4379,\n",
      "                 1.574,\n",
      "                 0.4834,\n",
      "                 0.3008,\n",
      "                 0.7845,\n",
      "                 0.6323,\n",
      "                 0.8763,\n",
      "                 0.7556,\n",
      "                 0.1232,\n",
      "                 0.9874,\n",
      "                 0.3726,\n",
      "                 1.7552,\n",
      "                 0.5074,\n",
      "                 0.9979,\n",
      "                 0.1925,\n",
      "                 0.651,\n",
      "                 1.5723,\n",
      "                 1.0546,\n",
      "                 1.1078,\n",
      "                 0.8607,\n",
      "                 1.6446,\n",
      "                 0.1511,\n",
      "                 1.6126,\n",
      "                 1.0666,\n",
      "                 0.364,\n",
      "                 0.9072,\n",
      "                 0.1087,\n",
      "                 1.4018,\n",
      "                 0.1064,\n",
      "                 1.8746,\n",
      "                 0.5733,\n",
      "                 0.493,\n",
      "                 2.1826,\n",
      "                 0.7402,\n",
      "                 0.7057,\n",
      "                 0.5011,\n",
      "                 0.6193,\n",
      "                 1.1029,\n",
      "                 0.14,\n",
      "                 0.3781,\n",
      "                 0.6769,\n",
      "                 0.6212,\n",
      "                 0.6761,\n",
      "                 2.0776,\n",
      "                 1.5417,\n",
      "                 0.5814,\n",
      "                 0.9394,\n",
      "                 0.3464,\n",
      "                 1.1056,\n",
      "                 0.0892,\n",
      "                 0.1003,\n",
      "                 1.1076,\n",
      "                 0.6976,\n",
      "                 0.1203,\n",
      "                 0.561,\n",
      "                 1.3502,\n",
      "                 1.6342,\n",
      "                 0.3099,\n",
      "                 1.1106,\n",
      "                 0.4217,\n",
      "                 0.1338,\n",
      "                 0.3437,\n",
      "                 1.4365,\n",
      "                 0.8154,\n",
      "                 0.5113,\n",
      "                 0.7433,\n",
      "                 1.322,\n",
      "                 0.6701,\n",
      "                 1.1855,\n",
      "                 0.1814,\n",
      "                 0.5362,\n",
      "                 1.2,\n",
      "                 1.2501,\n",
      "                 0.358,\n",
      "                 0.0926,\n",
      "                 1.1571,\n",
      "                 0.3824,\n",
      "                 0.2287,\n",
      "                 0.9487,\n",
      "                 0.3608,\n",
      "                 0.2318,\n",
      "                 2.3315,\n",
      "                 1.3327,\n",
      "                 0.4678,\n",
      "                 0.5386,\n",
      "                 0.8041,\n",
      "                 0.6356,\n",
      "                 0.7625,\n",
      "                 0.4408,\n",
      "                 0.174,\n",
      "                 0.3561,\n",
      "                 1.7797,\n",
      "                 0.857,\n",
      "                 0.1951,\n",
      "                 2.0727,\n",
      "                 0.5151,\n",
      "                 0.1181,\n",
      "                 0.9869,\n",
      "                 0.7919,\n",
      "                 0.6985,\n",
      "                 0.8941,\n",
      "                 0.1449,\n",
      "                 0.5566,\n",
      "                 0.1495,\n",
      "                 0.4678,\n",
      "                 1.4121,\n",
      "                 0.3402,\n",
      "                 1.0115,\n",
      "                 1.8088,\n",
      "                 0.9694,\n",
      "                 0.5464,\n",
      "                 0.0452,\n",
      "                 1.1479,\n",
      "                 0.1984,\n",
      "                 0.1084,\n",
      "                 0.3922,\n",
      "                 0.203,\n",
      "                 0.2408,\n",
      "                 1.6455,\n",
      "                 0.7057,\n",
      "                 0.849,\n",
      "                 0.5941,\n",
      "                 0.3352,\n",
      "                 0.4684,\n",
      "                 0.5943,\n",
      "                 0.7139,\n",
      "                 0.9686,\n",
      "                 0.0758,\n",
      "                 1.4023,\n",
      "                 0.4974,\n",
      "                 0.8086,\n",
      "                 0.7557,\n",
      "                 0.06,\n",
      "                 1.0236,\n",
      "                 0.868,\n",
      "                 0.0875,\n",
      "                 0.6337,\n",
      "                 0.4777,\n",
      "                 1.0849,\n",
      "                 1.2604,\n",
      "                 1.9583,\n",
      "                 0.0959,\n",
      "                 0.1643,\n",
      "                 1.0315,\n",
      "                 0.4292,\n",
      "                 1.2334,\n",
      "                 0.4719,\n",
      "                 0.121,\n",
      "                 0.3715,\n",
      "                 0.9488,\n",
      "                 0.7334,\n",
      "                 0.4744,\n",
      "                 0.0901,\n",
      "                 1.5597,\n",
      "                 0.8822,\n",
      "                 0.3639,\n",
      "                 0.4594,\n",
      "                 0.5943,\n",
      "                 1.1733,\n",
      "                 0.2401,\n",
      "                 0.0869,\n",
      "                 1.0631,\n",
      "                 0.035,\n",
      "                 1.4994,\n",
      "                 1.6517,\n",
      "                 0.689,\n",
      "                 0.414,\n",
      "                 0.1379,\n",
      "                 0.1914,\n",
      "                 0.812,\n",
      "                 0.3619,\n",
      "                 1.2202,\n",
      "                 0.0836,\n",
      "                 0.4229,\n",
      "                 0.1259,\n",
      "                 0.731,\n",
      "                 1.2744,\n",
      "                 0.7124,\n",
      "                 1.0217,\n",
      "                 0.2856,\n",
      "                 0.2286,\n",
      "                 0.0887,\n",
      "                 1.263,\n",
      "                 0.14,\n",
      "                 0.8343,\n",
      "                 0.5604,\n",
      "                 0.7647,\n",
      "                 1.1336,\n",
      "                 0.562,\n",
      "                 0.2618,\n",
      "                 0.4895,\n",
      "                 0.9937,\n",
      "                 1.861,\n",
      "                 0.3435,\n",
      "                 0.0977,\n",
      "                 1.1942,\n",
      "                 0.6099,\n",
      "                 1.4943,\n",
      "                 0.0706,\n",
      "                 0.557,\n",
      "                 0.9601,\n",
      "                 0.5375,\n",
      "                 0.1196,\n",
      "                 0.7505,\n",
      "                 0.3116,\n",
      "                 0.0505,\n",
      "                 1.128,\n",
      "                 0.3841,\n",
      "                 0.5253,\n",
      "                 0.5613,\n",
      "                 1.1203,\n",
      "                 1.19,\n",
      "                 0.27,\n",
      "                 0.8163,\n",
      "                 0.5366,\n",
      "                 0.5166,\n",
      "                 0.4261,\n",
      "                 0.3892,\n",
      "                 1.0531,\n",
      "                 1.1089],\n",
      "  'val_loss': [0.5765315294265747,\n",
      "               0.5717545747756958,\n",
      "               0.5700541138648987,\n",
      "               0.5613851547241211,\n",
      "               0.5577799081802368,\n",
      "               0.5547692775726318,\n",
      "               0.5516780614852905,\n",
      "               0.5485532283782959,\n",
      "               0.5458609461784363,\n",
      "               0.5441464185714722,\n",
      "               0.542737603187561,\n",
      "               0.5419324040412903,\n",
      "               0.5408005118370056,\n",
      "               0.5393007397651672,\n",
      "               0.5393214225769043,\n",
      "               0.5374678373336792,\n",
      "               0.5357578992843628,\n",
      "               0.5350523591041565,\n",
      "               0.5351155400276184,\n",
      "               0.5343121886253357,\n",
      "               0.5339641571044922,\n",
      "               0.5337988138198853,\n",
      "               0.5337890386581421,\n",
      "               0.5333872437477112,\n",
      "               0.5338934063911438,\n",
      "               0.5346373319625854,\n",
      "               0.5351365208625793,\n",
      "               0.5357660055160522,\n",
      "               0.5352624654769897,\n",
      "               0.5339688062667847,\n",
      "               0.5333048105239868,\n",
      "               0.5328525304794312,\n",
      "               0.5330957770347595,\n",
      "               0.5331546068191528,\n",
      "               0.5332411527633667,\n",
      "               0.5333898663520813,\n",
      "               0.5334507822990417,\n",
      "               0.5332896709442139,\n",
      "               0.5331941843032837,\n",
      "               0.533146858215332]}]\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.fewshot_lora import batch_fine_tune\n",
    "\n",
    "metrics, training_histories = batch_fine_tune(model_names=['opt-125m', 'opt-350m'], \n",
    "                                              train_datasets=train_datasets, \n",
    "                                              eval_dataset_in=eval_dataset_in, \n",
    "                                              eval_dataset_out=eval_dataset_out, \n",
    "                                              exp_label='final', \n",
    "                                              save_trials=False)\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)\n",
    "print(\"Training histories:\")\n",
    "pprint.pprint(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-context learning (ICL)\n",
    "\n",
    "ICL is performed similarly to zero-shot evaluation, using the `generate` method. Context (labeled training examples) is pre-pended to each evaluation example. Model parameters are not updated using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07c36ebab49443581b80fa3df3bb31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2e8d7c50c841e0a18519e88f96da48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddb489e101a4d47aceff62d05504735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e8f56142a74a50845f103d5be0234c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd3572bd94249ea940e0fed3b946ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 2-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd3fe0f524c4f5c98ab72f399636014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58b8c83b0fc44eab094833c52732a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 8-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1443c775d6414f9bb5f7cdfcf9e48708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 16-shot:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "[{'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.7108021247386932,\n",
      "  'eval_in_peak_memory_gb': 3.716986656188965,\n",
      "  'eval_in_runtime': 3.782561779022217,\n",
      "  'eval_in_samples_per_second': 13.218554757597344,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.716986656188965,\n",
      "  'eval_out_runtime': 3.737440347671509,\n",
      "  'eval_out_samples_per_second': 13.37813994306314,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7411929666996002,\n",
      "  'eval_in_peak_memory_gb': 3.7184338569641113,\n",
      "  'eval_in_runtime': 3.7354483604431152,\n",
      "  'eval_in_samples_per_second': 13.385274048887878,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7788479083776474,\n",
      "  'eval_out_peak_memory_gb': 3.717555046081543,\n",
      "  'eval_out_runtime': 3.6653995513916016,\n",
      "  'eval_out_samples_per_second': 13.641077677607358,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.699963207244873,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.361722469329834,\n",
      "  'eval_in_samples_per_second': 14.873327722965662,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.299437999725342,\n",
      "  'eval_out_samples_per_second': 15.154095941236719,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7908021223545074,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.3809988498687744,\n",
      "  'eval_in_samples_per_second': 14.788529135980225,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.320896625518799,\n",
      "  'eval_out_samples_per_second': 15.056174773940418,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.7348250168561935,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3929688930511475,\n",
      "  'eval_in_samples_per_second': 14.73635673536553,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.313682794570923,\n",
      "  'eval_out_samples_per_second': 15.088951809726352,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 0.7320318847894669,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.3792686462402344,\n",
      "  'eval_in_samples_per_second': 14.796100942027758,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.6495723658800125,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.312976837158203,\n",
      "  'eval_out_samples_per_second': 15.09216709250792,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7439860987663269,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.349304437637329,\n",
      "  'eval_in_samples_per_second': 14.928472741424207,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3341493606567383,\n",
      "  'eval_out_samples_per_second': 14.996328775790458,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7844341725111008,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.418851375579834,\n",
      "  'eval_in_samples_per_second': 14.624794852780065,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.6867792326211929,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.3184189796447754,\n",
      "  'eval_out_samples_per_second': 15.067416232459085,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.36,\n",
      "  'eval_in_loss': 0.842422724366188,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3268396854400635,\n",
      "  'eval_in_samples_per_second': 15.029278452708539,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.6675609189271927,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.318333625793457,\n",
      "  'eval_out_samples_per_second': 15.067803795058234,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7996295934915543,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.3894290924072266,\n",
      "  'eval_in_samples_per_second': 14.751746868523277,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7808593547344208,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.3512039184570312,\n",
      "  'eval_out_samples_per_second': 14.920011200936143,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 0.8176181465387344,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.5243306159973145,\n",
      "  'eval_in_samples_per_second': 14.187091237423822,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.5411946773529053,\n",
      "  'eval_out_samples_per_second': 14.119528734120806,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7611929661035538,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.5823073387145996,\n",
      "  'eval_in_samples_per_second': 13.95748473606426,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.567392110824585,\n",
      "  'eval_out_samples_per_second': 14.015840829014657,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 0.8252158570289612,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3724844455718994,\n",
      "  'eval_in_samples_per_second': 14.825865265487117,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.327868938446045,\n",
      "  'eval_out_samples_per_second': 15.024630153658515,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.8008593541383743,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.4036569595336914,\n",
      "  'eval_in_samples_per_second': 14.690082048353695,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.35686993598938,\n",
      "  'eval_out_samples_per_second': 14.894827906182597,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.080193281173706,\n",
      "  'eval_in_samples_per_second': 16.232747569966623,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.0902936458587646,\n",
      "  'eval_out_samples_per_second': 16.17969220077319,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.8008593541383743,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.558263063430786,\n",
      "  'eval_in_samples_per_second': 14.051799742931676,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.5735464096069336,\n",
      "  'eval_out_samples_per_second': 13.991702994421072,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7548250162601471,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.5301923751831055,\n",
      "  'eval_in_samples_per_second': 14.163534075790015,\n",
      "  'eval_out_accuracy': 0.44,\n",
      "  'eval_out_loss': 0.7055494713783265,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.521430015563965,\n",
      "  'eval_out_samples_per_second': 14.198777138551876,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7515838092565537,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.387624979019165,\n",
      "  'eval_in_samples_per_second': 14.759603058091965,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7788479083776474,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.339463472366333,\n",
      "  'eval_out_samples_per_second': 14.972465012342285,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.8148250144720077,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3550195693969727,\n",
      "  'eval_in_samples_per_second': 14.90304272919247,\n",
      "  'eval_out_accuracy': 0.58,\n",
      "  'eval_out_loss': 0.7292387527227402,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3383586406707764,\n",
      "  'eval_out_samples_per_second': 14.977420158174947,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.8008593541383743,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.3602957725524902,\n",
      "  'eval_in_samples_per_second': 14.87964256254141,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.3425920009613037,\n",
      "  'eval_out_samples_per_second': 14.958451401074491,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7199632066488266,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.694136381149292,\n",
      "  'eval_in_samples_per_second': 13.534963206865788,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.6399632090330124,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.6671676635742188,\n",
      "  'eval_out_samples_per_second': 13.634500679270092,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.739290714263916,\n",
      "  'eval_in_samples_per_second': 13.371519847138327,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.7330212593078613,\n",
      "  'eval_out_samples_per_second': 13.393976762208553,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7419746524095535,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.385166883468628,\n",
      "  'eval_in_samples_per_second': 14.770320554704012,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3720741271972656,\n",
      "  'eval_out_samples_per_second': 14.827669296095225,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7583998340368271,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.456439733505249,\n",
      "  'eval_in_samples_per_second': 14.46575200352009,\n",
      "  'eval_out_accuracy': 0.32,\n",
      "  'eval_out_loss': 0.837618145942688,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.3836846351623535,\n",
      "  'eval_out_samples_per_second': 14.776790803851299,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7908021223545074,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3625667095184326,\n",
      "  'eval_in_samples_per_second': 14.869593474075852,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.361952781677246,\n",
      "  'eval_out_samples_per_second': 14.87230881781019,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7459975451231002,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.415696859359741,\n",
      "  'eval_in_samples_per_second': 14.638301365353687,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.7576181483268738,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.3651466369628906,\n",
      "  'eval_out_samples_per_second': 14.858193533321318,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7399632060527801,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3877086639404297,\n",
      "  'eval_in_samples_per_second': 14.759238458788325,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3447797298431396,\n",
      "  'eval_out_samples_per_second': 14.948667487393813,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7303540492057801,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.401653289794922,\n",
      "  'eval_in_samples_per_second': 14.69873492104611,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.4029548168182373,\n",
      "  'eval_out_samples_per_second': 14.693113100675841,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7583998340368271,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.362539052963257,\n",
      "  'eval_in_samples_per_second': 14.869715775029352,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7892387509346008,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.352031946182251,\n",
      "  'eval_out_samples_per_second': 14.916325620627449,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.757170073390007,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.427654981613159,\n",
      "  'eval_in_samples_per_second': 14.58723245723771,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.41550350189209,\n",
      "  'eval_out_samples_per_second': 14.639130064513607,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6931471824645996,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.6943817138671875,\n",
      "  'eval_in_samples_per_second': 13.534064390888627,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.727832317352295,\n",
      "  'eval_out_samples_per_second': 13.412620457003996,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.736384630203247,\n",
      "  'eval_in_samples_per_second': 13.381919943632827,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.737757682800293,\n",
      "  'eval_out_samples_per_second': 13.377004140766148,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.1094460487365723,\n",
      "  'eval_in_samples_per_second': 16.08003458375358,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.1028077602386475,\n",
      "  'eval_out_samples_per_second': 16.114436943445806,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.461071252822876,\n",
      "  'eval_in_samples_per_second': 14.446394294604486,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.4186716079711914,\n",
      "  'eval_out_samples_per_second': 14.62556388376609,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.4099278450012207,\n",
      "  'eval_in_samples_per_second': 14.663066866150096,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3897430896759033,\n",
      "  'eval_out_samples_per_second': 14.750380390857453,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.462833881378174,\n",
      "  'eval_in_samples_per_second': 14.43904088754627,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.4194552898406982,\n",
      "  'eval_out_samples_per_second': 14.622211949532273,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6931471824645996,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.428914785385132,\n",
      "  'eval_in_samples_per_second': 14.581873020908,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.408155918121338,\n",
      "  'eval_out_samples_per_second': 14.670690309133882,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.4293081760406494,\n",
      "  'eval_in_samples_per_second': 14.580200271685156,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.4117484092712402,\n",
      "  'eval_out_samples_per_second': 14.655242415920156,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_in_runtime': 3.3986997604370117,\n",
      "  'eval_in_samples_per_second': 14.711508378007153,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 3.717951774597168,\n",
      "  'eval_out_runtime': 3.3863325119018555,\n",
      "  'eval_out_samples_per_second': 14.765236380144682,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_in_runtime': 3.205258369445801,\n",
      "  'eval_in_samples_per_second': 15.599366489961044,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 3.717310905456543,\n",
      "  'eval_out_runtime': 3.1680407524108887,\n",
      "  'eval_out_samples_per_second': 15.782625258829087,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.7108021247386932,\n",
      "  'eval_in_peak_memory_gb': 7.301274299621582,\n",
      "  'eval_in_runtime': 17.7826144695282,\n",
      "  'eval_in_samples_per_second': 2.811735028371595,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7636524873971939,\n",
      "  'eval_out_peak_memory_gb': 7.301274299621582,\n",
      "  'eval_out_runtime': 17.05459427833557,\n",
      "  'eval_out_samples_per_second': 2.931761329761737,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.7712501978874207,\n",
      "  'eval_in_peak_memory_gb': 7.2999067306518555,\n",
      "  'eval_in_runtime': 64.14785099029541,\n",
      "  'eval_in_samples_per_second': 0.7794493381791424,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.2999067306518555,\n",
      "  'eval_out_runtime': 63.19734025001526,\n",
      "  'eval_out_samples_per_second': 0.7911725367269381,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.42,\n",
      "  'eval_in_loss': 0.7475609165430069,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.654972553253174,\n",
      "  'eval_in_samples_per_second': 2.0279884673164075,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.35378336906433,\n",
      "  'eval_out_samples_per_second': 2.0530690957657556,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7259975457191468,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 62.23095750808716,\n",
      "  'eval_in_samples_per_second': 0.8034586322008994,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 62.16570448875427,\n",
      "  'eval_out_samples_per_second': 0.80430199273371,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7796295940876007,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 25.152878761291504,\n",
      "  'eval_in_samples_per_second': 1.9878440346536577,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 25.041503190994263,\n",
      "  'eval_out_samples_per_second': 1.9966852476324832,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.7712501978874207,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 63.69982123374939,\n",
      "  'eval_in_samples_per_second': 0.7849315591722421,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 61.937522888183594,\n",
      "  'eval_out_samples_per_second': 0.8072650901823355,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.7419746524095535,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 23.52471351623535,\n",
      "  'eval_in_samples_per_second': 2.125424395306365,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.6855494719743729,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 23.49061393737793,\n",
      "  'eval_out_samples_per_second': 2.1285097159781214,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7700204372406005,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.88739728927612,\n",
      "  'eval_in_samples_per_second': 0.8946560839324357,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 55.96661996841431,\n",
      "  'eval_out_samples_per_second': 0.8933896674163695,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7383998346328735,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.080155611038208,\n",
      "  'eval_in_samples_per_second': 2.0763985419213937,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 23.900508880615234,\n",
      "  'eval_out_samples_per_second': 2.0920056660614885,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7383998346328735,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.34305381774902,\n",
      "  'eval_in_samples_per_second': 0.903455746490891,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7636524873971939,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 55.47252178192139,\n",
      "  'eval_out_samples_per_second': 0.9013471606097977,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.48,\n",
      "  'eval_in_loss': 0.7776181477308274,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.672138690948486,\n",
      "  'eval_in_samples_per_second': 2.026577453471579,\n",
      "  'eval_out_accuracy': 0.48,\n",
      "  'eval_out_loss': 0.7432044130563736,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.381779670715332,\n",
      "  'eval_out_samples_per_second': 2.0507116656481976,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.6991815215349197,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.29981589317322,\n",
      "  'eval_in_samples_per_second': 0.9041621421776291,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7067792320251465,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 55.08898329734802,\n",
      "  'eval_out_samples_per_second': 0.9076224865164102,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7940433293581008,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.71471858024597,\n",
      "  'eval_in_samples_per_second': 2.0230859533219245,\n",
      "  'eval_out_accuracy': 0.52,\n",
      "  'eval_out_loss': 0.7712501978874207,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.567224264144897,\n",
      "  'eval_out_samples_per_second': 2.0352319603714224,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8084570646286011,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.490925788879395,\n",
      "  'eval_in_samples_per_second': 0.9175839697369225,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.63327932357788,\n",
      "  'eval_out_samples_per_second': 0.9151930951071737,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 7.300576210021973,\n",
      "  'eval_in_runtime': 24.39886975288391,\n",
      "  'eval_in_samples_per_second': 2.0492752535838292,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.237054109573364,\n",
      "  'eval_out_samples_per_second': 2.0629569820636973,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.46,\n",
      "  'eval_in_loss': 0.8236524856090546,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.07552123069763,\n",
      "  'eval_in_samples_per_second': 0.9078443359721002,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.687336444854736,\n",
      "  'eval_out_samples_per_second': 0.914288448668892,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7864456188678741,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.7498037815094,\n",
      "  'eval_in_samples_per_second': 2.0202180365306592,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.592562913894653,\n",
      "  'eval_out_samples_per_second': 2.0331349837373107,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 0.7176181495189666,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.38079023361206,\n",
      "  'eval_in_samples_per_second': 0.919442321180093,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.25121855735779,\n",
      "  'eval_out_samples_per_second': 0.9216382844403185,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7884570652246475,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.69538426399231,\n",
      "  'eval_in_samples_per_second': 2.024669851884171,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.4341938495636,\n",
      "  'eval_out_samples_per_second': 2.046312651354078,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.52,\n",
      "  'eval_in_loss': 0.7432044130563736,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.591240644454956,\n",
      "  'eval_in_samples_per_second': 0.9158978511890385,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7700204372406005,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.38486051559448,\n",
      "  'eval_out_samples_per_second': 0.9193735081045734,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.7059975463151932,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.794607400894165,\n",
      "  'eval_in_samples_per_second': 2.016567521782856,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7211929672956466,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.55758023262024,\n",
      "  'eval_out_samples_per_second': 2.036031218319473,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.720749616622925,\n",
      "  'eval_in_samples_per_second': 0.9137301727462288,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.28714108467102,\n",
      "  'eval_out_samples_per_second': 0.9210284240611526,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.58,\n",
      "  'eval_in_loss': 0.7252158600091935,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.814202785491943,\n",
      "  'eval_in_samples_per_second': 2.014975070213957,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.7315838098526001,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.59472942352295,\n",
      "  'eval_out_samples_per_second': 2.032955888190373,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.56,\n",
      "  'eval_in_loss': 0.7520318841934204,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.46925234794617,\n",
      "  'eval_in_samples_per_second': 0.9179490785113615,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7360547775030136,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.49014759063721,\n",
      "  'eval_out_samples_per_second': 0.9175970741652253,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6979517608880996,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.809606313705444,\n",
      "  'eval_in_samples_per_second': 2.0153483843223565,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.66203236579895,\n",
      "  'eval_out_samples_per_second': 2.027407930472895,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 0.7935952544212341,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.34018397331238,\n",
      "  'eval_in_samples_per_second': 0.9201293838930701,\n",
      "  'eval_out_accuracy': 0.4,\n",
      "  'eval_out_loss': 0.7591815197467804,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.4123899936676,\n",
      "  'eval_out_samples_per_second': 0.9189083590303402,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7315838098526001,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.68863606452942,\n",
      "  'eval_in_samples_per_second': 2.025223259369757,\n",
      "  'eval_out_accuracy': 0.56,\n",
      "  'eval_out_loss': 0.6791815221309662,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.604429244995117,\n",
      "  'eval_out_samples_per_second': 2.0321544345585947,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.44,\n",
      "  'eval_in_loss': 0.7399632060527801,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.57994318008423,\n",
      "  'eval_in_samples_per_second': 0.9160874322464408,\n",
      "  'eval_out_accuracy': 0.42,\n",
      "  'eval_out_loss': 0.7227563387155533,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.4891791343689,\n",
      "  'eval_out_samples_per_second': 0.9176133829562986,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.54,\n",
      "  'eval_in_loss': 0.7404112809896469,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.77171540260315,\n",
      "  'eval_in_samples_per_second': 2.018431068958015,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.58446764945984,\n",
      "  'eval_out_samples_per_second': 2.0338044619444333,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.38,\n",
      "  'eval_in_loss': 0.7867792296409607,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.582223892211914,\n",
      "  'eval_in_samples_per_second': 0.916049153635425,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.34858536720276,\n",
      "  'eval_out_samples_per_second': 0.9199871470835567,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 8},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6931471824645996,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.802963733673096,\n",
      "  'eval_in_samples_per_second': 2.0158881227616683,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.527846574783325,\n",
      "  'eval_out_samples_per_second': 2.0384993785554815,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.72426629066467,\n",
      "  'eval_in_samples_per_second': 0.9136714548976863,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.817851543426514,\n",
      "  'eval_out_samples_per_second': 0.9121116313796095,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.61512541770935,\n",
      "  'eval_in_samples_per_second': 2.031271389095889,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.41839599609375,\n",
      "  'eval_out_samples_per_second': 2.047636544513349,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 54.46488404273987,\n",
      "  'eval_in_samples_per_second': 0.918022701760713,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.34955286979675,\n",
      "  'eval_out_samples_per_second': 0.9199707699488012,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.079060316085815,\n",
      "  'eval_in_samples_per_second': 2.076492991987645,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.02046227455139,\n",
      "  'eval_out_samples_per_second': 2.0815586073450705,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6931471824645996,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.234214782714844,\n",
      "  'eval_in_samples_per_second': 0.9052360062815114,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 55.31083917617798,\n",
      "  'eval_out_samples_per_second': 0.9039819453966028,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.13042449951172,\n",
      "  'eval_in_samples_per_second': 2.072072955078422,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 24.882349967956543,\n",
      "  'eval_out_samples_per_second': 2.0094565048875985,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.8132616430521011,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.54189896583557,\n",
      "  'eval_in_samples_per_second': 0.900221291150948,\n",
      "  'eval_out_accuracy': 0.54,\n",
      "  'eval_out_loss': 0.7732616442441941,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 55.35291004180908,\n",
      "  'eval_out_samples_per_second': 0.9032948757749877,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.6931471824645996,\n",
      "  'eval_in_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_in_runtime': 24.179583311080933,\n",
      "  'eval_in_samples_per_second': 2.0678602834766875,\n",
      "  'eval_out_accuracy': 0.46,\n",
      "  'eval_out_loss': 0.6931471824645996,\n",
      "  'eval_out_peak_memory_gb': 7.300572395324707,\n",
      "  'eval_out_runtime': 23.934029817581177,\n",
      "  'eval_out_samples_per_second': 2.0890756960314136,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16},\n",
      " {'eval_in_accuracy': 0.0,\n",
      "  'eval_in_loss': 1.0032044053077698,\n",
      "  'eval_in_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_in_runtime': 55.252147912979126,\n",
      "  'eval_in_samples_per_second': 0.9049421948038809,\n",
      "  'eval_out_accuracy': 0.0,\n",
      "  'eval_out_loss': 0.9783998274803162,\n",
      "  'eval_out_peak_memory_gb': 7.300694465637207,\n",
      "  'eval_out_runtime': 54.94097137451172,\n",
      "  'eval_out_samples_per_second': 0.9100676371221944,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 16}]\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.incontext import batch_evaluate\n",
    "\n",
    "metrics = batch_evaluate(model_names=['opt-125m', 'opt-350m'], \n",
    "                         train_datasets=train_datasets, \n",
    "                         eval_dataset_in=eval_dataset_in, \n",
    "                         eval_dataset_out=eval_dataset_out, \n",
    "                         exp_label='final')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-distillation fine-tuning\n",
    "TODO: add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82c4273c4c4441c90e1ccd2ed35fc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 16-shot:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb135073a343499c93c359c73c8112e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4096-shot:   0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28ea08d0ed641188c7d8f3825c93085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 16-shot:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959f04b7bac2479fa30e710f4fd4b2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4096-shot:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.context_distillation import batch_context_distillation\n",
    "from src.data.data import get_context_distillation_datasets\n",
    "\n",
    "context_distillation_datasets = get_context_distillation_datasets(dataset=in_domain_train,\n",
    "                                                                  train_datasets=train_datasets,\n",
    "                                                                  fewshot_sample_size=16,\n",
    "                                                                  large_sample_size=4096)\n",
    "\n",
    "metrics = batch_context_distillation(model_names=['opt-125m', 'opt-350m'],\n",
    "                                     in_domain_dataset=in_domain_train,\n",
    "                                     train_datasets=context_distillation_datasets,\n",
    "                                     eval_dataset_in=eval_dataset_in,\n",
    "                                     eval_dataset_out=eval_dataset_out,\n",
    "                                     exp_label='final')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive context-distillation fine-tuning\n",
    "TODO: add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813fa6c73f944b48816947d98f8184f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 16-shot:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ab387b23cc46469f8c9a88c86beb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4096-shot:   0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0e862f23794f3492542bba08840c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 16-shot:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c01c725ce14b1a8364861b981ec8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4096-shot:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.context_distillation_recursive import batch_recursive_context_distillation\n",
    "from src.data.data import get_context_distillation_datasets\n",
    "\n",
    "context_distillation_datasets = get_context_distillation_datasets(dataset=in_domain_train,\n",
    "                                                                  train_datasets=train_datasets,\n",
    "                                                                  fewshot_sample_size=16,\n",
    "                                                                  large_sample_size=4096)\n",
    "\n",
    "metrics = batch_recursive_context_distillation(model_names=['opt-125m', 'opt-350m'],\n",
    "                                     in_domain_dataset=in_domain_train,\n",
    "                                     train_datasets=context_distillation_datasets,\n",
    "                                     eval_dataset_in=eval_dataset_in,\n",
    "                                     eval_dataset_out=eval_dataset_out,\n",
    "                                     exp_label='final')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot in-domain vs. out-of-domain metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.plot import plot_in_out_domain_subplots\n",
    "\n",
    "plot_in_out_domain_subplots(logfiles=['fewshot_metrics_final.csv',\n",
    "                                      'icl_metrics_final.csv',\n",
    "                                      'zeroshot_metrics_final.csv',\n",
    "                                      'fewshot_lora_metrics_final.csv',\n",
    "                                      'context_distillation_metrics_final.csv',\n",
    "                                      'recursive_context_distillation_metrics_final.csv'],\n",
    "                            metrics=['accuracy', 'runtime', 'peak_memory_gb', 'loss'],\n",
    "                            group_by='model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.plot import plot_learning_curves\n",
    "\n",
    "plot_learning_curves(logfile='fewshot_training_history_final.csv', subplot=True)\n",
    "plot_learning_curves(logfile='fewshot_lora_training_history_final.csv', subplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
