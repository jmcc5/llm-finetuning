{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment notebook for \"Context is All You Need\"\n",
    "In this notebook we conduct experiments involving few-shot fine-tuning, in-context learning (ICL), and a novel implementation of context distillation.\n",
    "\n",
    "To install the development environment, run the following:\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate fine-tuning\n",
    "```\n",
    "\n",
    "Run ```pip install -e .``` if module importing isn't working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the check below fails, verify your pytorch installation by following the steps at https://pytorch.org/get-started/locally/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "from src.utils import cuda_check\n",
    "\n",
    "cuda_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets\n",
    "\n",
    "Import datasets using methods from `src/data/data.py`. Datasets are downloaded from huggingface and stored in `/data`. Once downloaded, datasets are loaded locally.\n",
    "\n",
    "Our in domain dataset is [MNLI](https://huggingface.co/datasets/glue). Our out of domain dataset is [HANS](https://huggingface.co/datasets/hans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In domain (MNLI):\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "    num_rows: 261802\n",
      "})\n",
      "{'premise': 'One of our number will carry out your instructions minutely.', 'hypothesis': 'A member of my team will execute your orders with immense precision.', 'label': 0, 'idx': 2}\n",
      "\n",
      "Out of domain (HANS):\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "{'premise': 'The president avoided the athlete .', 'hypothesis': 'The athlete avoided the president .', 'label': 1, 'parse_premise': '(ROOT (S (NP (DT The) (NN president)) (VP (VBD avoided) (NP (DT the) (NN athlete))) (. .)))', 'parse_hypothesis': '(ROOT (S (NP (DT The) (NN athlete)) (VP (VBD avoided) (NP (DT the) (NN president))) (. .)))', 'binary_parse_premise': '( ( The president ) ( ( avoided ( the athlete ) ) . ) )', 'binary_parse_hypothesis': '( ( The athlete ) ( ( avoided ( the president ) ) . ) )', 'heuristic': 'lexical_overlap', 'subcase': 'ln_subject/object_swap', 'template': 'temp1'}\n"
     ]
    }
   ],
   "source": [
    "from src.data.data import get_in_domain, get_out_domain\n",
    "\n",
    "in_domain_train, in_domain_test = get_in_domain()\n",
    "out_domain = get_out_domain()\n",
    "\n",
    "print(f\"In domain (MNLI):\\n{in_domain_train}\")\n",
    "print(in_domain_train[1])\n",
    "\n",
    "print(f\"\\nOut of domain (HANS):\\n{out_domain}\")\n",
    "print(out_domain[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models\n",
    "\n",
    "Import models using methods from src/models/opt.py. Models are downloaded from huggingface and stored in /models/pretrained. Once downloaded, models are loaded locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.model.model import get_model\n",
    "\n",
    "# # Get SequenceClassification models\n",
    "# model_opt125, tokenizer_opt125 = get_model(model_name='opt-125m', model_type='SequenceClassification', pretrained=True)\n",
    "# model_opt350, tokenizer_opt350 = get_model(model_name='opt-350m', model_type='SequenceClassification', pretrained=True)\n",
    "\n",
    "# # Get CasualLM models\n",
    "# model_opt125_causal, tokenizer_opt125_causal = get_model(model_name='opt-125m', model_type='CausalLM', pretrained=True)\n",
    "# model_opt350_causal, tokenizer_opt350_causal = get_model(model_name='opt-350m', model_type='CausalLM', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and evaluation datasets\n",
    "\n",
    "The `get_random_subsets` method from `src/data/data.py` creates a dictionary of training and evaluation data organized by sample size. Each sample size will contain 10 randomly generated trials of that sample size. Evaluation sets contain 50 samples and are randomly generated a single time to ensure consistant comparison across fine-tuning methods.\n",
    "\n",
    "Before generating our datasets, we set random seeds to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train datasets:\n",
      "{2: [...], 4: [...]}\n",
      "Eval datasets:\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "    num_rows: 10\n",
      "})\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pprint\n",
    "from src.data.data import get_random_subsets\n",
    "\n",
    "# Seed random generators\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Generate training and evaluation datasets\n",
    "train_datasets, eval_dataset_in, eval_dataset_out = get_random_subsets(train_dataset=in_domain_train, \n",
    "                                                                       eval_dataset_in=in_domain_test, \n",
    "                                                                       eval_dataset_out=out_domain, \n",
    "                                                                       train_sample_sizes=[2, 4],\n",
    "                                                                       num_trials=1,\n",
    "                                                                       eval_sample_size=10)\n",
    "\n",
    "print(\"Train datasets:\")\n",
    "pprint.pprint(train_datasets, depth=1)\n",
    "print(\"Eval datasets:\")\n",
    "pprint.pprint(eval_dataset_in, depth=1)\n",
    "pprint.pprint(eval_dataset_out, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot baseline\n",
    "\n",
    "We evaluate both models on in and out of domain eval sets with no training or context using the `generate` method. These results serve as a baseline for comparison to other fine-tuning methods. Model parameters are not updated using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4463880e0fe546fcaf3cd90d9cd6a7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1189a2c22e0f418c8646d39291fe1c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11e13785a7e4a8792f4ad91b9ac923b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee9b70663134bdeac5334d632ca322a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "{'eval_in_accuracy': 0.5,\n",
      " 'eval_in_loss': 0.7411929666996002,\n",
      " 'eval_in_peak_memory_gb': 7.290054798126221,\n",
      " 'eval_in_runtime': 27.97590708732605,\n",
      " 'eval_in_samples_per_second': 0.35745042935641963,\n",
      " 'eval_out_accuracy': 0.6,\n",
      " 'eval_out_loss': 0.6171700775623321,\n",
      " 'eval_out_peak_memory_gb': 7.291031360626221,\n",
      " 'eval_out_runtime': 51.53153085708618,\n",
      " 'eval_out_samples_per_second': 0.1940559465957508,\n",
      " 'model_name': 'opt-350m',\n",
      " 'sample_size': '10'}\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.zeroshot import batch_evaluate\n",
    "\n",
    "metrics = batch_evaluate(model_names=['opt-125m', 'opt-350m'], \n",
    "                         eval_dataset_in=eval_dataset_in, \n",
    "                         eval_dataset_out=eval_dataset_out, \n",
    "                         exp_label='test')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot fine-tuning\n",
    "\n",
    "We fine-tune both models on 10 trials of training data and evaluate on in and out of domain eval sets. This method updates all model parameters. Fine-tuned models can be saved locally to `models/finetuned/` by setting the `save_trials` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fbc7c81c584a7bbcbd1322979694e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 2-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac64d52af32b4f97a9024062cf5592bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1375bb0179c54b43bebc857e6ade2822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 2-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038823f445d54010972b8e463fa30d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "[{'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 1.0867196321487427,\n",
      "  'eval_in_peak_memory_gb': 2.795626640319824,\n",
      "  'eval_in_runtime': 3.0859,\n",
      "  'eval_in_samples_per_second': 3.241,\n",
      "  'eval_in_steps_per_second': 0.648,\n",
      "  'eval_out_accuracy': 0.7,\n",
      "  'eval_out_loss': 0.5852086544036865,\n",
      "  'eval_out_peak_memory_gb': 2.795626640319824,\n",
      "  'eval_out_runtime': 3.0932,\n",
      "  'eval_out_samples_per_second': 3.233,\n",
      "  'eval_out_steps_per_second': 0.647,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 20903740047360.0,\n",
      "  'train_loss': 0.07343715172901284,\n",
      "  'train_peak_memory_gb': 3.7395753860473633,\n",
      "  'train_runtime': 220.8174,\n",
      "  'train_samples_per_second': 0.362,\n",
      "  'train_steps_per_second': 0.181},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 1.7668994665145874,\n",
      "  'eval_in_peak_memory_gb': 2.809414863586426,\n",
      "  'eval_in_runtime': 3.1643,\n",
      "  'eval_in_samples_per_second': 3.16,\n",
      "  'eval_in_steps_per_second': 0.632,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.9107545614242554,\n",
      "  'eval_out_peak_memory_gb': 2.809414863586426,\n",
      "  'eval_out_runtime': 3.1387,\n",
      "  'eval_out_samples_per_second': 3.186,\n",
      "  'eval_out_steps_per_second': 0.637,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 41807480094720.0,\n",
      "  'train_loss': 0.062327027811625156,\n",
      "  'train_peak_memory_gb': 4.809170722961426,\n",
      "  'train_runtime': 206.044,\n",
      "  'train_samples_per_second': 0.777,\n",
      "  'train_steps_per_second': 0.194},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.2781825065612793,\n",
      "  'eval_in_peak_memory_gb': 5.225518226623535,\n",
      "  'eval_in_runtime': 27.4648,\n",
      "  'eval_in_samples_per_second': 0.364,\n",
      "  'eval_in_steps_per_second': 0.073,\n",
      "  'eval_out_accuracy': 0.7,\n",
      "  'eval_out_loss': 0.9258222579956055,\n",
      "  'eval_out_peak_memory_gb': 5.225518226623535,\n",
      "  'eval_out_runtime': 27.4428,\n",
      "  'eval_out_samples_per_second': 0.364,\n",
      "  'eval_out_steps_per_second': 0.073,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'total_flos': 74553501941760.0,\n",
      "  'train_loss': 0.07981272615862353,\n",
      "  'train_peak_memory_gb': 7.733736991882324,\n",
      "  'train_runtime': 1728.0197,\n",
      "  'train_samples_per_second': 0.046,\n",
      "  'train_steps_per_second': 0.023},\n",
      " {'epoch': 40.0,\n",
      "  'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 3.2846152782440186,\n",
      "  'eval_in_peak_memory_gb': 5.225512504577637,\n",
      "  'eval_in_runtime': 32.6333,\n",
      "  'eval_in_samples_per_second': 0.306,\n",
      "  'eval_in_steps_per_second': 0.061,\n",
      "  'eval_out_accuracy': 0.3,\n",
      "  'eval_out_loss': 1.0600287914276123,\n",
      "  'eval_out_peak_memory_gb': 5.225512504577637,\n",
      "  'eval_out_runtime': 32.8994,\n",
      "  'eval_out_samples_per_second': 0.304,\n",
      "  'eval_out_steps_per_second': 0.061,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'total_flos': 149107003883520.0,\n",
      "  'train_loss': 0.07161233774001605,\n",
      "  'train_peak_memory_gb': 10.472392082214355,\n",
      "  'train_runtime': 2758.2322,\n",
      "  'train_samples_per_second': 0.058,\n",
      "  'train_steps_per_second': 0.015}]\n",
      "Training histories:\n",
      "[{'model_name': 'opt-125m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [0.5417,\n",
      "                 0.6562,\n",
      "                 0.6007,\n",
      "                 0.4579,\n",
      "                 0.2541,\n",
      "                 0.2006,\n",
      "                 0.0927,\n",
      "                 0.053,\n",
      "                 0.0254,\n",
      "                 0.0183,\n",
      "                 0.0109,\n",
      "                 0.0088,\n",
      "                 0.004,\n",
      "                 0.0024,\n",
      "                 0.0016,\n",
      "                 0.0012,\n",
      "                 0.0012,\n",
      "                 0.001,\n",
      "                 0.0007,\n",
      "                 0.0006,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.6823172569274902,\n",
      "               0.6802356243133545,\n",
      "               0.6766036748886108,\n",
      "               0.6695037484169006,\n",
      "               0.6584781408309937,\n",
      "               0.6497859954833984,\n",
      "               0.6425051093101501,\n",
      "               0.6365993618965149,\n",
      "               0.6316581964492798,\n",
      "               0.6277209520339966,\n",
      "               0.6238160133361816,\n",
      "               0.6191328763961792,\n",
      "               0.6148402094841003,\n",
      "               0.6109827160835266,\n",
      "               0.6074539422988892,\n",
      "               0.6042709946632385,\n",
      "               0.6016684770584106,\n",
      "               0.5994243025779724,\n",
      "               0.5974448323249817,\n",
      "               0.5954324007034302,\n",
      "               0.5936186909675598,\n",
      "               0.5921297073364258,\n",
      "               0.5908671617507935,\n",
      "               0.5897637605667114,\n",
      "               0.5889027118682861,\n",
      "               0.5881765484809875,\n",
      "               0.5876136422157288,\n",
      "               0.5871589779853821,\n",
      "               0.5867719650268555,\n",
      "               0.5864457488059998,\n",
      "               0.5861802101135254,\n",
      "               0.5859463810920715,\n",
      "               0.5857584476470947,\n",
      "               0.585602879524231,\n",
      "               0.5854787826538086,\n",
      "               0.5853821039199829,\n",
      "               0.5853089690208435,\n",
      "               0.5852571725845337,\n",
      "               0.5852245092391968,\n",
      "               0.5852087736129761]},\n",
      " {'model_name': 'opt-125m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.5751,\n",
      "                 0.561,\n",
      "                 0.4855,\n",
      "                 0.313,\n",
      "                 0.2408,\n",
      "                 0.1228,\n",
      "                 0.0723,\n",
      "                 0.0425,\n",
      "                 0.0288,\n",
      "                 0.0146,\n",
      "                 0.0119,\n",
      "                 0.0077,\n",
      "                 0.0039,\n",
      "                 0.0025,\n",
      "                 0.0019,\n",
      "                 0.0016,\n",
      "                 0.0009,\n",
      "                 0.0009,\n",
      "                 0.0006,\n",
      "                 0.0005,\n",
      "                 0.0004,\n",
      "                 0.0004,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0003,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0002,\n",
      "                 0.0001,\n",
      "                 0.0001,\n",
      "                 0.0001],\n",
      "  'val_loss': [0.6823172569274902,\n",
      "               0.6865927577018738,\n",
      "               0.6979302167892456,\n",
      "               0.7195539474487305,\n",
      "               0.7506411671638489,\n",
      "               0.777499794960022,\n",
      "               0.7990185022354126,\n",
      "               0.814210057258606,\n",
      "               0.8218307495117188,\n",
      "               0.8248062133789062,\n",
      "               0.826951801776886,\n",
      "               0.8277789354324341,\n",
      "               0.8296065330505371,\n",
      "               0.8317545652389526,\n",
      "               0.8349596858024597,\n",
      "               0.8392693400382996,\n",
      "               0.844534695148468,\n",
      "               0.8504613041877747,\n",
      "               0.8562495112419128,\n",
      "               0.862116813659668,\n",
      "               0.8677515983581543,\n",
      "               0.8727391362190247,\n",
      "               0.8773015141487122,\n",
      "               0.8815388679504395,\n",
      "               0.8855970501899719,\n",
      "               0.8893276453018188,\n",
      "               0.8926286697387695,\n",
      "               0.8956405520439148,\n",
      "               0.8983335494995117,\n",
      "               0.9007137417793274,\n",
      "               0.9028235673904419,\n",
      "               0.9046443104743958,\n",
      "               0.9061347246170044,\n",
      "               0.9074044227600098,\n",
      "               0.9084394574165344,\n",
      "               0.9092695116996765,\n",
      "               0.90989750623703,\n",
      "               0.9103397130966187,\n",
      "               0.9106196165084839,\n",
      "               0.9107546806335449]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 2,\n",
      "  'train_loss': [1.0762,\n",
      "                 1.2212,\n",
      "                 0.6926,\n",
      "                 0.1557,\n",
      "                 0.0427,\n",
      "                 0.0032,\n",
      "                 0.0009,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [1.1440174579620361,\n",
      "               1.1049432754516602,\n",
      "               1.0461409091949463,\n",
      "               0.9907014966011047,\n",
      "               0.9732445478439331,\n",
      "               0.9590311050415039,\n",
      "               0.9554767608642578,\n",
      "               0.9590370059013367,\n",
      "               0.9578157663345337,\n",
      "               0.9575005769729614,\n",
      "               0.9589449167251587,\n",
      "               0.9597770571708679,\n",
      "               0.9598745107650757,\n",
      "               0.9581511616706848,\n",
      "               0.9557663202285767,\n",
      "               0.9520000219345093,\n",
      "               0.9480663537979126,\n",
      "               0.9446970224380493,\n",
      "               0.9416801333427429,\n",
      "               0.9393146634101868,\n",
      "               0.9375258684158325,\n",
      "               0.9360159039497375,\n",
      "               0.9345923662185669,\n",
      "               0.9332841634750366,\n",
      "               0.9321783185005188,\n",
      "               0.9311413764953613,\n",
      "               0.9302382469177246,\n",
      "               0.9294017553329468,\n",
      "               0.9286566972732544,\n",
      "               0.928022563457489,\n",
      "               0.9275186657905579,\n",
      "               0.9271078109741211,\n",
      "               0.9267643690109253,\n",
      "               0.9264854192733765,\n",
      "               0.9262627363204956,\n",
      "               0.9260941743850708,\n",
      "               0.9259742498397827,\n",
      "               0.9258931875228882,\n",
      "               0.9258455038070679,\n",
      "               0.9258228540420532]},\n",
      " {'model_name': 'opt-350m',\n",
      "  'sample_size': 4,\n",
      "  'train_loss': [0.8508,\n",
      "                 1.0696,\n",
      "                 0.7426,\n",
      "                 0.1598,\n",
      "                 0.0326,\n",
      "                 0.0083,\n",
      "                 0.0005,\n",
      "                 0.0002,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0,\n",
      "                 0.0],\n",
      "  'val_loss': [1.1440174579620361,\n",
      "               1.2696506977081299,\n",
      "               1.6101293563842773,\n",
      "               1.9955297708511353,\n",
      "               2.1375348567962646,\n",
      "               2.022218704223633,\n",
      "               1.9242286682128906,\n",
      "               1.8321325778961182,\n",
      "               1.7380632162094116,\n",
      "               1.6459795236587524,\n",
      "               1.5606783628463745,\n",
      "               1.4819631576538086,\n",
      "               1.410995364189148,\n",
      "               1.350298285484314,\n",
      "               1.2990309000015259,\n",
      "               1.256042242050171,\n",
      "               1.22067391872406,\n",
      "               1.1910560131072998,\n",
      "               1.1669665575027466,\n",
      "               1.147626280784607,\n",
      "               1.1315085887908936,\n",
      "               1.1181707382202148,\n",
      "               1.1073100566864014,\n",
      "               1.0985541343688965,\n",
      "               1.091408371925354,\n",
      "               1.0854487419128418,\n",
      "               1.0804022550582886,\n",
      "               1.0761059522628784,\n",
      "               1.0725853443145752,\n",
      "               1.0697071552276611,\n",
      "               1.0673481225967407,\n",
      "               1.0654646158218384,\n",
      "               1.0639649629592896,\n",
      "               1.0627710819244385,\n",
      "               1.061847448348999,\n",
      "               1.0611597299575806,\n",
      "               1.0606622695922852,\n",
      "               1.06032395362854,\n",
      "               1.0601208209991455,\n",
      "               1.0600286722183228]}]\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.fewshot import batch_fine_tune\n",
    "\n",
    "metrics, training_histories = batch_fine_tune(model_names=['opt-125m', 'opt-350m'], \n",
    "                                              train_datasets=train_datasets, \n",
    "                                              eval_dataset_in=eval_dataset_in, \n",
    "                                              eval_dataset_out=eval_dataset_out,\n",
    "                                              exp_label='test',\n",
    "                                              save_trials=False)\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)\n",
    "print(\"Training histories:\")\n",
    "pprint.pprint(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-context learning (ICL)\n",
    "\n",
    "ICL is performed similarly to zero-shot evaluation, using the `generate` method. Context (labeled training examples) is pre-pended to each evaluation example. Model parameters are not updated using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d2c22dafc473fa8565da85bb43896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 2-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51790104ee284b7f8344d8ddee9f4a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-125m 4-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95bdf6f32ca492bbdf8f647254f7da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 2-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c415440ffd4835969198f7ebfb9990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "opt-350m 4-shot:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "[{'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 0.6791815221309662,\n",
      "  'eval_in_peak_memory_gb': 6.7336745262146,\n",
      "  'eval_in_runtime': 30.203482627868652,\n",
      "  'eval_in_samples_per_second': 0.3310876471832104,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7132616460323333,\n",
      "  'eval_out_peak_memory_gb': 6.7336745262146,\n",
      "  'eval_out_runtime': 25.80851149559021,\n",
      "  'eval_out_samples_per_second': 0.38746907204271186,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.6,\n",
      "  'eval_in_loss': 0.7032044142484665,\n",
      "  'eval_in_peak_memory_gb': 6.732081890106201,\n",
      "  'eval_in_runtime': 33.61594796180725,\n",
      "  'eval_in_samples_per_second': 0.29747785221947326,\n",
      "  'eval_out_accuracy': 0.7,\n",
      "  'eval_out_loss': 0.5791815251111985,\n",
      "  'eval_out_peak_memory_gb': 6.732081890106201,\n",
      "  'eval_out_runtime': 32.34635376930237,\n",
      "  'eval_out_samples_per_second': 0.3091538561446852,\n",
      "  'model_name': 'opt-125m',\n",
      "  'sample_size': 4},\n",
      " {'eval_in_accuracy': 0.5,\n",
      "  'eval_in_loss': 0.7171700745820999,\n",
      "  'eval_in_peak_memory_gb': 10.311509609222412,\n",
      "  'eval_in_runtime': 127.59925866127014,\n",
      "  'eval_in_samples_per_second': 0.07837036127730476,\n",
      "  'eval_out_accuracy': 0.5,\n",
      "  'eval_out_loss': 0.7512501984834671,\n",
      "  'eval_out_peak_memory_gb': 10.311509609222412,\n",
      "  'eval_out_runtime': 130.1016139984131,\n",
      "  'eval_out_samples_per_second': 0.07686299725783552,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 2},\n",
      " {'eval_in_accuracy': 0.4,\n",
      "  'eval_in_loss': 0.8032044112682343,\n",
      "  'eval_in_peak_memory_gb': 10.310887813568115,\n",
      "  'eval_in_runtime': 153.90174221992493,\n",
      "  'eval_in_samples_per_second': 0.06497652239511391,\n",
      "  'eval_out_accuracy': 0.6,\n",
      "  'eval_out_loss': 0.7132616460323333,\n",
      "  'eval_out_peak_memory_gb': 10.310887813568115,\n",
      "  'eval_out_runtime': 152.7819948196411,\n",
      "  'eval_out_samples_per_second': 0.06545273879821364,\n",
      "  'model_name': 'opt-350m',\n",
      "  'sample_size': 4}]\n"
     ]
    }
   ],
   "source": [
    "from src.finetuners.incontext import batch_evaluate\n",
    "\n",
    "metrics = batch_evaluate(model_names=['opt-125m', 'opt-350m'], \n",
    "                         train_datasets=train_datasets, \n",
    "                         eval_dataset_in=eval_dataset_in, \n",
    "                         eval_dataset_out=eval_dataset_out,\n",
    "                         exp_label='test')\n",
    "\n",
    "print(\"Metrics:\")\n",
    "pprint.pprint(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-distillation fine-tuning\n",
    "TODO: add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot in-domain vs. out-of-domain metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.plot import plot_in_out_domain\n",
    "\n",
    "plot_in_out_domain(logfile='opt-125m_fewshot_metrics_2_4_6_8_16.csv', metric='accuracy')\n",
    "plot_in_out_domain(logfile='opt-125m_fewshot_metrics_2_4_6_8_16.csv', metric='peak_memory_gb')\n",
    "plot_in_out_domain(logfile='opt-125m_fewshot_metrics_2_4_6_8_16.csv', metric='runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.plot import plot_learning_curves\n",
    "\n",
    "plot_learning_curves(logfile='opt-125m_fewshot_training_history_2_4_6_8_16.csv', subplot=False)\n",
    "plot_learning_curves(logfile='opt-125m_fewshot_training_history_2_4_6_8_16.csv', subplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
